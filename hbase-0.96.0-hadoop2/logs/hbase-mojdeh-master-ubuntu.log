dimanche 26 janvier 2014, 21:42:47 (UTC+0100) Starting master on ubuntu
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 62986
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 62986
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
dimanche 26 janvier 2014, 21:46:52 (UTC+0100) Starting master on ubuntu
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 62986
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 62986
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
dimanche 26 janvier 2014, 21:47:59 (UTC+0100) Starting master on ubuntu
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 62986
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 62986
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
dimanche 26 janvier 2014, 22:04:26 (UTC+0100) Starting master on ubuntu
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 62986
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 62986
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-01-26 22:04:26,620 INFO  [main] util.VersionInfo: HBase 0.96.1.1-hadoop2
2014-01-26 22:04:26,621 INFO  [main] util.VersionInfo: Subversion file:///home/jon/proj/hbase-svn/hbase-0.96.1.1 -r Unknown
2014-01-26 22:04:26,621 INFO  [main] util.VersionInfo: Compiled by jon on Tue Dec 17 12:22:12 PST 2013
2014-01-26 22:04:27,514 INFO  [main] server.ZooKeeperServer: Server environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
2014-01-26 22:04:27,514 INFO  [main] server.ZooKeeperServer: Server environment:host.name=localhost
2014-01-26 22:04:27,514 INFO  [main] server.ZooKeeperServer: Server environment:java.version=1.7.0_51
2014-01-26 22:04:27,514 INFO  [main] server.ZooKeeperServer: Server environment:java.vendor=Oracle Corporation
2014-01-26 22:04:27,514 INFO  [main] server.ZooKeeperServer: Server environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
2014-01-26 22:04:27,514 INFO  [main] server.ZooKeeperServer: Server environment:java.class.path=/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../conf:/usr/lib/jvm/java-7-openjdk-amd64/lib/tools.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/..:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/activation-1.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/aopalliance-1.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/asm-3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/avro-1.7.4.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-beanutils-1.7.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-cli-1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-codec-1.7.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-collections-3.2.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-compress-1.4.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-configuration-1.6.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-daemon-1.0.13.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-digester-1.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-el-1.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-httpclient-3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-io-2.4.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-lang-2.6.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-logging-1.1.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-math-2.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-net-3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/core-3.1.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/gmbal-api-only-3.0.0-b023.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/grizzly-framework-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/grizzly-http-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/grizzly-http-server-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/grizzly-http-servlet-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/grizzly-rcm-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/guava-12.0.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/guice-3.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/guice-servlet-3.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-annotations-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-auth-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-client-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-common-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-hdfs-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-hdfs-2.2.0-tests.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-app-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-common-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-core-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-yarn-api-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-yarn-client-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-yarn-common-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-yarn-server-common-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hamcrest-core-1.3.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-client-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-common-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-common-0.96.1.1-hadoop2-tests.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-examples-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-hadoop2-compat-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-hadoop-compat-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-it-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-it-0.96.1.1-hadoop2-tests.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-prefix-tree-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-protocol-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-server-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-server-0.96.1.1-hadoop2-tests.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-shell-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-testing-util-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-thrift-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/high-scale-lib-1.1.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/htrace-core-2.01.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/httpclient-4.1.3.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/httpcore-4.1.3.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jackson-core-asl-1.8.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jackson-xc-1.8.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jamon-runtime-2.3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jasper-compiler-5.5.23.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jasper-runtime-5.5.23.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/javax.inject-1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/javax.servlet-3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/javax.servlet-api-3.0.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jaxb-api-2.2.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-client-1.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-core-1.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-grizzly2-1.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-guice-1.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-json-1.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-server-1.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-test-framework-core-1.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-test-framework-grizzly2-1.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jets3t-0.6.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jettison-1.3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jetty-6.1.26.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jetty-sslengine-6.1.26.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jetty-util-6.1.26.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jruby-complete-1.6.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jsch-0.1.42.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jsp-2.1-6.1.14.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jsp-api-2.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jsr305-1.3.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/junit-4.11.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/libthrift-0.9.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/log4j-1.2.17.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/management-api-3.0.0-b012.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/metrics-core-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/netty-3.6.6.Final.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/paranamer-2.3.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/protobuf-java-2.5.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/servlet-api-2.5.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/slf4j-api-1.6.4.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/snappy-java-1.0.4.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/stax-api-1.0.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/xmlenc-0.52.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/xz-1.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/zookeeper-3.4.5.jar:
2014-01-26 22:04:27,514 INFO  [main] server.ZooKeeperServer: Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2014-01-26 22:04:27,514 INFO  [main] server.ZooKeeperServer: Server environment:java.io.tmpdir=/tmp
2014-01-26 22:04:27,514 INFO  [main] server.ZooKeeperServer: Server environment:java.compiler=<NA>
2014-01-26 22:04:27,514 INFO  [main] server.ZooKeeperServer: Server environment:os.name=Linux
2014-01-26 22:04:27,514 INFO  [main] server.ZooKeeperServer: Server environment:os.arch=amd64
2014-01-26 22:04:27,514 INFO  [main] server.ZooKeeperServer: Server environment:os.version=3.8.0-29-generic
2014-01-26 22:04:27,514 INFO  [main] server.ZooKeeperServer: Server environment:user.name=mojdeh
2014-01-26 22:04:27,515 INFO  [main] server.ZooKeeperServer: Server environment:user.home=/home/mojdeh
2014-01-26 22:04:27,515 INFO  [main] server.ZooKeeperServer: Server environment:user.dir=/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2
2014-01-26 22:04:27,530 INFO  [main] server.ZooKeeperServer: Created server with tickTime 2000 minSessionTimeout 4000 maxSessionTimeout 40000 datadir /home/mojdeh/HBASE/zookeeper/zookeeper_0/version-2 snapdir /home/mojdeh/HBASE/zookeeper/zookeeper_0/version-2
2014-01-26 22:04:27,544 INFO  [main] server.NIOServerCnxnFactory: binding to port 0.0.0.0/0.0.0.0:2181
2014-01-26 22:04:27,551 INFO  [main] persistence.FileTxnSnapLog: Snapshotting: 0x0 to /home/mojdeh/HBASE/zookeeper/zookeeper_0/version-2/snapshot.0
2014-01-26 22:04:27,756 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33381
2014-01-26 22:04:27,766 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Processing stat command from /127.0.0.1:33381
2014-01-26 22:04:27,769 INFO  [Thread-1] server.NIOServerCnxn: Stat command output
2014-01-26 22:04:27,769 INFO  [Thread-1] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:33381 (no session established for client)
2014-01-26 22:04:27,770 INFO  [main] zookeeper.MiniZooKeeperCluster: Started MiniZK Cluster and connect 1 ZK server on client port: 2181
2014-01-26 22:04:27,888 DEBUG [main] master.HMaster: master/localhost/127.0.0.1:0 HConnection server-to-server retries=350
2014-01-26 22:04:28,068 INFO  [main] ipc.RpcServer: master/localhost/127.0.0.1:0: started 10 reader(s).
2014-01-26 22:04:28,151 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-01-26 22:04:28,180 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-01-26 22:04:28,180 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-01-26 22:04:58,792 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-01-26 22:04:58,920 INFO  [main] master.HMaster: hbase.rootdir=file:/home/mojdeh/HBASE/hbase, hbase.cluster.distributed=false
2014-01-26 22:04:58,926 INFO  [main] Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2014-01-26 22:04:59,048 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
2014-01-26 22:04:59,048 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=localhost
2014-01-26 22:04:59,048 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_51
2014-01-26 22:04:59,048 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2014-01-26 22:04:59,048 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
2014-01-26 22:04:59,048 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../conf:/usr/lib/jvm/java-7-openjdk-amd64/lib/tools.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/..:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/activation-1.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/aopalliance-1.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/asm-3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/avro-1.7.4.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-beanutils-1.7.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-cli-1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-codec-1.7.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-collections-3.2.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-compress-1.4.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-configuration-1.6.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-daemon-1.0.13.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-digester-1.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-el-1.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-httpclient-3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-io-2.4.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-lang-2.6.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-logging-1.1.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-math-2.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-net-3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/core-3.1.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/gmbal-api-only-3.0.0-b023.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/grizzly-framework-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/grizzly-http-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/grizzly-http-server-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/grizzly-http-servlet-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/grizzly-rcm-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/guava-12.0.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/guice-3.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/guice-servlet-3.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-annotations-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-auth-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-client-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-common-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-hdfs-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-hdfs-2.2.0-tests.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-app-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-common-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-core-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-yarn-api-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-yarn-client-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-yarn-common-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-yarn-server-common-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hamcrest-core-1.3.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-client-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-common-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-common-0.96.1.1-hadoop2-tests.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-examples-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-hadoop2-compat-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-hadoop-compat-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-it-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-it-0.96.1.1-hadoop2-tests.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-prefix-tree-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-protocol-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-server-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-server-0.96.1.1-hadoop2-tests.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-shell-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-testing-util-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-thrift-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/high-scale-lib-1.1.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/htrace-core-2.01.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/httpclient-4.1.3.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/httpcore-4.1.3.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jackson-core-asl-1.8.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jackson-xc-1.8.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jamon-runtime-2.3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jasper-compiler-5.5.23.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jasper-runtime-5.5.23.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/javax.inject-1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/javax.servlet-3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/javax.servlet-api-3.0.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jaxb-api-2.2.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-client-1.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-core-1.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-grizzly2-1.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-guice-1.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-json-1.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-server-1.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-test-framework-core-1.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-test-framework-grizzly2-1.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jets3t-0.6.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jettison-1.3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jetty-6.1.26.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jetty-sslengine-6.1.26.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jetty-util-6.1.26.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jruby-complete-1.6.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jsch-0.1.42.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jsp-2.1-6.1.14.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jsp-api-2.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jsr305-1.3.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/junit-4.11.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/libthrift-0.9.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/log4j-1.2.17.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/management-api-3.0.0-b012.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/metrics-core-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/netty-3.6.6.Final.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/paranamer-2.3.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/protobuf-java-2.5.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/servlet-api-2.5.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/slf4j-api-1.6.4.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/snappy-java-1.0.4.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/stax-api-1.0.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/xmlenc-0.52.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/xz-1.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/zookeeper-3.4.5.jar:
2014-01-26 22:04:59,048 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2014-01-26 22:04:59,048 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-01-26 22:04:59,048 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-01-26 22:04:59,048 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-01-26 22:04:59,048 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-01-26 22:04:59,048 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=3.8.0-29-generic
2014-01-26 22:04:59,048 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=mojdeh
2014-01-26 22:04:59,048 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/mojdeh
2014-01-26 22:04:59,048 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2
2014-01-26 22:04:59,049 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=master:51791, quorum=localhost:2181, baseZNode=/hbase
2014-01-26 22:04:59,068 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:51791 connecting to ZooKeeper ensemble=localhost:2181
2014-01-26 22:04:59,069 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2014-01-26 22:04:59,070 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33382
2014-01-26 22:04:59,070 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2014-01-26 22:04:59,073 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:33382
2014-01-26 22:04:59,076 INFO  [SyncThread:0] persistence.FileTxnLog: Creating new log file: log.1
2014-01-26 22:05:35,598 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33383
2014-01-26 22:05:35,601 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:33383
2014-01-26 22:05:40,000 INFO  [SessionTracker] server.ZooKeeperServer: Expiring session 0x143d05e25a40000, timeout of 40000ms exceeded
2014-01-26 22:05:40,001 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x143d05e25a40000
2014-01-26 22:06:16,000 INFO  [SessionTracker] server.ZooKeeperServer: Expiring session 0x143d05e25a40001, timeout of 40000ms exceeded
2014-01-26 22:06:16,031 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x143d05e25a40001
2014-01-26 22:06:29,091 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Client session timed out, have not heard from server in 90020ms for sessionid 0x0, closing socket connection and attempting reconnect
2014-01-26 22:06:29,204 WARN  [main] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=localhost:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase
2014-01-26 22:06:29,205 INFO  [main] util.RetryCounter: Sleeping 1000ms before retry #0...
2014-01-26 22:06:31,077 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2014-01-26 22:06:31,078 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2014-01-26 22:06:31,078 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33384
2014-01-26 22:06:31,078 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:33384
2014-01-26 22:07:02,368 WARN  [SyncThread:0] persistence.FileTxnLog: fsync-ing the write ahead log in SyncThread:0 took 123290ms which will adversely effect operation latency. See the ZooKeeper troubleshooting guide
2014-01-26 22:07:02,416 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d05e25a40000 with negotiated timeout 40000 for client /127.0.0.1:33382
2014-01-26 22:07:02,417 WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x143d05e25a40000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:220)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:744)
2014-01-26 22:07:02,478 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:33382 which had sessionid 0x143d05e25a40000
2014-01-26 22:07:03,023 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d05e25a40001 with negotiated timeout 40000 for client /127.0.0.1:33383
2014-01-26 22:07:03,024 INFO  [SyncThread:0] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:33383 which had sessionid 0x143d05e25a40001
2014-01-26 22:07:03,025 WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Exception causing close of session 0x143d05e25a40001 due to java.nio.channels.CancelledKeyException
2014-01-26 22:07:03,025 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d05e25a40002 with negotiated timeout 40000 for client /127.0.0.1:33384
2014-01-26 22:07:03,026 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x143d05e25a40002, negotiated timeout = 40000
2014-01-26 22:07:04,349 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33405
2014-01-26 22:07:04,350 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to renew session 0x143d05e25a40001 at /127.0.0.1:33405
2014-01-26 22:07:04,350 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Invalid session 0x143d05e25a40001 for client /127.0.0.1:33405, probably expired
2014-01-26 22:07:04,351 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:33405 which had sessionid 0x143d05e25a40001
2014-01-26 22:07:09,553 WARN  [SyncThread:0] persistence.FileTxnLog: fsync-ing the write ahead log in SyncThread:0 took 3758ms which will adversely effect operation latency. See the ZooKeeper troubleshooting guide
2014-01-26 22:07:10,293 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-01-26 22:07:10,293 INFO  [RpcServer.listener,port=51791] ipc.RpcServer: RpcServer.listener,port=51791: starting
2014-01-26 22:07:10,304 INFO  [RpcServer.handler=0,port=51791] ipc.RpcServer: RpcServer.handler=0,port=51791: starting
2014-01-26 22:07:10,304 INFO  [RpcServer.handler=1,port=51791] ipc.RpcServer: RpcServer.handler=1,port=51791: starting
2014-01-26 22:07:10,304 INFO  [RpcServer.handler=2,port=51791] ipc.RpcServer: RpcServer.handler=2,port=51791: starting
2014-01-26 22:07:10,304 INFO  [RpcServer.handler=3,port=51791] ipc.RpcServer: RpcServer.handler=3,port=51791: starting
2014-01-26 22:07:10,304 INFO  [RpcServer.handler=4,port=51791] ipc.RpcServer: RpcServer.handler=4,port=51791: starting
2014-01-26 22:07:10,304 INFO  [RpcServer.handler=5,port=51791] ipc.RpcServer: RpcServer.handler=5,port=51791: starting
2014-01-26 22:07:10,305 INFO  [RpcServer.handler=6,port=51791] ipc.RpcServer: RpcServer.handler=6,port=51791: starting
2014-01-26 22:07:10,305 INFO  [RpcServer.handler=7,port=51791] ipc.RpcServer: RpcServer.handler=7,port=51791: starting
2014-01-26 22:07:10,305 INFO  [RpcServer.handler=8,port=51791] ipc.RpcServer: RpcServer.handler=8,port=51791: starting
2014-01-26 22:07:10,305 INFO  [RpcServer.handler=9,port=51791] ipc.RpcServer: RpcServer.handler=9,port=51791: starting
2014-01-26 22:07:10,305 INFO  [RpcServer.handler=10,port=51791] ipc.RpcServer: RpcServer.handler=10,port=51791: starting
2014-01-26 22:07:10,305 INFO  [RpcServer.handler=11,port=51791] ipc.RpcServer: RpcServer.handler=11,port=51791: starting
2014-01-26 22:07:10,305 INFO  [RpcServer.handler=12,port=51791] ipc.RpcServer: RpcServer.handler=12,port=51791: starting
2014-01-26 22:07:10,305 INFO  [RpcServer.handler=13,port=51791] ipc.RpcServer: RpcServer.handler=13,port=51791: starting
2014-01-26 22:07:10,306 INFO  [RpcServer.handler=14,port=51791] ipc.RpcServer: RpcServer.handler=14,port=51791: starting
2014-01-26 22:07:10,306 INFO  [RpcServer.handler=15,port=51791] ipc.RpcServer: RpcServer.handler=15,port=51791: starting
2014-01-26 22:07:10,307 INFO  [RpcServer.handler=16,port=51791] ipc.RpcServer: RpcServer.handler=16,port=51791: starting
2014-01-26 22:07:10,307 INFO  [RpcServer.handler=17,port=51791] ipc.RpcServer: RpcServer.handler=17,port=51791: starting
2014-01-26 22:07:10,307 INFO  [RpcServer.handler=18,port=51791] ipc.RpcServer: RpcServer.handler=18,port=51791: starting
2014-01-26 22:07:10,307 INFO  [RpcServer.handler=19,port=51791] ipc.RpcServer: RpcServer.handler=19,port=51791: starting
2014-01-26 22:07:10,307 INFO  [RpcServer.handler=20,port=51791] ipc.RpcServer: RpcServer.handler=20,port=51791: starting
2014-01-26 22:07:10,307 INFO  [RpcServer.handler=21,port=51791] ipc.RpcServer: RpcServer.handler=21,port=51791: starting
2014-01-26 22:07:10,309 INFO  [RpcServer.handler=23,port=51791] ipc.RpcServer: RpcServer.handler=23,port=51791: starting
2014-01-26 22:07:10,309 INFO  [RpcServer.handler=24,port=51791] ipc.RpcServer: RpcServer.handler=24,port=51791: starting
2014-01-26 22:07:10,309 INFO  [RpcServer.handler=25,port=51791] ipc.RpcServer: RpcServer.handler=25,port=51791: starting
2014-01-26 22:07:10,309 INFO  [RpcServer.handler=22,port=51791] ipc.RpcServer: RpcServer.handler=22,port=51791: starting
2014-01-26 22:07:10,310 INFO  [RpcServer.handler=26,port=51791] ipc.RpcServer: RpcServer.handler=26,port=51791: starting
2014-01-26 22:07:10,310 INFO  [RpcServer.handler=27,port=51791] ipc.RpcServer: RpcServer.handler=27,port=51791: starting
2014-01-26 22:07:10,310 INFO  [RpcServer.handler=28,port=51791] ipc.RpcServer: RpcServer.handler=28,port=51791: starting
2014-01-26 22:07:10,310 INFO  [RpcServer.handler=29,port=51791] ipc.RpcServer: RpcServer.handler=29,port=51791: starting
2014-01-26 22:07:10,310 INFO  [Replication.RpcServer.handler=0,port=51791] ipc.RpcServer: Replication.RpcServer.handler=0,port=51791: starting
2014-01-26 22:07:10,310 INFO  [Replication.RpcServer.handler=1,port=51791] ipc.RpcServer: Replication.RpcServer.handler=1,port=51791: starting
2014-01-26 22:07:10,311 INFO  [Replication.RpcServer.handler=2,port=51791] ipc.RpcServer: Replication.RpcServer.handler=2,port=51791: starting
2014-01-26 22:07:10,357 DEBUG [main] regionserver.HRegionServer: regionserver/localhost/127.0.0.1:0 HConnection server-to-server retries=350
2014-01-26 22:07:10,376 INFO  [main] ipc.RpcServer: regionserver/localhost/127.0.0.1:0: started 10 reader(s).
2014-01-26 22:07:10,444 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 386.7 M
2014-01-26 22:07:10,488 INFO  [M:0;localhost:51791] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-01-26 22:07:10,529 INFO  [M:0;localhost:51791] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-01-26 22:07:10,678 INFO  [M:0;localhost:51791] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2014-01-26 22:07:10,679 INFO  [M:0;localhost:51791] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-01-26 22:07:10,687 INFO  [M:0;localhost:51791] http.HttpServer: Jetty bound to port 60010
2014-01-26 22:07:10,687 INFO  [M:0;localhost:51791] mortbay.log: jetty-6.1.26
2014-01-26 22:07:10,994 INFO  [M:0;localhost:51791] mortbay.log: Started SelectChannelConnector@0.0.0.0:60010
2014-01-26 22:07:13,143 WARN  [SyncThread:0] persistence.FileTxnLog: fsync-ing the write ahead log in SyncThread:0 took 2086ms which will adversely effect operation latency. See the ZooKeeper troubleshooting guide
2014-01-26 22:07:13,169 DEBUG [main-EventThread] master.ActiveMasterManager: A master is now available
2014-01-26 22:07:13,184 INFO  [M:0;localhost:51791] master.ActiveMasterManager: Registered Active Master=localhost,51791,1390770268454
2014-01-26 22:07:13,189 INFO  [M:0;localhost:51791] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2014-01-26 22:07:13,265 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:RS:0;localhost:35894
2014-01-26 22:07:13,268 INFO  [RS:0;localhost:35894] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=regionserver:35894, quorum=localhost:2181, baseZNode=/hbase
2014-01-26 22:07:13,269 INFO  [RS:0;localhost:35894] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:35894 connecting to ZooKeeper ensemble=localhost:2181
2014-01-26 22:07:13,270 INFO  [RS:0;localhost:35894-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2014-01-26 22:07:13,271 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33409
2014-01-26 22:07:13,271 INFO  [RS:0;localhost:35894-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2014-01-26 22:07:13,272 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:33409
2014-01-26 22:07:13,319 DEBUG [M:0;localhost:51791] util.FSUtils: Created version file at file:/home/mojdeh/HBASE/hbase with version=8
2014-01-26 22:07:13,331 DEBUG [M:0;localhost:51791] util.FSUtils: Created cluster ID file at file:/home/mojdeh/HBASE/hbase/hbase.id with ID: 7e21e55a-7634-4277-b78f-fbccc8d4184c
2014-01-26 22:07:13,356 INFO  [M:0;localhost:51791] master.MasterFileSystem: BOOTSTRAP: creating hbase:meta region
2014-01-26 22:07:13,380 INFO  [M:0;localhost:51791] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2014-01-26 22:07:13,449 INFO  [M:0;localhost:51791] regionserver.HRegion: creating HRegion hbase:meta HTD == 'hbase:meta', {TABLE_ATTRIBUTES => {IS_META => 'true', coprocessor$1 => '|org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint|536870911|'}, {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '10', TTL => '2147483647', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '8192', IN_MEMORY => 'false', BLOCKCACHE => 'false'} RootDir = file:/home/mojdeh/HBASE/hbase Table name == hbase:meta
2014-01-26 22:07:13,471 INFO  [M:0;localhost:51791] wal.FSHLog: WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true, optionallogflushinternal=1000ms
2014-01-26 22:07:13,494 INFO  [M:0;localhost:51791] wal.FSHLog: New WAL /home/mojdeh/HBASE/hbase/data/hbase/meta/1588230740/WALs/hlog.1390770433472
2014-01-26 22:07:13,494 INFO  [M:0;localhost:51791] wal.FSHLog: FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2014-01-26 22:07:13,502 DEBUG [M:0;localhost:51791] regionserver.HRegion: Instantiated hbase:meta,,1.1588230740
2014-01-26 22:07:13,530 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1,200000; off-peak ratio 5,000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0,500000
2014-01-26 22:07:13,541 INFO  [StoreOpener-1588230740-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2014-01-26 22:07:13,542 INFO  [StoreOpener-1588230740-1] util.ChecksumType: Checksum can use org.apache.hadoop.util.PureJavaCrc32C
2014-01-26 22:07:13,551 DEBUG [M:0;localhost:51791] regionserver.HRegion: Found 0 recovered edits file(s) under file:/home/mojdeh/HBASE/hbase/data/hbase/meta/1588230740
2014-01-26 22:07:13,559 INFO  [M:0;localhost:51791] regionserver.HRegion: Onlined 1588230740; next sequenceid=1
2014-01-26 22:07:13,559 DEBUG [M:0;localhost:51791] regionserver.HRegion: Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2014-01-26 22:07:13,559 DEBUG [M:0;localhost:51791] regionserver.HRegion: Updates disabled for region hbase:meta,,1.1588230740
2014-01-26 22:07:13,560 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore: Closed info
2014-01-26 22:07:13,560 INFO  [M:0;localhost:51791] regionserver.HRegion: Closed hbase:meta,,1.1588230740
2014-01-26 22:07:13,561 INFO  [M:0;localhost:51791.logSyncer] wal.FSHLog: M:0;localhost:51791.logSyncer exiting
2014-01-26 22:07:13,561 DEBUG [M:0;localhost:51791] wal.FSHLog: Closing WAL writer in file:/home/mojdeh/HBASE/hbase/data/hbase/meta/1588230740/WALs
2014-01-26 22:07:13,563 DEBUG [M:0;localhost:51791] wal.FSHLog: Moved 1 WAL file(s) to /home/mojdeh/HBASE/hbase/data/hbase/meta/1588230740/oldWALs
2014-01-26 22:07:14,991 WARN  [SyncThread:0] persistence.FileTxnLog: fsync-ing the write ahead log in SyncThread:0 took 1718ms which will adversely effect operation latency. See the ZooKeeper troubleshooting guide
2014-01-26 22:07:14,993 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d05e25a40003 with negotiated timeout 40000 for client /127.0.0.1:33409
2014-01-26 22:07:14,993 INFO  [RS:0;localhost:35894-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x143d05e25a40003, negotiated timeout = 40000
2014-01-26 22:07:15,041 DEBUG [M:0;localhost:51791] util.FSTableDescriptors: Wrote descriptor into: file:/home/mojdeh/HBASE/hbase/data/hbase/meta/.tabledesc/.tableinfo.0000000001
2014-01-26 22:07:15,043 DEBUG [M:0;localhost:51791] fs.HFileSystem: The file system is not a DistributedFileSystem. Skipping on block location reordering
2014-01-26 22:07:15,048 INFO  [M:0;localhost:51791] master.SplitLogManager: Timeout=120000, unassigned timeout=180000, distributedLogReplay=false
2014-01-26 22:07:15,052 INFO  [M:0;localhost:51791] master.SplitLogManager: Found 0 orphan tasks and 0 rescan nodes
2014-01-26 22:07:16,474 WARN  [SyncThread:0] persistence.FileTxnLog: fsync-ing the write ahead log in SyncThread:0 took 1417ms which will adversely effect operation latency. See the ZooKeeper troubleshooting guide
2014-01-26 22:07:16,557 INFO  [M:0;localhost:51791] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x9449798, quorum=localhost:2181, baseZNode=/hbase
2014-01-26 22:07:16,557 INFO  [M:0;localhost:51791] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x9449798 connecting to ZooKeeper ensemble=localhost:2181
2014-01-26 22:07:16,557 INFO  [M:0;localhost:51791-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2014-01-26 22:07:16,558 INFO  [M:0;localhost:51791-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2014-01-26 22:07:16,558 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33410
2014-01-26 22:07:16,560 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:33410
2014-01-26 22:07:17,281 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d05e25a40004 with negotiated timeout 40000 for client /127.0.0.1:33410
2014-01-26 22:07:17,281 INFO  [M:0;localhost:51791-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x143d05e25a40004, negotiated timeout = 40000
2014-01-26 22:07:17,303 DEBUG [M:0;localhost:51791] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@74e1d431
2014-01-26 22:07:17,548 INFO  [M:0;localhost:51791] master.HMaster: Server active/primary master=localhost,51791,1390770268454, sessionid=0x143d05e25a40002, setting cluster-up flag (Was=false)
2014-01-26 22:07:17,549 DEBUG [RS:0;localhost:35894] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@42e85a1
2014-01-26 22:07:17,551 INFO  [RS:0;localhost:35894] regionserver.HRegionServer: ClusterId : 7e21e55a-7634-4277-b78f-fbccc8d4184c
2014-01-26 22:07:17,558 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x143d05e25a40003 type:create cxid:0x8 zxid:0x14 txntype:-1 reqpath:n/a Error Path:/hbase/online-snapshot Error:KeeperErrorCode = NoNode for /hbase/online-snapshot
2014-01-26 22:07:17,567 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x143d05e25a40002 type:create cxid:0x24 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/hbase/online-snapshot Error:KeeperErrorCode = NoNode for /hbase/online-snapshot
2014-01-26 22:07:17,922 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x143d05e25a40002 type:create cxid:0x25 zxid:0x17 txntype:-1 reqpath:n/a Error Path:/hbase/online-snapshot Error:KeeperErrorCode = NodeExists for /hbase/online-snapshot
2014-01-26 22:07:18,207 INFO  [M:0;localhost:51791] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot already exists and this is not a retry
2014-01-26 22:07:18,210 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x143d05e25a40002 type:create cxid:0x26 zxid:0x19 txntype:-1 reqpath:n/a Error Path:/hbase/online-snapshot/acquired Error:KeeperErrorCode = NodeExists for /hbase/online-snapshot/acquired
2014-01-26 22:07:18,535 INFO  [M:0;localhost:51791] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2014-01-26 22:07:18,595 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33411
2014-01-26 22:07:18,596 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:33411
2014-01-26 22:07:18,616 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33412
2014-01-26 22:07:18,616 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:33412
2014-01-26 22:07:18,761 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d05e25a40005 with negotiated timeout 40000 for client /127.0.0.1:33411
2014-01-26 22:07:18,763 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d05e25a40006 with negotiated timeout 40000 for client /127.0.0.1:33412
2014-01-26 22:07:18,764 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x143d05e25a40002 type:create cxid:0x29 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/hbase/online-snapshot/abort Error:KeeperErrorCode = NodeExists for /hbase/online-snapshot/abort
2014-01-26 22:07:19,020 INFO  [RS:0;localhost:35894] regionserver.MemStoreFlusher: globalMemStoreLimit=386.7 M, globalMemStoreLimitLowMark=367.3 M, maxHeap=966.7 M
2014-01-26 22:07:19,023 INFO  [RS:0;localhost:35894] regionserver.HRegionServer: CompactionChecker runs every 10sec
2014-01-26 22:07:19,152 INFO  [M:0;localhost:51791] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/abort already exists and this is not a retry
2014-01-26 22:07:19,153 INFO  [M:0;localhost:51791] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2014-01-26 22:07:19,219 DEBUG [M:0;localhost:51791] procedure.ZKProcedureCoordinatorRpcs: Starting the controller for procedure member:localhost,51791,1390770268454
2014-01-26 22:07:19,222 INFO  [RS:0;localhost:35894] regionserver.HRegionServer: reportForDuty to master=localhost,51791,1390770268454 with port=35894, startcode=1390770430440
2014-01-26 22:07:19,231 DEBUG [M:0;localhost:51791] executor.ExecutorService: Starting executor service name=MASTER_OPEN_REGION-localhost:51791, corePoolSize=5, maxPoolSize=5
2014-01-26 22:07:19,231 DEBUG [M:0;localhost:51791] executor.ExecutorService: Starting executor service name=MASTER_CLOSE_REGION-localhost:51791, corePoolSize=5, maxPoolSize=5
2014-01-26 22:07:19,232 DEBUG [M:0;localhost:51791] executor.ExecutorService: Starting executor service name=MASTER_SERVER_OPERATIONS-localhost:51791, corePoolSize=5, maxPoolSize=5
2014-01-26 22:07:19,232 DEBUG [M:0;localhost:51791] executor.ExecutorService: Starting executor service name=MASTER_META_SERVER_OPERATIONS-localhost:51791, corePoolSize=5, maxPoolSize=5
2014-01-26 22:07:19,232 DEBUG [M:0;localhost:51791] executor.ExecutorService: Starting executor service name=M_LOG_REPLAY_OPS-localhost:51791, corePoolSize=10, maxPoolSize=10
2014-01-26 22:07:19,232 DEBUG [M:0;localhost:51791] executor.ExecutorService: Starting executor service name=MASTER_TABLE_OPERATIONS-localhost:51791, corePoolSize=1, maxPoolSize=1
2014-01-26 22:07:19,234 DEBUG [M:0;localhost:51791] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner
2014-01-26 22:07:19,238 INFO  [M:0;localhost:51791] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=replicationLogCleaner, quorum=localhost:2181, baseZNode=/hbase
2014-01-26 22:07:19,239 INFO  [M:0;localhost:51791] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=localhost:2181
2014-01-26 22:07:19,239 INFO  [M:0;localhost:51791-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2014-01-26 22:07:19,239 INFO  [M:0;localhost:51791-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2014-01-26 22:07:19,239 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33413
2014-01-26 22:07:19,240 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:33413
2014-01-26 22:07:19,305 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d05e25a40007 with negotiated timeout 40000 for client /127.0.0.1:33413
2014-01-26 22:07:19,305 INFO  [M:0;localhost:51791-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x143d05e25a40007, negotiated timeout = 40000
2014-01-26 22:07:19,306 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x143d05e25a40007 type:create cxid:0x1 zxid:0x21 txntype:-1 reqpath:n/a Error Path:/hbase/replication Error:KeeperErrorCode = NoNode for /hbase/replication
2014-01-26 22:07:19,366 DEBUG [RS:0;localhost:35894] regionserver.HRegionServer: Master is not running yet
2014-01-26 22:07:19,366 WARN  [RS:0;localhost:35894] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2014-01-26 22:07:19,658 DEBUG [M:0;localhost:51791] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner
2014-01-26 22:07:19,667 DEBUG [M:0;localhost:51791] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotLogCleaner
2014-01-26 22:07:19,668 DEBUG [M:0;localhost:51791] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner
2014-01-26 22:07:19,669 DEBUG [M:0;localhost:51791] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner
2014-01-26 22:07:19,669 DEBUG [M:0;localhost:51791] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner
2014-01-26 22:07:19,670 INFO  [M:0;localhost:51791] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-01-26 22:07:20,121 WARN  [RpcServer.handler=4,port=51791] master.HMaster: Table Namespace Manager not ready yet
2014-01-26 22:07:20,331 WARN  [RpcServer.handler=6,port=51791] master.HMaster: Table Namespace Manager not ready yet
2014-01-26 22:07:20,709 WARN  [RpcServer.handler=8,port=51791] master.HMaster: Table Namespace Manager not ready yet
2014-01-26 22:07:21,175 INFO  [M:0;localhost:51791] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 1505 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-01-26 22:07:21,220 WARN  [RpcServer.handler=10,port=51791] master.HMaster: Table Namespace Manager not ready yet
2014-01-26 22:07:22,235 WARN  [RpcServer.handler=12,port=51791] master.HMaster: Table Namespace Manager not ready yet
2014-01-26 22:07:22,367 INFO  [RS:0;localhost:35894] regionserver.HRegionServer: reportForDuty to master=localhost,51791,1390770268454 with port=35894, startcode=1390770430440
2014-01-26 22:07:22,380 INFO  [RpcServer.handler=13,port=51791] master.ServerManager: Registering server=localhost,35894,1390770430440
2014-01-26 22:07:22,383 INFO  [RpcServer.handler=13,port=51791] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2014-01-26 22:07:22,385 DEBUG [RS:0;localhost:35894] regionserver.HRegionServer: Config from master: hbase.rootdir=/home/mojdeh/HBASE/hbase
2014-01-26 22:07:22,385 DEBUG [RS:0;localhost:35894] regionserver.HRegionServer: Config from master: fs.default.name=file:/
2014-01-26 22:07:22,387 DEBUG [RS:0;localhost:35894] fs.HFileSystem: The file system is not a DistributedFileSystem. Skipping on block location reordering
2014-01-26 22:07:22,387 DEBUG [RS:0;localhost:35894] regionserver.HRegionServer: logdir=file:/home/mojdeh/HBASE/hbase/WALs/localhost,35894,1390770430440
2014-01-26 22:07:22,429 INFO  [M:0;localhost:51791] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 2759 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-01-26 22:07:22,727 DEBUG [RS:0;localhost:35894] regionserver.Replication: ReplicationStatisticsThread 300
2014-01-26 22:07:22,729 INFO  [RS:0;localhost:35894] wal.FSHLog: WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true, optionallogflushinternal=1000ms
2014-01-26 22:07:22,742 INFO  [RS:0;localhost:35894] wal.FSHLog: New WAL /home/mojdeh/HBASE/hbase/WALs/localhost,35894,1390770430440/localhost%2C35894%2C1390770430440.1390770442732
2014-01-26 22:07:22,742 INFO  [RS:0;localhost:35894] wal.FSHLog: FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2014-01-26 22:07:22,751 INFO  [RS:0;localhost:35894] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2014-01-26 22:07:22,755 DEBUG [RS:0;localhost:35894] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-localhost:35894, corePoolSize=3, maxPoolSize=3
2014-01-26 22:07:22,756 DEBUG [RS:0;localhost:35894] executor.ExecutorService: Starting executor service name=RS_OPEN_META-localhost:35894, corePoolSize=1, maxPoolSize=1
2014-01-26 22:07:22,756 DEBUG [RS:0;localhost:35894] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-localhost:35894, corePoolSize=3, maxPoolSize=3
2014-01-26 22:07:22,756 DEBUG [RS:0;localhost:35894] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-localhost:35894, corePoolSize=1, maxPoolSize=1
2014-01-26 22:07:22,756 DEBUG [RS:0;localhost:35894] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-localhost:35894, corePoolSize=2, maxPoolSize=2
2014-01-26 22:07:22,757 INFO  [RS:0;localhost:35894] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-01-26 22:07:22,758 INFO  [RS:0;localhost:35894] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context regionserver
2014-01-26 22:07:22,758 INFO  [RS:0;localhost:35894] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-01-26 22:07:22,760 INFO  [RS:0;localhost:35894] http.HttpServer: Jetty bound to port 60030
2014-01-26 22:07:22,760 INFO  [RS:0;localhost:35894] mortbay.log: jetty-6.1.26
2014-01-26 22:07:22,866 INFO  [RS:0;localhost:35894] mortbay.log: Started SelectChannelConnector@0.0.0.0:60030
2014-01-26 22:07:22,868 INFO  [RS:0;localhost:35894] regionserver.ReplicationSourceManager: Current list of replicators: [localhost,35894,1390770430440] other RSs: [localhost,35894,1390770430440]
2014-01-26 22:07:22,888 INFO  [RS:0;localhost:35894] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2014-01-26 22:07:22,893 INFO  [RS:0;localhost:35894] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x51196da, quorum=localhost:2181, baseZNode=/hbase
2014-01-26 22:07:22,894 INFO  [RS:0;localhost:35894] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x51196da connecting to ZooKeeper ensemble=localhost:2181
2014-01-26 22:07:22,894 INFO  [RS:0;localhost:35894-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2014-01-26 22:07:22,894 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33415
2014-01-26 22:07:22,895 INFO  [RS:0;localhost:35894-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2014-01-26 22:07:22,895 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:33415
2014-01-26 22:07:23,037 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d05e25a40008 with negotiated timeout 40000 for client /127.0.0.1:33415
2014-01-26 22:07:23,037 INFO  [RS:0;localhost:35894-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x143d05e25a40008, negotiated timeout = 40000
2014-01-26 22:07:23,040 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-01-26 22:07:23,040 INFO  [RpcServer.listener,port=35894] ipc.RpcServer: RpcServer.listener,port=35894: starting
2014-01-26 22:07:23,040 INFO  [RpcServer.handler=0,port=35894] ipc.RpcServer: RpcServer.handler=0,port=35894: starting
2014-01-26 22:07:23,040 INFO  [RpcServer.handler=1,port=35894] ipc.RpcServer: RpcServer.handler=1,port=35894: starting
2014-01-26 22:07:23,040 INFO  [RpcServer.handler=2,port=35894] ipc.RpcServer: RpcServer.handler=2,port=35894: starting
2014-01-26 22:07:23,040 INFO  [RpcServer.handler=3,port=35894] ipc.RpcServer: RpcServer.handler=3,port=35894: starting
2014-01-26 22:07:23,040 INFO  [RpcServer.handler=4,port=35894] ipc.RpcServer: RpcServer.handler=4,port=35894: starting
2014-01-26 22:07:23,041 INFO  [RpcServer.handler=5,port=35894] ipc.RpcServer: RpcServer.handler=5,port=35894: starting
2014-01-26 22:07:23,041 INFO  [RpcServer.handler=6,port=35894] ipc.RpcServer: RpcServer.handler=6,port=35894: starting
2014-01-26 22:07:23,041 INFO  [RpcServer.handler=7,port=35894] ipc.RpcServer: RpcServer.handler=7,port=35894: starting
2014-01-26 22:07:23,041 INFO  [RpcServer.handler=8,port=35894] ipc.RpcServer: RpcServer.handler=8,port=35894: starting
2014-01-26 22:07:23,041 INFO  [RpcServer.handler=9,port=35894] ipc.RpcServer: RpcServer.handler=9,port=35894: starting
2014-01-26 22:07:23,041 INFO  [RpcServer.handler=10,port=35894] ipc.RpcServer: RpcServer.handler=10,port=35894: starting
2014-01-26 22:07:23,041 INFO  [RpcServer.handler=11,port=35894] ipc.RpcServer: RpcServer.handler=11,port=35894: starting
2014-01-26 22:07:23,041 INFO  [RpcServer.handler=12,port=35894] ipc.RpcServer: RpcServer.handler=12,port=35894: starting
2014-01-26 22:07:23,041 INFO  [RpcServer.handler=13,port=35894] ipc.RpcServer: RpcServer.handler=13,port=35894: starting
2014-01-26 22:07:23,041 INFO  [RpcServer.handler=14,port=35894] ipc.RpcServer: RpcServer.handler=14,port=35894: starting
2014-01-26 22:07:23,041 INFO  [RpcServer.handler=15,port=35894] ipc.RpcServer: RpcServer.handler=15,port=35894: starting
2014-01-26 22:07:23,041 INFO  [RpcServer.handler=16,port=35894] ipc.RpcServer: RpcServer.handler=16,port=35894: starting
2014-01-26 22:07:23,041 INFO  [RpcServer.handler=17,port=35894] ipc.RpcServer: RpcServer.handler=17,port=35894: starting
2014-01-26 22:07:23,042 INFO  [RpcServer.handler=18,port=35894] ipc.RpcServer: RpcServer.handler=18,port=35894: starting
2014-01-26 22:07:23,042 INFO  [RpcServer.handler=19,port=35894] ipc.RpcServer: RpcServer.handler=19,port=35894: starting
2014-01-26 22:07:23,042 INFO  [RpcServer.handler=20,port=35894] ipc.RpcServer: RpcServer.handler=20,port=35894: starting
2014-01-26 22:07:23,042 INFO  [RpcServer.handler=21,port=35894] ipc.RpcServer: RpcServer.handler=21,port=35894: starting
2014-01-26 22:07:23,042 INFO  [RpcServer.handler=22,port=35894] ipc.RpcServer: RpcServer.handler=22,port=35894: starting
2014-01-26 22:07:23,042 INFO  [RpcServer.handler=23,port=35894] ipc.RpcServer: RpcServer.handler=23,port=35894: starting
2014-01-26 22:07:23,042 INFO  [RpcServer.handler=24,port=35894] ipc.RpcServer: RpcServer.handler=24,port=35894: starting
2014-01-26 22:07:23,042 INFO  [RpcServer.handler=25,port=35894] ipc.RpcServer: RpcServer.handler=25,port=35894: starting
2014-01-26 22:07:23,042 INFO  [RpcServer.handler=26,port=35894] ipc.RpcServer: RpcServer.handler=26,port=35894: starting
2014-01-26 22:07:23,042 INFO  [RpcServer.handler=27,port=35894] ipc.RpcServer: RpcServer.handler=27,port=35894: starting
2014-01-26 22:07:23,042 INFO  [RpcServer.handler=28,port=35894] ipc.RpcServer: RpcServer.handler=28,port=35894: starting
2014-01-26 22:07:23,043 INFO  [RpcServer.handler=29,port=35894] ipc.RpcServer: RpcServer.handler=29,port=35894: starting
2014-01-26 22:07:23,043 INFO  [Priority.RpcServer.handler=0,port=35894] ipc.RpcServer: Priority.RpcServer.handler=0,port=35894: starting
2014-01-26 22:07:23,043 INFO  [Priority.RpcServer.handler=1,port=35894] ipc.RpcServer: Priority.RpcServer.handler=1,port=35894: starting
2014-01-26 22:07:23,043 INFO  [Priority.RpcServer.handler=2,port=35894] ipc.RpcServer: Priority.RpcServer.handler=2,port=35894: starting
2014-01-26 22:07:23,043 INFO  [Priority.RpcServer.handler=3,port=35894] ipc.RpcServer: Priority.RpcServer.handler=3,port=35894: starting
2014-01-26 22:07:23,043 INFO  [Priority.RpcServer.handler=4,port=35894] ipc.RpcServer: Priority.RpcServer.handler=4,port=35894: starting
2014-01-26 22:07:23,043 INFO  [Priority.RpcServer.handler=5,port=35894] ipc.RpcServer: Priority.RpcServer.handler=5,port=35894: starting
2014-01-26 22:07:23,043 INFO  [Priority.RpcServer.handler=6,port=35894] ipc.RpcServer: Priority.RpcServer.handler=6,port=35894: starting
2014-01-26 22:07:23,043 INFO  [Priority.RpcServer.handler=7,port=35894] ipc.RpcServer: Priority.RpcServer.handler=7,port=35894: starting
2014-01-26 22:07:23,043 INFO  [Priority.RpcServer.handler=8,port=35894] ipc.RpcServer: Priority.RpcServer.handler=8,port=35894: starting
2014-01-26 22:07:23,044 INFO  [Priority.RpcServer.handler=9,port=35894] ipc.RpcServer: Priority.RpcServer.handler=9,port=35894: starting
2014-01-26 22:07:23,044 INFO  [Replication.RpcServer.handler=0,port=35894] ipc.RpcServer: Replication.RpcServer.handler=0,port=35894: starting
2014-01-26 22:07:23,044 INFO  [Replication.RpcServer.handler=1,port=35894] ipc.RpcServer: Replication.RpcServer.handler=1,port=35894: starting
2014-01-26 22:07:23,044 INFO  [Replication.RpcServer.handler=2,port=35894] ipc.RpcServer: Replication.RpcServer.handler=2,port=35894: starting
2014-01-26 22:07:23,060 INFO  [RS:0;localhost:35894] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2014-01-26 22:07:23,066 INFO  [RS:0;localhost:35894] regionserver.HRegionServer: Serving as localhost,35894,1390770430440, RpcServer on localhost/127.0.0.1:35894, sessionid=0x143d05e25a40003
2014-01-26 22:07:23,066 INFO  [SplitLogWorker-localhost,35894,1390770430440] regionserver.SplitLogWorker: SplitLogWorker localhost,35894,1390770430440 starting
2014-01-26 22:07:23,066 DEBUG [RS:0;localhost:35894] snapshot.RegionServerSnapshotManager: Start Snapshot Manager localhost,35894,1390770430440
2014-01-26 22:07:23,066 DEBUG [RS:0;localhost:35894] procedure.ZKProcedureMemberRpcs: Starting procedure member 'localhost,35894,1390770430440'
2014-01-26 22:07:23,066 DEBUG [RS:0;localhost:35894] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2014-01-26 22:07:23,067 DEBUG [RS:0;localhost:35894] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2014-01-26 22:07:23,934 INFO  [M:0;localhost:51791] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 4264 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-01-26 22:07:24,185 INFO  [M:0;localhost:51791] master.ServerManager: Finished waiting for region servers count to settle; checked in 1, slept for 4515 ms, expecting minimum of 1, maximum of 2147483647, master is running.
2014-01-26 22:07:24,186 INFO  [M:0;localhost:51791] master.MasterFileSystem: Log folder file:/home/mojdeh/HBASE/hbase/WALs/localhost,35894,1390770430440 belongs to an existing region server
2014-01-26 22:07:24,262 WARN  [RpcServer.handler=16,port=51791] master.HMaster: Table Namespace Manager not ready yet
2014-01-26 22:07:25,223 INFO  [M:0;localhost:51791] zookeeper.ZooKeeperNodeTracker: Unsetting hbase:meta region location in ZooKeeper
2014-01-26 22:07:25,228 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x143d05e25a40002 type:delete cxid:0x41 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/hbase/meta-region-server Error:KeeperErrorCode = NoNode for /hbase/meta-region-server
2014-01-26 22:07:25,277 WARN  [M:0;localhost:51791] zookeeper.RecoverableZooKeeper: Node /hbase/meta-region-server already deleted, retry=false
2014-01-26 22:07:25,283 DEBUG [M:0;localhost:51791] master.AssignmentManager: No previous transition plan found (or ignoring an existing plan) for hbase:meta,,1.1588230740; generated random plan=hri=hbase:meta,,1.1588230740, src=, dest=localhost,35894,1390770430440; 1 (online=1, available=1) available servers, forceNewPlan=false
2014-01-26 22:07:25,283 DEBUG [M:0;localhost:51791] zookeeper.ZKAssign: master:51791-0x143d05e25a40002, quorum=localhost:2181, baseZNode=/hbase Creating (or updating) unassigned node 1588230740 with OFFLINE state
2014-01-26 22:07:25,367 DEBUG [M:0;localhost:51791] master.AssignmentManager: Setting table hbase:meta to ENABLED state.
2014-01-26 22:07:25,522 INFO  [M:0;localhost:51791] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to localhost,35894,1390770430440
2014-01-26 22:07:25,522 INFO  [M:0;localhost:51791] master.RegionStates: Transitioned {1588230740 state=OFFLINE, ts=1390770445283, server=null} to {1588230740 state=PENDING_OPEN, ts=1390770445522, server=localhost,35894,1390770430440}
2014-01-26 22:07:25,523 DEBUG [M:0;localhost:51791] master.ServerManager: New admin connection to localhost,35894,1390770430440
2014-01-26 22:07:25,561 INFO  [Priority.RpcServer.handler=0,port=35894] regionserver.HRegionServer: Open hbase:meta,,1.1588230740
2014-01-26 22:07:25,563 DEBUG [RS_OPEN_META-localhost:35894-0] zookeeper.ZKAssign: regionserver:35894-0x143d05e25a40003, quorum=localhost:2181, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-01-26 22:07:25,566 INFO  [M:0;localhost:51791] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2014-01-26 22:07:25,759 DEBUG [RS_OPEN_META-localhost:35894-0] zookeeper.ZKAssign: regionserver:35894-0x143d05e25a40003, quorum=localhost:2181, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-01-26 22:07:25,760 DEBUG [RS_OPEN_META-localhost:35894-0] regionserver.HRegionServer: logdir=file:/home/mojdeh/HBASE/hbase/WALs/localhost,35894,1390770430440
2014-01-26 22:07:25,761 INFO  [RS_OPEN_META-localhost:35894-0] wal.FSHLog: WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true, optionallogflushinternal=1000ms
2014-01-26 22:07:25,765 DEBUG [AM.ZK.Worker-pool2-t1] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=localhost,35894,1390770430440, region=1588230740, current_state={1588230740 state=PENDING_OPEN, ts=1390770445522, server=localhost,35894,1390770430440}
2014-01-26 22:07:25,766 INFO  [AM.ZK.Worker-pool2-t1] master.RegionStates: Transitioned {1588230740 state=PENDING_OPEN, ts=1390770445522, server=localhost,35894,1390770430440} to {1588230740 state=OPENING, ts=1390770445766, server=localhost,35894,1390770430440}
2014-01-26 22:07:25,775 INFO  [RS_OPEN_META-localhost:35894-0] wal.FSHLog: New WAL /home/mojdeh/HBASE/hbase/WALs/localhost,35894,1390770430440/localhost%2C35894%2C1390770430440.1390770445763.meta
2014-01-26 22:07:25,775 INFO  [RS_OPEN_META-localhost:35894-0] wal.FSHLog: FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2014-01-26 22:07:25,777 DEBUG [RS_OPEN_META-localhost:35894-0] regionserver.HRegion: Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2014-01-26 22:07:25,794 DEBUG [RS_OPEN_META-localhost:35894-0] coprocessor.CoprocessorHost: Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2014-01-26 22:07:25,797 DEBUG [RS_OPEN_META-localhost:35894-0] regionserver.HRegion: Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2014-01-26 22:07:25,800 INFO  [RS_OPEN_META-localhost:35894-0] regionserver.RegionCoprocessorHost: Load coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2014-01-26 22:07:25,804 DEBUG [RS_OPEN_META-localhost:35894-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table meta 1588230740
2014-01-26 22:07:25,804 DEBUG [RS_OPEN_META-localhost:35894-0] regionserver.HRegion: Instantiated hbase:meta,,1.1588230740
2014-01-26 22:07:25,808 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1,200000; off-peak ratio 5,000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0,500000
2014-01-26 22:07:25,809 DEBUG [RS_OPEN_META-localhost:35894-0] regionserver.HRegion: Found 0 recovered edits file(s) under file:/home/mojdeh/HBASE/hbase/data/hbase/meta/1588230740
2014-01-26 22:07:25,810 INFO  [RS_OPEN_META-localhost:35894-0] regionserver.HRegion: Onlined 1588230740; next sequenceid=1
2014-01-26 22:07:25,810 DEBUG [RS_OPEN_META-localhost:35894-0] zookeeper.ZKAssign: regionserver:35894-0x143d05e25a40003, quorum=localhost:2181, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2014-01-26 22:07:25,812 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Post open deploy tasks for region=hbase:meta,,1.1588230740
2014-01-26 22:07:25,813 INFO  [PostOpenDeployTasks:1588230740] zookeeper.ZooKeeperNodeTracker: Setting hbase:meta region location in ZooKeeper as localhost,35894,1390770430440
2014-01-26 22:07:25,935 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Finished post open deploy task for hbase:meta,,1.1588230740
2014-01-26 22:07:25,935 DEBUG [RS_OPEN_META-localhost:35894-0] zookeeper.ZKAssign: regionserver:35894-0x143d05e25a40003, quorum=localhost:2181, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-01-26 22:07:27,181 WARN  [SyncThread:0] persistence.FileTxnLog: fsync-ing the write ahead log in SyncThread:0 took 1244ms which will adversely effect operation latency. See the ZooKeeper troubleshooting guide
2014-01-26 22:07:27,183 DEBUG [RS_OPEN_META-localhost:35894-0] zookeeper.ZKAssign: regionserver:35894-0x143d05e25a40003, quorum=localhost:2181, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-01-26 22:07:27,183 DEBUG [RS_OPEN_META-localhost:35894-0] handler.OpenRegionHandler: Transitioned 1588230740 to OPENED in zk on localhost,35894,1390770430440
2014-01-26 22:07:27,183 DEBUG [RS_OPEN_META-localhost:35894-0] handler.OpenRegionHandler: Opened hbase:meta,,1.1588230740 on localhost,35894,1390770430440
2014-01-26 22:07:27,185 DEBUG [AM.ZK.Worker-pool2-t2] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=localhost,35894,1390770430440, region=1588230740, current_state={1588230740 state=OPENING, ts=1390770445766, server=localhost,35894,1390770430440}
2014-01-26 22:07:27,185 INFO  [AM.ZK.Worker-pool2-t2] master.RegionStates: Transitioned {1588230740 state=OPENING, ts=1390770445766, server=localhost,35894,1390770430440} to {1588230740 state=OPEN, ts=1390770447185, server=localhost,35894,1390770430440}
2014-01-26 22:07:27,191 INFO  [AM.ZK.Worker-pool2-t2] handler.OpenedRegionHandler: Handling OPENED of 1588230740 from localhost,35894,1390770430440; deleting unassigned node
2014-01-26 22:07:27,242 DEBUG [AM.ZK.Worker-pool2-t2] zookeeper.ZKAssign: master:51791-0x143d05e25a40002, quorum=localhost:2181, baseZNode=/hbase Deleted unassigned node 1588230740 in expected state RS_ZK_REGION_OPENED
2014-01-26 22:07:27,243 DEBUG [AM.ZK.Worker-pool2-t3] master.AssignmentManager: Znode hbase:meta,,1.1588230740 deleted, state: {1588230740 state=OPEN, ts=1390770447185, server=localhost,35894,1390770430440}
2014-01-26 22:07:27,244 INFO  [AM.ZK.Worker-pool2-t3] master.RegionStates: Onlined 1588230740 on localhost,35894,1390770430440
2014-01-26 22:07:27,246 INFO  [M:0;localhost:51791] master.HMaster: hbase:meta assigned=1, rit=false, location=localhost,35894,1390770430440
2014-01-26 22:07:27,317 INFO  [M:0;localhost:51791] catalog.MetaMigrationConvertingToPB: hbase:meta doesn't have any entries to update.
2014-01-26 22:07:27,317 INFO  [M:0;localhost:51791] catalog.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2014-01-26 22:07:27,334 INFO  [M:0;localhost:51791] master.AssignmentManager: Clean cluster startup. Assigning userregions
2014-01-26 22:07:27,334 DEBUG [M:0;localhost:51791] zookeeper.ZKAssign: master:51791-0x143d05e25a40002, quorum=localhost:2181, baseZNode=/hbase Deleting any existing unassigned nodes
2014-01-26 22:07:27,347 INFO  [M:0;localhost:51791] master.SnapshotOfRegionAssignmentFromMeta: Start to scan the hbase:meta for the current region assignment snappshot
2014-01-26 22:07:27,362 INFO  [M:0;localhost:51791] master.SnapshotOfRegionAssignmentFromMeta: Finished to scan the hbase:meta for the current region assignmentsnapshot
2014-01-26 22:07:27,393 INFO  [M:0;localhost:51791] master.TableNamespaceManager: Namespace table not found. Creating...
2014-01-26 22:07:27,432 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x143d05e25a40002 type:create cxid:0x6a zxid:0x2f txntype:-1 reqpath:n/a Error Path:/hbase/table-lock/hbase:namespace Error:KeeperErrorCode = NoNode for /hbase/table-lock/hbase:namespace
2014-01-26 22:07:27,764 DEBUG [M:0;localhost:51791] lock.ZKInterProcessLockBase: Acquired a lock for /hbase/table-lock/hbase:namespace/write-master:517910000000000
2014-01-26 22:07:27,946 INFO  [MASTER_TABLE_OPERATIONS-localhost:51791-0] handler.CreateTableHandler: Create table hbase:namespace
2014-01-26 22:07:27,960 DEBUG [MASTER_TABLE_OPERATIONS-localhost:51791-0] util.FSTableDescriptors: Wrote descriptor into: file:/home/mojdeh/HBASE/hbase/.tmp/data/hbase/namespace/.tabledesc/.tableinfo.0000000001
2014-01-26 22:07:27,968 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: creating HRegion hbase:namespace HTD == 'hbase:namespace', {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '10', TTL => '2147483647', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '8192', IN_MEMORY => 'true', BLOCKCACHE => 'true'} RootDir = file:/home/mojdeh/HBASE/hbase/.tmp Table name == hbase:namespace
2014-01-26 22:07:27,974 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: Instantiated hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19.
2014-01-26 22:07:27,975 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: Closing hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19.: disabling compactions & flushes
2014-01-26 22:07:27,975 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: Updates disabled for region hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19.
2014-01-26 22:07:27,975 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: Closed hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19.
2014-01-26 22:07:28,044 INFO  [MASTER_TABLE_OPERATIONS-localhost:51791-0] catalog.MetaEditor: Added 1
2014-01-26 22:07:28,044 DEBUG [MASTER_TABLE_OPERATIONS-localhost:51791-0] master.AssignmentManager: Assigning 1 region(s) to localhost,35894,1390770430440
2014-01-26 22:07:28,046 DEBUG [MASTER_TABLE_OPERATIONS-localhost:51791-0] zookeeper.ZKAssign: master:51791-0x143d05e25a40002, quorum=localhost:2181, baseZNode=/hbase Async create of unassigned node 15a4b862c6b279ff97f6704c95fa3d19 with OFFLINE state
2014-01-26 22:07:28,285 WARN  [RpcServer.handler=23,port=51791] master.HMaster: Table Namespace Manager not ready yet
2014-01-26 22:07:28,521 DEBUG [main-EventThread] master.OfflineCallback: rs={15a4b862c6b279ff97f6704c95fa3d19 state=OFFLINE, ts=1390770448044, server=null}, server=localhost,35894,1390770430440
2014-01-26 22:07:28,526 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={15a4b862c6b279ff97f6704c95fa3d19 state=OFFLINE, ts=1390770448044, server=null}, server=localhost,35894,1390770430440
2014-01-26 22:07:28,527 INFO  [MASTER_TABLE_OPERATIONS-localhost:51791-0] master.AssignmentManager: localhost,35894,1390770430440 unassigned znodes=1 of total=1
2014-01-26 22:07:28,527 INFO  [MASTER_TABLE_OPERATIONS-localhost:51791-0] master.RegionStates: Transitioned {15a4b862c6b279ff97f6704c95fa3d19 state=OFFLINE, ts=1390770448046, server=null} to {15a4b862c6b279ff97f6704c95fa3d19 state=PENDING_OPEN, ts=1390770448527, server=localhost,35894,1390770430440}
2014-01-26 22:07:28,530 INFO  [Priority.RpcServer.handler=8,port=35894] regionserver.HRegionServer: Open hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19.
2014-01-26 22:07:28,536 DEBUG [RS_OPEN_REGION-localhost:35894-0] zookeeper.ZKAssign: regionserver:35894-0x143d05e25a40003, quorum=localhost:2181, baseZNode=/hbase Transitioning 15a4b862c6b279ff97f6704c95fa3d19 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-01-26 22:07:28,537 DEBUG [MASTER_TABLE_OPERATIONS-localhost:51791-0] master.AssignmentManager: Bulk assigning done for localhost,35894,1390770430440
2014-01-26 22:07:28,888 DEBUG [RS_OPEN_REGION-localhost:35894-0] zookeeper.ZKAssign: regionserver:35894-0x143d05e25a40003, quorum=localhost:2181, baseZNode=/hbase Transitioned node 15a4b862c6b279ff97f6704c95fa3d19 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-01-26 22:07:28,901 DEBUG [RS_OPEN_REGION-localhost:35894-0] regionserver.HRegion: Opening region: {ENCODED => 15a4b862c6b279ff97f6704c95fa3d19, NAME => 'hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19.', STARTKEY => '', ENDKEY => ''}
2014-01-26 22:07:28,903 DEBUG [RS_OPEN_REGION-localhost:35894-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table namespace 15a4b862c6b279ff97f6704c95fa3d19
2014-01-26 22:07:28,905 DEBUG [RS_OPEN_REGION-localhost:35894-0] regionserver.HRegion: Instantiated hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19.
2014-01-26 22:07:28,917 INFO  [StoreOpener-15a4b862c6b279ff97f6704c95fa3d19-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1,200000; off-peak ratio 5,000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0,500000
2014-01-26 22:07:28,921 DEBUG [RS_OPEN_REGION-localhost:35894-0] regionserver.HRegion: Found 0 recovered edits file(s) under file:/home/mojdeh/HBASE/hbase/data/hbase/namespace/15a4b862c6b279ff97f6704c95fa3d19
2014-01-26 22:07:28,922 INFO  [RS_OPEN_REGION-localhost:35894-0] regionserver.HRegion: Onlined 15a4b862c6b279ff97f6704c95fa3d19; next sequenceid=1
2014-01-26 22:07:28,922 DEBUG [RS_OPEN_REGION-localhost:35894-0] zookeeper.ZKAssign: regionserver:35894-0x143d05e25a40003, quorum=localhost:2181, baseZNode=/hbase Attempting to retransition opening state of node 15a4b862c6b279ff97f6704c95fa3d19
2014-01-26 22:07:28,987 DEBUG [MASTER_TABLE_OPERATIONS-localhost:51791-0] lock.ZKInterProcessLockBase: Released /hbase/table-lock/hbase:namespace/write-master:517910000000000
2014-01-26 22:07:28,988 DEBUG [AM.ZK.Worker-pool2-t5] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=localhost,35894,1390770430440, region=15a4b862c6b279ff97f6704c95fa3d19, current_state={15a4b862c6b279ff97f6704c95fa3d19 state=PENDING_OPEN, ts=1390770448527, server=localhost,35894,1390770430440}
2014-01-26 22:07:28,988 INFO  [AM.ZK.Worker-pool2-t5] master.RegionStates: Transitioned {15a4b862c6b279ff97f6704c95fa3d19 state=PENDING_OPEN, ts=1390770448527, server=localhost,35894,1390770430440} to {15a4b862c6b279ff97f6704c95fa3d19 state=OPENING, ts=1390770448988, server=localhost,35894,1390770430440}
2014-01-26 22:07:28,989 INFO  [PostOpenDeployTasks:15a4b862c6b279ff97f6704c95fa3d19] regionserver.HRegionServer: Post open deploy tasks for region=hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19.
2014-01-26 22:07:29,005 INFO  [PostOpenDeployTasks:15a4b862c6b279ff97f6704c95fa3d19] catalog.MetaEditor: Updated row hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19. with server=localhost,35894,1390770430440
2014-01-26 22:07:29,005 INFO  [PostOpenDeployTasks:15a4b862c6b279ff97f6704c95fa3d19] regionserver.HRegionServer: Finished post open deploy task for hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19.
2014-01-26 22:07:29,006 DEBUG [RS_OPEN_REGION-localhost:35894-0] zookeeper.ZKAssign: regionserver:35894-0x143d05e25a40003, quorum=localhost:2181, baseZNode=/hbase Transitioning 15a4b862c6b279ff97f6704c95fa3d19 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-01-26 22:07:29,100 DEBUG [RS_OPEN_REGION-localhost:35894-0] zookeeper.ZKAssign: regionserver:35894-0x143d05e25a40003, quorum=localhost:2181, baseZNode=/hbase Transitioned node 15a4b862c6b279ff97f6704c95fa3d19 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-01-26 22:07:29,101 DEBUG [RS_OPEN_REGION-localhost:35894-0] handler.OpenRegionHandler: Transitioned 15a4b862c6b279ff97f6704c95fa3d19 to OPENED in zk on localhost,35894,1390770430440
2014-01-26 22:07:29,101 DEBUG [RS_OPEN_REGION-localhost:35894-0] handler.OpenRegionHandler: Opened hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19. on localhost,35894,1390770430440
2014-01-26 22:07:29,103 DEBUG [AM.ZK.Worker-pool2-t6] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=localhost,35894,1390770430440, region=15a4b862c6b279ff97f6704c95fa3d19, current_state={15a4b862c6b279ff97f6704c95fa3d19 state=OPENING, ts=1390770448988, server=localhost,35894,1390770430440}
2014-01-26 22:07:29,103 INFO  [AM.ZK.Worker-pool2-t6] master.RegionStates: Transitioned {15a4b862c6b279ff97f6704c95fa3d19 state=OPENING, ts=1390770448988, server=localhost,35894,1390770430440} to {15a4b862c6b279ff97f6704c95fa3d19 state=OPEN, ts=1390770449103, server=localhost,35894,1390770430440}
2014-01-26 22:07:29,103 DEBUG [AM.ZK.Worker-pool2-t6] handler.OpenedRegionHandler: Handling OPENED of 15a4b862c6b279ff97f6704c95fa3d19 from localhost,35894,1390770430440; deleting unassigned node
2014-01-26 22:07:29,163 DEBUG [AM.ZK.Worker-pool2-t6] zookeeper.ZKAssign: master:51791-0x143d05e25a40002, quorum=localhost:2181, baseZNode=/hbase Deleted unassigned node 15a4b862c6b279ff97f6704c95fa3d19 in expected state RS_ZK_REGION_OPENED
2014-01-26 22:07:29,168 DEBUG [AM.ZK.Worker-pool2-t8] master.AssignmentManager: Znode hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19. deleted, state: {15a4b862c6b279ff97f6704c95fa3d19 state=OPEN, ts=1390770449103, server=localhost,35894,1390770430440}
2014-01-26 22:07:29,168 INFO  [AM.ZK.Worker-pool2-t8] master.RegionStates: Onlined 15a4b862c6b279ff97f6704c95fa3d19 on localhost,35894,1390770430440
2014-01-26 22:07:30,153 DEBUG [main-EventThread] hbase.ZKNamespaceManager: Updating namespace cache from node default with data: \x0A\x07default
2014-01-26 22:07:30,527 DEBUG [main-EventThread] hbase.ZKNamespaceManager: Updating namespace cache from node default with data: \x0A\x07default
2014-01-26 22:07:30,527 DEBUG [main-EventThread] hbase.ZKNamespaceManager: Updating namespace cache from node hbase with data: \x0A\x05hbase
2014-01-26 22:07:30,539 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x143d05e25a40002 type:create cxid:0x8c zxid:0x3f txntype:-1 reqpath:n/a Error Path:/hbase/namespace/default Error:KeeperErrorCode = NodeExists for /hbase/namespace/default
2014-01-26 22:07:30,677 INFO  [M:0;localhost:51791] zookeeper.RecoverableZooKeeper: Node /hbase/namespace/default already exists and this is not a retry
2014-01-26 22:07:30,799 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x143d05e25a40002 type:create cxid:0x8f zxid:0x41 txntype:-1 reqpath:n/a Error Path:/hbase/namespace/hbase Error:KeeperErrorCode = NodeExists for /hbase/namespace/hbase
2014-01-26 22:07:31,006 INFO  [M:0;localhost:51791] zookeeper.RecoverableZooKeeper: Node /hbase/namespace/hbase already exists and this is not a retry
2014-01-26 22:07:31,215 INFO  [M:0;localhost:51791] master.HMaster: Master has completed initialization
2014-01-26 22:07:46,344 INFO  [RpcServer.handler=29,port=51791] master.HMaster: Client=mojdeh//127.0.0.1 create 'test', {NAME => 'c', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => '2147483647', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
2014-01-26 22:07:46,346 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x143d05e25a40002 type:create cxid:0x94 zxid:0x43 txntype:-1 reqpath:n/a Error Path:/hbase/table-lock/test Error:KeeperErrorCode = NoNode for /hbase/table-lock/test
2014-01-26 22:07:47,429 DEBUG [RpcServer.handler=29,port=51791] lock.ZKInterProcessLockBase: Acquired a lock for /hbase/table-lock/test/write-master:517910000000000
2014-01-26 22:07:48,518 WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x143d05e25a40006, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:220)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:744)
2014-01-26 22:07:48,519 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:33412 which had sessionid 0x143d05e25a40006
2014-01-26 22:07:48,520 WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x143d05e25a40005, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:220)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:744)
2014-01-26 22:07:48,521 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:33411 which had sessionid 0x143d05e25a40005
2014-01-26 22:07:48,568 INFO  [MASTER_TABLE_OPERATIONS-localhost:51791-0] handler.CreateTableHandler: Create table test
2014-01-26 22:07:48,575 WARN  [RpcServer.handler=29,port=51791] ipc.RpcServer: RpcServer.respondercallId: 17 service: MasterService methodName: CreateTable size: 300 connection: 127.0.0.1:33500: output error
2014-01-26 22:07:48,575 WARN  [RpcServer.handler=29,port=51791] ipc.RpcServer: RpcServer.handler=29,port=51791: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
2014-01-26 22:07:48,583 DEBUG [MASTER_TABLE_OPERATIONS-localhost:51791-0] util.FSTableDescriptors: Wrote descriptor into: file:/home/mojdeh/HBASE/hbase/.tmp/data/default/test/.tabledesc/.tableinfo.0000000001
2014-01-26 22:07:48,585 INFO  [RegionOpenAndInitThread-test-1] regionserver.HRegion: creating HRegion test HTD == 'test', {NAME => 'c', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => '2147483647', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = file:/home/mojdeh/HBASE/hbase/.tmp Table name == test
2014-01-26 22:07:48,591 DEBUG [RegionOpenAndInitThread-test-1] regionserver.HRegion: Instantiated test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb.
2014-01-26 22:07:48,591 DEBUG [RegionOpenAndInitThread-test-1] regionserver.HRegion: Closing test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb.: disabling compactions & flushes
2014-01-26 22:07:48,591 DEBUG [RegionOpenAndInitThread-test-1] regionserver.HRegion: Updates disabled for region test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb.
2014-01-26 22:07:48,591 INFO  [RegionOpenAndInitThread-test-1] regionserver.HRegion: Closed test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb.
2014-01-26 22:07:48,602 INFO  [MASTER_TABLE_OPERATIONS-localhost:51791-0] catalog.MetaEditor: Added 1
2014-01-26 22:07:48,603 DEBUG [MASTER_TABLE_OPERATIONS-localhost:51791-0] master.AssignmentManager: Assigning 1 region(s) to localhost,35894,1390770430440
2014-01-26 22:07:48,603 DEBUG [MASTER_TABLE_OPERATIONS-localhost:51791-0] zookeeper.ZKAssign: master:51791-0x143d05e25a40002, quorum=localhost:2181, baseZNode=/hbase Async create of unassigned node 8e6786d5a1299d7b651eff93cf9ca5cb with OFFLINE state
2014-01-26 22:07:49,132 DEBUG [main-EventThread] master.OfflineCallback: rs={8e6786d5a1299d7b651eff93cf9ca5cb state=OFFLINE, ts=1390770468603, server=null}, server=localhost,35894,1390770430440
2014-01-26 22:07:49,134 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={8e6786d5a1299d7b651eff93cf9ca5cb state=OFFLINE, ts=1390770468603, server=null}, server=localhost,35894,1390770430440
2014-01-26 22:07:49,139 INFO  [MASTER_TABLE_OPERATIONS-localhost:51791-0] master.AssignmentManager: localhost,35894,1390770430440 unassigned znodes=1 of total=1
2014-01-26 22:07:49,139 INFO  [MASTER_TABLE_OPERATIONS-localhost:51791-0] master.RegionStates: Transitioned {8e6786d5a1299d7b651eff93cf9ca5cb state=OFFLINE, ts=1390770468603, server=null} to {8e6786d5a1299d7b651eff93cf9ca5cb state=PENDING_OPEN, ts=1390770469139, server=localhost,35894,1390770430440}
2014-01-26 22:07:49,143 INFO  [Priority.RpcServer.handler=6,port=35894] regionserver.HRegionServer: Open test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb.
2014-01-26 22:07:49,148 DEBUG [RS_OPEN_REGION-localhost:35894-1] zookeeper.ZKAssign: regionserver:35894-0x143d05e25a40003, quorum=localhost:2181, baseZNode=/hbase Transitioning 8e6786d5a1299d7b651eff93cf9ca5cb from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-01-26 22:07:49,149 DEBUG [MASTER_TABLE_OPERATIONS-localhost:51791-0] master.AssignmentManager: Bulk assigning done for localhost,35894,1390770430440
2014-01-26 22:07:49,900 DEBUG [RS_OPEN_REGION-localhost:35894-1] zookeeper.ZKAssign: regionserver:35894-0x143d05e25a40003, quorum=localhost:2181, baseZNode=/hbase Transitioned node 8e6786d5a1299d7b651eff93cf9ca5cb from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-01-26 22:07:49,901 DEBUG [RS_OPEN_REGION-localhost:35894-1] regionserver.HRegion: Opening region: {ENCODED => 8e6786d5a1299d7b651eff93cf9ca5cb, NAME => 'test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb.', STARTKEY => '', ENDKEY => ''}
2014-01-26 22:07:49,903 DEBUG [RS_OPEN_REGION-localhost:35894-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table test 8e6786d5a1299d7b651eff93cf9ca5cb
2014-01-26 22:07:49,905 DEBUG [RS_OPEN_REGION-localhost:35894-1] regionserver.HRegion: Instantiated test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb.
2014-01-26 22:07:49,905 DEBUG [AM.ZK.Worker-pool2-t10] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=localhost,35894,1390770430440, region=8e6786d5a1299d7b651eff93cf9ca5cb, current_state={8e6786d5a1299d7b651eff93cf9ca5cb state=PENDING_OPEN, ts=1390770469139, server=localhost,35894,1390770430440}
2014-01-26 22:07:49,905 INFO  [AM.ZK.Worker-pool2-t10] master.RegionStates: Transitioned {8e6786d5a1299d7b651eff93cf9ca5cb state=PENDING_OPEN, ts=1390770469139, server=localhost,35894,1390770430440} to {8e6786d5a1299d7b651eff93cf9ca5cb state=OPENING, ts=1390770469905, server=localhost,35894,1390770430440}
2014-01-26 22:07:49,910 INFO  [StoreOpener-8e6786d5a1299d7b651eff93cf9ca5cb-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1,200000; off-peak ratio 5,000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0,500000
2014-01-26 22:07:49,911 DEBUG [RS_OPEN_REGION-localhost:35894-1] regionserver.HRegion: Found 0 recovered edits file(s) under file:/home/mojdeh/HBASE/hbase/data/default/test/8e6786d5a1299d7b651eff93cf9ca5cb
2014-01-26 22:07:49,911 INFO  [RS_OPEN_REGION-localhost:35894-1] regionserver.HRegion: Onlined 8e6786d5a1299d7b651eff93cf9ca5cb; next sequenceid=1
2014-01-26 22:07:49,912 DEBUG [RS_OPEN_REGION-localhost:35894-1] zookeeper.ZKAssign: regionserver:35894-0x143d05e25a40003, quorum=localhost:2181, baseZNode=/hbase Attempting to retransition opening state of node 8e6786d5a1299d7b651eff93cf9ca5cb
2014-01-26 22:07:50,829 DEBUG [MASTER_TABLE_OPERATIONS-localhost:51791-0] lock.ZKInterProcessLockBase: Released /hbase/table-lock/test/write-master:517910000000000
2014-01-26 22:07:50,830 INFO  [PostOpenDeployTasks:8e6786d5a1299d7b651eff93cf9ca5cb] regionserver.HRegionServer: Post open deploy tasks for region=test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb.
2014-01-26 22:07:50,839 INFO  [PostOpenDeployTasks:8e6786d5a1299d7b651eff93cf9ca5cb] catalog.MetaEditor: Updated row test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb. with server=localhost,35894,1390770430440
2014-01-26 22:07:50,840 INFO  [PostOpenDeployTasks:8e6786d5a1299d7b651eff93cf9ca5cb] regionserver.HRegionServer: Finished post open deploy task for test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb.
2014-01-26 22:07:50,840 DEBUG [RS_OPEN_REGION-localhost:35894-1] zookeeper.ZKAssign: regionserver:35894-0x143d05e25a40003, quorum=localhost:2181, baseZNode=/hbase Transitioning 8e6786d5a1299d7b651eff93cf9ca5cb from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-01-26 22:07:51,162 DEBUG [RS_OPEN_REGION-localhost:35894-1] zookeeper.ZKAssign: regionserver:35894-0x143d05e25a40003, quorum=localhost:2181, baseZNode=/hbase Transitioned node 8e6786d5a1299d7b651eff93cf9ca5cb from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-01-26 22:07:51,162 DEBUG [RS_OPEN_REGION-localhost:35894-1] handler.OpenRegionHandler: Transitioned 8e6786d5a1299d7b651eff93cf9ca5cb to OPENED in zk on localhost,35894,1390770430440
2014-01-26 22:07:51,162 DEBUG [RS_OPEN_REGION-localhost:35894-1] handler.OpenRegionHandler: Opened test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb. on localhost,35894,1390770430440
2014-01-26 22:07:51,163 DEBUG [AM.ZK.Worker-pool2-t11] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=localhost,35894,1390770430440, region=8e6786d5a1299d7b651eff93cf9ca5cb, current_state={8e6786d5a1299d7b651eff93cf9ca5cb state=OPENING, ts=1390770469905, server=localhost,35894,1390770430440}
2014-01-26 22:07:51,164 INFO  [AM.ZK.Worker-pool2-t11] master.RegionStates: Transitioned {8e6786d5a1299d7b651eff93cf9ca5cb state=OPENING, ts=1390770469905, server=localhost,35894,1390770430440} to {8e6786d5a1299d7b651eff93cf9ca5cb state=OPEN, ts=1390770471163, server=localhost,35894,1390770430440}
2014-01-26 22:07:51,164 DEBUG [AM.ZK.Worker-pool2-t11] handler.OpenedRegionHandler: Handling OPENED of 8e6786d5a1299d7b651eff93cf9ca5cb from localhost,35894,1390770430440; deleting unassigned node
2014-01-26 22:07:51,377 DEBUG [AM.ZK.Worker-pool2-t11] zookeeper.ZKAssign: master:51791-0x143d05e25a40002, quorum=localhost:2181, baseZNode=/hbase Deleted unassigned node 8e6786d5a1299d7b651eff93cf9ca5cb in expected state RS_ZK_REGION_OPENED
2014-01-26 22:07:51,378 DEBUG [AM.ZK.Worker-pool2-t13] master.AssignmentManager: Znode test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb. deleted, state: {8e6786d5a1299d7b651eff93cf9ca5cb state=OPEN, ts=1390770471163, server=localhost,35894,1390770430440}
2014-01-26 22:07:51,378 INFO  [AM.ZK.Worker-pool2-t13] master.RegionStates: Onlined 8e6786d5a1299d7b651eff93cf9ca5cb on localhost,35894,1390770430440
dimanche 26 janvier 2014, 22:07:53 (UTC+0100) Stopping hbase (via master)
2014-01-26 22:08:25,009 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33422
2014-01-26 22:08:25,016 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:33422
2014-01-26 22:08:26,000 INFO  [SessionTracker] server.ZooKeeperServer: Expiring session 0x143d05e25a40005, timeout of 40000ms exceeded
2014-01-26 22:08:27,337 WARN  [SyncThread:0] persistence.FileTxnLog: fsync-ing the write ahead log in SyncThread:0 took 2320ms which will adversely effect operation latency. See the ZooKeeper troubleshooting guide
2014-01-26 22:08:27,343 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x143d05e25a40005
2014-01-26 22:08:27,345 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d05e25a40009 with negotiated timeout 40000 for client /127.0.0.1:33422
2014-01-26 22:08:27,906 INFO  [RpcServer.handler=13,port=51791] master.HMaster: Client=mojdeh//127.0.0.1 shutdown
2014-01-26 22:08:27,908 INFO  [RpcServer.handler=13,port=51791] master.HMaster: Cluster shutdown requested
2014-01-26 22:08:27,909 INFO  [M:0;localhost:51791] master.ServerManager: Waiting on regionserver(s) to go down localhost,35894,1390770430440
2014-01-26 22:08:27,909 INFO  [CatalogJanitor-localhost:51791] master.CatalogJanitor: CatalogJanitor-localhost:51791 exiting
2014-01-26 22:08:27,909 INFO  [localhost,51791,1390770268454-ClusterStatusChore] balancer.ClusterStatusChore: localhost,51791,1390770268454-ClusterStatusChore exiting
2014-01-26 22:08:27,909 INFO  [localhost,51791,1390770268454-BalancerChore] balancer.BalancerChore: localhost,51791,1390770268454-BalancerChore exiting
2014-01-26 22:08:28,001 INFO  [SessionTracker] server.ZooKeeperServer: Expiring session 0x143d05e25a40006, timeout of 40000ms exceeded
2014-01-26 22:08:28,001 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x143d05e25a40006
2014-01-26 22:08:28,060 INFO  [localhost,51791,1390770268454.splitLogManagerTimeoutMonitor] master.SplitLogManager$TimeoutMonitor: localhost,51791,1390770268454.splitLogManagerTimeoutMonitor exiting
2014-01-26 22:08:28,287 WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x143d05e25a40009, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:220)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:744)
2014-01-26 22:08:28,287 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:33422 which had sessionid 0x143d05e25a40009
2014-01-26 22:08:28,911 INFO  [M:0;localhost:51791] master.ServerManager: Waiting on regionserver(s) to go down localhost,35894,1390770430440
2014-01-26 22:08:29,146 INFO  [RS:0;localhost:35894] regionserver.HRegionServer: Closing user regions
2014-01-26 22:08:29,151 DEBUG [RS_CLOSE_REGION-localhost:35894-0] handler.CloseRegionHandler: Processing close of hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19.
2014-01-26 22:08:29,152 DEBUG [RS_CLOSE_REGION-localhost:35894-0] regionserver.HRegion: Closing hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19.: disabling compactions & flushes
2014-01-26 22:08:29,152 DEBUG [RS_CLOSE_REGION-localhost:35894-1] handler.CloseRegionHandler: Processing close of test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb.
2014-01-26 22:08:29,153 DEBUG [RS_CLOSE_REGION-localhost:35894-0] regionserver.HRegion: Updates disabled for region hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19.
2014-01-26 22:08:29,153 DEBUG [RS_CLOSE_REGION-localhost:35894-0] regionserver.HRegion: Started memstore flush for hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19., current region memstore size 344
2014-01-26 22:08:29,154 DEBUG [RS_CLOSE_REGION-localhost:35894-1] regionserver.HRegion: Closing test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb.: disabling compactions & flushes
2014-01-26 22:08:29,154 DEBUG [RS_CLOSE_REGION-localhost:35894-1] regionserver.HRegion: Updates disabled for region test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb.
2014-01-26 22:08:29,155 INFO  [StoreCloserThread-test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb.-1] regionserver.HStore: Closed c
2014-01-26 22:08:29,160 INFO  [RS_CLOSE_REGION-localhost:35894-1] regionserver.HRegion: Closed test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb.
2014-01-26 22:08:29,160 DEBUG [RS_CLOSE_REGION-localhost:35894-1] handler.CloseRegionHandler: Closed test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb.
2014-01-26 22:08:29,239 INFO  [RS_CLOSE_REGION-localhost:35894-0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4, memsize=344, hasBloomFilter=true, into tmp file file:/home/mojdeh/HBASE/hbase/data/hbase/namespace/15a4b862c6b279ff97f6704c95fa3d19/.tmp/3043bb9a547d49deb2c4fc2989675374
2014-01-26 22:08:29,256 DEBUG [RS_CLOSE_REGION-localhost:35894-0] regionserver.HRegionFileSystem: Committing store file file:/home/mojdeh/HBASE/hbase/data/hbase/namespace/15a4b862c6b279ff97f6704c95fa3d19/.tmp/3043bb9a547d49deb2c4fc2989675374 as file:/home/mojdeh/HBASE/hbase/data/hbase/namespace/15a4b862c6b279ff97f6704c95fa3d19/info/3043bb9a547d49deb2c4fc2989675374
2014-01-26 22:08:29,258 INFO  [RS_CLOSE_REGION-localhost:35894-0] regionserver.HStore: Added file:/home/mojdeh/HBASE/hbase/data/hbase/namespace/15a4b862c6b279ff97f6704c95fa3d19/info/3043bb9a547d49deb2c4fc2989675374, entries=2, sequenceid=4, filesize=1.0 K
2014-01-26 22:08:29,259 INFO  [RS_CLOSE_REGION-localhost:35894-0] regionserver.HRegion: Finished memstore flush of ~344/344, currentsize=0/0 for region hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19. in 106ms, sequenceid=4, compaction requested=false
2014-01-26 22:08:29,265 INFO  [StoreCloserThread-hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19.-1] regionserver.HStore: Closed info
2014-01-26 22:08:29,266 INFO  [RS_CLOSE_REGION-localhost:35894-0] regionserver.HRegion: Closed hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19.
2014-01-26 22:08:29,266 DEBUG [RS_CLOSE_REGION-localhost:35894-0] handler.CloseRegionHandler: Closed hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19.
2014-01-26 22:08:29,912 INFO  [M:0;localhost:51791] master.ServerManager: Waiting on regionserver(s) to go down localhost,35894,1390770430440
2014-01-26 22:08:30,913 INFO  [M:0;localhost:51791] master.ServerManager: Waiting on regionserver(s) to go down localhost,35894,1390770430440
2014-01-26 22:08:31,914 INFO  [M:0;localhost:51791] master.ServerManager: Waiting on regionserver(s) to go down localhost,35894,1390770430440
2014-01-26 22:08:32,158 DEBUG [RS:0;localhost:35894] regionserver.HRegionServer: Waiting on 1588230740
2014-01-26 22:08:32,916 INFO  [M:0;localhost:51791] master.ServerManager: Waiting on regionserver(s) to go down localhost,35894,1390770430440
2014-01-26 22:08:33,918 INFO  [M:0;localhost:51791] master.ServerManager: Waiting on regionserver(s) to go down localhost,35894,1390770430440
2014-01-26 22:08:34,920 INFO  [M:0;localhost:51791] master.ServerManager: Waiting on regionserver(s) to go down localhost,35894,1390770430440
2014-01-26 22:08:35,160 INFO  [RS:0;localhost:35894] regionserver.HRegionServer: STOPPED: Stopped; only catalog regions remaining online
2014-01-26 22:08:35,160 INFO  [RS:0;localhost:35894] ipc.RpcServer: Stopping server on 35894
2014-01-26 22:08:35,161 INFO  [RpcServer.handler=2,port=35894] ipc.RpcServer: RpcServer.handler=2,port=35894: exiting
2014-01-26 22:08:35,161 INFO  [RpcServer.handler=0,port=35894] ipc.RpcServer: RpcServer.handler=0,port=35894: exiting
2014-01-26 22:08:35,161 INFO  [Replication.RpcServer.handler=1,port=35894] ipc.RpcServer: Replication.RpcServer.handler=1,port=35894: exiting
2014-01-26 22:08:35,161 INFO  [RpcServer.handler=5,port=35894] ipc.RpcServer: RpcServer.handler=5,port=35894: exiting
2014-01-26 22:08:35,161 INFO  [Priority.RpcServer.handler=2,port=35894] ipc.RpcServer: Priority.RpcServer.handler=2,port=35894: exiting
2014-01-26 22:08:35,163 INFO  [Priority.RpcServer.handler=7,port=35894] ipc.RpcServer: Priority.RpcServer.handler=7,port=35894: exiting
2014-01-26 22:08:35,163 INFO  [Priority.RpcServer.handler=6,port=35894] ipc.RpcServer: Priority.RpcServer.handler=6,port=35894: exiting
2014-01-26 22:08:35,163 INFO  [RS:0;localhost:35894] regionserver.SplitLogWorker: Sending interrupt to stop the worker thread
2014-01-26 22:08:35,161 INFO  [Priority.RpcServer.handler=0,port=35894] ipc.RpcServer: Priority.RpcServer.handler=0,port=35894: exiting
2014-01-26 22:08:35,163 INFO  [RpcServer.handler=8,port=35894] ipc.RpcServer: RpcServer.handler=8,port=35894: exiting
2014-01-26 22:08:35,161 INFO  [RpcServer.handler=3,port=35894] ipc.RpcServer: RpcServer.handler=3,port=35894: exiting
2014-01-26 22:08:35,165 INFO  [RpcServer.handler=19,port=35894] ipc.RpcServer: RpcServer.handler=19,port=35894: exiting
2014-01-26 22:08:35,165 INFO  [RpcServer.handler=20,port=35894] ipc.RpcServer: RpcServer.handler=20,port=35894: exiting
2014-01-26 22:08:35,164 INFO  [RpcServer.handler=10,port=35894] ipc.RpcServer: RpcServer.handler=10,port=35894: exiting
2014-01-26 22:08:35,165 INFO  [RpcServer.handler=29,port=35894] ipc.RpcServer: RpcServer.handler=29,port=35894: exiting
2014-01-26 22:08:35,163 INFO  [SplitLogWorker-localhost,35894,1390770430440] regionserver.SplitLogWorker: SplitLogWorker interrupted while waiting for task, exiting: java.lang.InterruptedException
2014-01-26 22:08:35,166 INFO  [RpcServer.handler=18,port=35894] ipc.RpcServer: RpcServer.handler=18,port=35894: exiting
2014-01-26 22:08:35,163 INFO  [RS:0;localhost:35894] regionserver.HRegionServer: Stopping infoServer
2014-01-26 22:08:35,163 INFO  [RpcServer.handler=16,port=35894] ipc.RpcServer: RpcServer.handler=16,port=35894: exiting
2014-01-26 22:08:35,163 INFO  [RpcServer.handler=17,port=35894] ipc.RpcServer: RpcServer.handler=17,port=35894: exiting
2014-01-26 22:08:35,163 INFO  [RpcServer.handler=9,port=35894] ipc.RpcServer: RpcServer.handler=9,port=35894: exiting
2014-01-26 22:08:35,163 INFO  [RpcServer.handler=15,port=35894] ipc.RpcServer: RpcServer.handler=15,port=35894: exiting
2014-01-26 22:08:35,163 INFO  [Priority.RpcServer.handler=8,port=35894] ipc.RpcServer: Priority.RpcServer.handler=8,port=35894: exiting
2014-01-26 22:08:35,163 INFO  [RpcServer.handler=14,port=35894] ipc.RpcServer: RpcServer.handler=14,port=35894: exiting
2014-01-26 22:08:35,163 INFO  [Priority.RpcServer.handler=3,port=35894] ipc.RpcServer: Priority.RpcServer.handler=3,port=35894: exiting
2014-01-26 22:08:35,163 INFO  [Replication.RpcServer.handler=2,port=35894] ipc.RpcServer: Replication.RpcServer.handler=2,port=35894: exiting
2014-01-26 22:08:35,163 INFO  [RpcServer.handler=13,port=35894] ipc.RpcServer: RpcServer.handler=13,port=35894: exiting
2014-01-26 22:08:35,162 INFO  [Priority.RpcServer.handler=9,port=35894] ipc.RpcServer: Priority.RpcServer.handler=9,port=35894: exiting
2014-01-26 22:08:35,162 INFO  [RpcServer.handler=11,port=35894] ipc.RpcServer: RpcServer.handler=11,port=35894: exiting
2014-01-26 22:08:35,162 INFO  [Replication.RpcServer.handler=0,port=35894] ipc.RpcServer: Replication.RpcServer.handler=0,port=35894: exiting
2014-01-26 22:08:35,162 INFO  [Priority.RpcServer.handler=5,port=35894] ipc.RpcServer: Priority.RpcServer.handler=5,port=35894: exiting
2014-01-26 22:08:35,161 INFO  [RpcServer.listener,port=35894] ipc.RpcServer: RpcServer.listener,port=35894: stopping
2014-01-26 22:08:35,161 INFO  [RpcServer.handler=1,port=35894] ipc.RpcServer: RpcServer.handler=1,port=35894: exiting
2014-01-26 22:08:35,161 INFO  [Priority.RpcServer.handler=1,port=35894] ipc.RpcServer: Priority.RpcServer.handler=1,port=35894: exiting
2014-01-26 22:08:35,161 INFO  [RpcServer.handler=7,port=35894] ipc.RpcServer: RpcServer.handler=7,port=35894: exiting
2014-01-26 22:08:35,161 INFO  [Priority.RpcServer.handler=4,port=35894] ipc.RpcServer: Priority.RpcServer.handler=4,port=35894: exiting
2014-01-26 22:08:35,166 INFO  [RpcServer.handler=24,port=35894] ipc.RpcServer: RpcServer.handler=24,port=35894: exiting
2014-01-26 22:08:35,166 INFO  [SplitLogWorker-localhost,35894,1390770430440] regionserver.SplitLogWorker: SplitLogWorker localhost,35894,1390770430440 exiting
2014-01-26 22:08:35,166 INFO  [RpcServer.handler=22,port=35894] ipc.RpcServer: RpcServer.handler=22,port=35894: exiting
2014-01-26 22:08:35,166 INFO  [RpcServer.handler=6,port=35894] ipc.RpcServer: RpcServer.handler=6,port=35894: exiting
2014-01-26 22:08:35,166 INFO  [RpcServer.handler=4,port=35894] ipc.RpcServer: RpcServer.handler=4,port=35894: exiting
2014-01-26 22:08:35,165 INFO  [RpcServer.handler=26,port=35894] ipc.RpcServer: RpcServer.handler=26,port=35894: exiting
2014-01-26 22:08:35,165 INFO  [RpcServer.handler=28,port=35894] ipc.RpcServer: RpcServer.handler=28,port=35894: exiting
2014-01-26 22:08:35,165 INFO  [RpcServer.handler=25,port=35894] ipc.RpcServer: RpcServer.handler=25,port=35894: exiting
2014-01-26 22:08:35,165 INFO  [RpcServer.handler=27,port=35894] ipc.RpcServer: RpcServer.handler=27,port=35894: exiting
2014-01-26 22:08:35,165 INFO  [RpcServer.handler=23,port=35894] ipc.RpcServer: RpcServer.handler=23,port=35894: exiting
2014-01-26 22:08:35,165 INFO  [RpcServer.handler=21,port=35894] ipc.RpcServer: RpcServer.handler=21,port=35894: exiting
2014-01-26 22:08:35,165 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2014-01-26 22:08:35,165 INFO  [RpcServer.handler=12,port=35894] ipc.RpcServer: RpcServer.handler=12,port=35894: exiting
2014-01-26 22:08:35,173 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2014-01-26 22:08:35,171 INFO  [RS:0;localhost:35894] mortbay.log: Stopped SelectChannelConnector@0.0.0.0:60030
2014-01-26 22:08:35,275 INFO  [RS:0;localhost:35894] snapshot.RegionServerSnapshotManager: Stopping RegionServerSnapshotManager gracefully.
2014-01-26 22:08:35,275 INFO  [Thread-60] regionserver.MemStoreFlusher: Thread-60 exiting
2014-01-26 22:08:35,275 INFO  [RS:0;localhost:35894.compactionChecker] regionserver.HRegionServer$CompactionChecker: RS:0;localhost:35894.compactionChecker exiting
2014-01-26 22:08:35,275 INFO  [RS:0;localhost:35894.logRoller] regionserver.LogRoller: LogRoller exiting.
2014-01-26 22:08:35,275 INFO  [RS_OPEN_META-localhost:35894-0-MetaLogRoller] regionserver.LogRoller: LogRoller exiting.
2014-01-26 22:08:35,277 INFO  [RS:0;localhost:35894] regionserver.HRegionServer: stopping server localhost,35894,1390770430440
2014-01-26 22:08:35,277 DEBUG [RS:0;localhost:35894] catalog.CatalogTracker: Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@42e85a1
2014-01-26 22:08:35,278 INFO  [RS:0;localhost:35894] regionserver.CompactSplitThread: Waiting for Split Thread to finish...
2014-01-26 22:08:35,278 INFO  [RS:0;localhost:35894] regionserver.CompactSplitThread: Waiting for Merge Thread to finish...
2014-01-26 22:08:35,278 INFO  [RS:0;localhost:35894] regionserver.CompactSplitThread: Waiting for Large Compaction Thread to finish...
2014-01-26 22:08:35,278 INFO  [RS:0;localhost:35894] regionserver.CompactSplitThread: Waiting for Small Compaction Thread to finish...
2014-01-26 22:08:35,279 INFO  [RS:0;localhost:35894] regionserver.HRegionServer: Waiting on 1 regions to close
2014-01-26 22:08:35,280 DEBUG [RS:0;localhost:35894] regionserver.HRegionServer: {1588230740=hbase:meta,,1.1588230740}
2014-01-26 22:08:35,280 DEBUG [RS_CLOSE_META-localhost:35894-0] handler.CloseRegionHandler: Processing close of hbase:meta,,1.1588230740
2014-01-26 22:08:35,281 DEBUG [RS_CLOSE_META-localhost:35894-0] regionserver.HRegion: Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2014-01-26 22:08:35,281 DEBUG [RS_CLOSE_META-localhost:35894-0] regionserver.HRegion: Updates disabled for region hbase:meta,,1.1588230740
2014-01-26 22:08:35,281 DEBUG [RS_CLOSE_META-localhost:35894-0] regionserver.HRegion: Started memstore flush for hbase:meta,,1.1588230740, current region memstore size 1.9 K
2014-01-26 22:08:35,303 INFO  [RS_CLOSE_META-localhost:35894-0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6, memsize=1.9 K, hasBloomFilter=false, into tmp file file:/home/mojdeh/HBASE/hbase/data/hbase/meta/1588230740/.tmp/4f9ea84902aa4ab6949f71e9eed1785e
2014-01-26 22:08:35,311 DEBUG [RS_CLOSE_META-localhost:35894-0] regionserver.HRegionFileSystem: Committing store file file:/home/mojdeh/HBASE/hbase/data/hbase/meta/1588230740/.tmp/4f9ea84902aa4ab6949f71e9eed1785e as file:/home/mojdeh/HBASE/hbase/data/hbase/meta/1588230740/info/4f9ea84902aa4ab6949f71e9eed1785e
2014-01-26 22:08:35,316 INFO  [RS_CLOSE_META-localhost:35894-0] regionserver.HStore: Added file:/home/mojdeh/HBASE/hbase/data/hbase/meta/1588230740/info/4f9ea84902aa4ab6949f71e9eed1785e, entries=8, sequenceid=6, filesize=1.7 K
2014-01-26 22:08:35,316 INFO  [RS_CLOSE_META-localhost:35894-0] regionserver.HRegion: Finished memstore flush of ~1.9 K/1944, currentsize=0/0 for region hbase:meta,,1.1588230740 in 35ms, sequenceid=6, compaction requested=false
2014-01-26 22:08:35,321 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore: Closed info
2014-01-26 22:08:35,322 INFO  [RS_CLOSE_META-localhost:35894-0] regionserver.HRegion: Closed hbase:meta,,1.1588230740
2014-01-26 22:08:35,323 DEBUG [RS_CLOSE_META-localhost:35894-0] handler.CloseRegionHandler: Closed hbase:meta,,1.1588230740
2014-01-26 22:08:35,480 INFO  [RS:0;localhost:35894] regionserver.HRegionServer: stopping server localhost,35894,1390770430440; all regions closed.
2014-01-26 22:08:35,481 INFO  [RS_OPEN_META-localhost:35894-0.logSyncer] wal.FSHLog: RS_OPEN_META-localhost:35894-0.logSyncer exiting
2014-01-26 22:08:35,481 DEBUG [RS:0;localhost:35894] wal.FSHLog: Closing WAL writer in file:/home/mojdeh/HBASE/hbase/WALs/localhost,35894,1390770430440
2014-01-26 22:08:35,481 INFO  [RS:0;localhost:35894.logSyncer] wal.FSHLog: RS:0;localhost:35894.logSyncer exiting
2014-01-26 22:08:35,482 DEBUG [RS:0;localhost:35894] wal.FSHLog: Closing WAL writer in file:/home/mojdeh/HBASE/hbase/WALs/localhost,35894,1390770430440
2014-01-26 22:08:35,491 DEBUG [RS:0;localhost:35894] wal.FSHLog: Moved 2 WAL file(s) to /home/mojdeh/HBASE/hbase/oldWALs
2014-01-26 22:08:35,592 INFO  [RS:0;localhost:35894] regionserver.Leases: RS:0;localhost:35894 closing leases
2014-01-26 22:08:35,592 INFO  [RS:0;localhost:35894] regionserver.Leases: RS:0;localhost:35894 closed leases
2014-01-26 22:08:35,922 INFO  [M:0;localhost:51791] master.ServerManager: Waiting on regionserver(s) to go down localhost,35894,1390770430440
2014-01-26 22:08:36,924 INFO  [M:0;localhost:51791] master.ServerManager: Waiting on regionserver(s) to go down localhost,35894,1390770430440
2014-01-26 22:08:37,927 INFO  [M:0;localhost:51791] master.ServerManager: Waiting on regionserver(s) to go down localhost,35894,1390770430440
2014-01-26 22:08:38,928 INFO  [M:0;localhost:51791] master.ServerManager: Waiting on regionserver(s) to go down localhost,35894,1390770430440
2014-01-26 22:08:39,930 INFO  [M:0;localhost:51791] master.ServerManager: Waiting on regionserver(s) to go down localhost,35894,1390770430440
2014-01-26 22:08:40,932 INFO  [M:0;localhost:51791] master.ServerManager: Waiting on regionserver(s) to go down localhost,35894,1390770430440
2014-01-26 22:08:41,934 INFO  [M:0;localhost:51791] master.ServerManager: Waiting on regionserver(s) to go down localhost,35894,1390770430440
2014-01-26 22:08:42,758 INFO  [RS:0;localhost:35894.periodicFlusher] regionserver.HRegionServer$PeriodicMemstoreFlusher: RS:0;localhost:35894.periodicFlusher exiting
2014-01-26 22:08:42,758 INFO  [RS:0;localhost:35894.leaseChecker] regionserver.Leases: RS:0;localhost:35894.leaseChecker closing leases
2014-01-26 22:08:42,759 INFO  [RS:0;localhost:35894.leaseChecker] regionserver.Leases: RS:0;localhost:35894.leaseChecker closed leases
2014-01-26 22:08:42,923 INFO  [RS:0;localhost:35894] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x143d05e25a40008
2014-01-26 22:08:42,923 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x143d05e25a40008
2014-01-26 22:08:42,936 INFO  [M:0;localhost:51791] master.ServerManager: Waiting on regionserver(s) to go down localhost,35894,1390770430440
2014-01-26 22:08:43,031 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:33415 which had sessionid 0x143d05e25a40008
2014-01-26 22:08:43,031 INFO  [RS:0;localhost:35894] zookeeper.ZooKeeper: Session: 0x143d05e25a40008 closed
2014-01-26 22:08:43,031 INFO  [RS:0;localhost:35894-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-01-26 22:08:43,142 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [localhost,35894,1390770430440]
2014-01-26 22:08:43,143 INFO  [main-EventThread] master.ServerManager: Cluster shutdown set; localhost,35894,1390770430440 expired; onlineServers=0
2014-01-26 22:08:43,143 DEBUG [M:0;localhost:51791] master.HMaster: Stopping service threads
2014-01-26 22:08:43,143 INFO  [main-EventThread] master.HMaster: Cluster shutdown set; onlineServer=0
2014-01-26 22:08:43,143 INFO  [M:0;localhost:51791] ipc.RpcServer: Stopping server on 51791
2014-01-26 22:08:43,143 DEBUG [main-EventThread] catalog.CatalogTracker: Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@74e1d431
2014-01-26 22:08:43,144 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x143d05e25a40003
2014-01-26 22:08:43,144 INFO  [RpcServer.handler=0,port=51791] ipc.RpcServer: RpcServer.handler=0,port=51791: exiting
2014-01-26 22:08:43,144 INFO  [Replication.RpcServer.handler=1,port=51791] ipc.RpcServer: Replication.RpcServer.handler=1,port=51791: exiting
2014-01-26 22:08:43,144 INFO  [RpcServer.handler=5,port=51791] ipc.RpcServer: RpcServer.handler=5,port=51791: exiting
2014-01-26 22:08:43,144 INFO  [RpcServer.handler=17,port=51791] ipc.RpcServer: RpcServer.handler=17,port=51791: exiting
2014-01-26 22:08:43,144 INFO  [RpcServer.listener,port=51791] ipc.RpcServer: RpcServer.listener,port=51791: stopping
2014-01-26 22:08:43,145 INFO  [RpcServer.handler=24,port=51791] ipc.RpcServer: RpcServer.handler=24,port=51791: exiting
2014-01-26 22:08:43,145 INFO  [RpcServer.handler=3,port=51791] ipc.RpcServer: RpcServer.handler=3,port=51791: exiting
2014-01-26 22:08:43,145 INFO  [RpcServer.handler=1,port=51791] ipc.RpcServer: RpcServer.handler=1,port=51791: exiting
2014-01-26 22:08:43,145 INFO  [RpcServer.handler=6,port=51791] ipc.RpcServer: RpcServer.handler=6,port=51791: exiting
2014-01-26 22:08:43,145 INFO  [RpcServer.handler=8,port=51791] ipc.RpcServer: RpcServer.handler=8,port=51791: exiting
2014-01-26 22:08:43,145 INFO  [RpcServer.handler=10,port=51791] ipc.RpcServer: RpcServer.handler=10,port=51791: exiting
2014-01-26 22:08:43,145 INFO  [RpcServer.handler=28,port=51791] ipc.RpcServer: RpcServer.handler=28,port=51791: exiting
2014-01-26 22:08:43,146 INFO  [RpcServer.handler=15,port=51791] ipc.RpcServer: RpcServer.handler=15,port=51791: exiting
2014-01-26 22:08:43,145 INFO  [RpcServer.handler=23,port=51791] ipc.RpcServer: RpcServer.handler=23,port=51791: exiting
2014-01-26 22:08:43,145 INFO  [RpcServer.handler=22,port=51791] ipc.RpcServer: RpcServer.handler=22,port=51791: exiting
2014-01-26 22:08:43,144 INFO  [RpcServer.handler=20,port=51791] ipc.RpcServer: RpcServer.handler=20,port=51791: exiting
2014-01-26 22:08:43,144 INFO  [RpcServer.handler=18,port=51791] ipc.RpcServer: RpcServer.handler=18,port=51791: exiting
2014-01-26 22:08:43,144 INFO  [RpcServer.handler=11,port=51791] ipc.RpcServer: RpcServer.handler=11,port=51791: exiting
2014-01-26 22:08:43,144 INFO  [RpcServer.handler=13,port=51791] ipc.RpcServer: RpcServer.handler=13,port=51791: exiting
2014-01-26 22:08:43,144 INFO  [RpcServer.handler=9,port=51791] ipc.RpcServer: RpcServer.handler=9,port=51791: exiting
2014-01-26 22:08:43,144 INFO  [M:0;localhost:51791.archivedHFileCleaner] cleaner.HFileCleaner: M:0;localhost:51791.archivedHFileCleaner exiting
2014-01-26 22:08:43,144 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2014-01-26 22:08:43,144 INFO  [M:0;localhost:51791.oldLogCleaner] cleaner.LogCleaner: M:0;localhost:51791.oldLogCleaner exiting
2014-01-26 22:08:43,144 INFO  [M:0;localhost:51791] master.HMaster: Stopping infoServer
2014-01-26 22:08:43,144 INFO  [RpcServer.handler=7,port=51791] ipc.RpcServer: RpcServer.handler=7,port=51791: exiting
2014-01-26 22:08:43,144 INFO  [Replication.RpcServer.handler=2,port=51791] ipc.RpcServer: Replication.RpcServer.handler=2,port=51791: exiting
2014-01-26 22:08:43,144 INFO  [RpcServer.handler=4,port=51791] ipc.RpcServer: RpcServer.handler=4,port=51791: exiting
2014-01-26 22:08:43,144 INFO  [Replication.RpcServer.handler=0,port=51791] ipc.RpcServer: Replication.RpcServer.handler=0,port=51791: exiting
2014-01-26 22:08:43,251 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:33409 which had sessionid 0x143d05e25a40003
2014-01-26 22:08:43,251 INFO  [RS:0;localhost:35894-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-01-26 22:08:43,251 INFO  [RS:0;localhost:35894] zookeeper.ZooKeeper: Session: 0x143d05e25a40003 closed
2014-01-26 22:08:43,151 INFO  [M:0;localhost:51791] mortbay.log: Stopped SelectChannelConnector@0.0.0.0:60010
2014-01-26 22:08:43,148 INFO  [M:0;localhost:51791.oldLogCleaner] master.ReplicationLogCleaner: Stopping replicationLogCleaner-0x143d05e25a40007, quorum=localhost:2181, baseZNode=/hbase
2014-01-26 22:08:43,147 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2014-01-26 22:08:43,146 INFO  [RpcServer.handler=2,port=51791] ipc.RpcServer: RpcServer.handler=2,port=51791: exiting
2014-01-26 22:08:43,146 INFO  [RpcServer.handler=16,port=51791] ipc.RpcServer: RpcServer.handler=16,port=51791: exiting
2014-01-26 22:08:43,145 INFO  [RpcServer.handler=12,port=51791] ipc.RpcServer: RpcServer.handler=12,port=51791: exiting
2014-01-26 22:08:43,145 INFO  [RpcServer.handler=26,port=51791] ipc.RpcServer: RpcServer.handler=26,port=51791: exiting
2014-01-26 22:08:43,145 INFO  [RpcServer.handler=29,port=51791] ipc.RpcServer: RpcServer.handler=29,port=51791: exiting
2014-01-26 22:08:43,145 INFO  [RpcServer.handler=21,port=51791] ipc.RpcServer: RpcServer.handler=21,port=51791: exiting
2014-01-26 22:08:43,145 INFO  [RpcServer.handler=19,port=51791] ipc.RpcServer: RpcServer.handler=19,port=51791: exiting
2014-01-26 22:08:43,145 INFO  [RpcServer.handler=14,port=51791] ipc.RpcServer: RpcServer.handler=14,port=51791: exiting
2014-01-26 22:08:43,145 INFO  [RpcServer.handler=27,port=51791] ipc.RpcServer: RpcServer.handler=27,port=51791: exiting
2014-01-26 22:08:43,145 INFO  [RpcServer.handler=25,port=51791] ipc.RpcServer: RpcServer.handler=25,port=51791: exiting
2014-01-26 22:08:43,254 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x143d05e25a40007
2014-01-26 22:08:43,253 INFO  [RS:0;localhost:35894] regionserver.HRegionServer: stopping server localhost,35894,1390770430440; zookeeper connection closed.
2014-01-26 22:08:43,255 INFO  [RS:0;localhost:35894] regionserver.HRegionServer: RS:0;localhost:35894 exiting
2014-01-26 22:08:43,373 INFO  [M:0;localhost:51791.oldLogCleaner] zookeeper.ZooKeeper: Session: 0x143d05e25a40007 closed
2014-01-26 22:08:43,373 INFO  [M:0;localhost:51791-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-01-26 22:08:43,373 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:33413 which had sessionid 0x143d05e25a40007
2014-01-26 22:08:43,493 INFO  [M:0;localhost:51791] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x143d05e25a40004
2014-01-26 22:08:43,501 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x143d05e25a40004
2014-01-26 22:08:43,680 INFO  [M:0;localhost:51791] zookeeper.ZooKeeper: Session: 0x143d05e25a40004 closed
2014-01-26 22:08:43,680 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:33410 which had sessionid 0x143d05e25a40004
2014-01-26 22:08:43,680 INFO  [M:0;localhost:51791-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-01-26 22:08:43,681 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x143d05e25a40002
2014-01-26 22:08:43,832 INFO  [M:0;localhost:51791] zookeeper.ZooKeeper: Session: 0x143d05e25a40002 closed
2014-01-26 22:08:43,832 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-01-26 22:08:43,832 INFO  [M:0;localhost:51791] master.HMaster: HMaster main thread exiting
2014-01-26 22:08:43,832 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:33384 which had sessionid 0x143d05e25a40002
2014-01-26 22:08:43,832 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: NIOServerCnxn factory exited run method
2014-01-26 22:08:43,832 INFO  [M:0;localhost:51791] server.ZooKeeperServer: shutting down
2014-01-26 22:08:43,832 INFO  [M:0;localhost:51791] server.SessionTrackerImpl: Shutting down
2014-01-26 22:08:43,832 INFO  [M:0;localhost:51791] server.PrepRequestProcessor: Shutting down
2014-01-26 22:08:43,832 INFO  [M:0;localhost:51791] server.SyncRequestProcessor: Shutting down
2014-01-26 22:08:43,832 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: PrepRequestProcessor exited loop!
2014-01-26 22:08:43,833 INFO  [SyncThread:0] server.SyncRequestProcessor: SyncRequestProcessor exited!
2014-01-26 22:08:43,833 INFO  [M:0;localhost:51791] server.FinalRequestProcessor: shutdown of request processor complete
2014-01-26 22:08:43,834 INFO  [M:0;localhost:51791] zookeeper.MiniZooKeeperCluster: Shutdown MiniZK cluster with all ZK servers
2014-01-26 22:08:44,000 INFO  [SessionTracker] server.SessionTrackerImpl: SessionTrackerImpl exited loop!
2014-01-26 22:08:44,003 INFO  [Thread-5] regionserver.ShutdownHook: Shutdown hook starting; hbase.shutdown.hook=true; fsShutdownHook=org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer@797fc155
2014-01-26 22:08:44,003 INFO  [Thread-5] regionserver.HRegionServer: STOPPED: Shutdown hook
2014-01-26 22:08:44,003 INFO  [Thread-5] regionserver.ShutdownHook: Starting fs shutdown hook thread.
2014-01-26 22:08:44,004 INFO  [Thread-5] regionserver.ShutdownHook: Shutdown hook finished.
dimanche 26 janvier 2014, 22:08:49 (UTC+0100) Starting master on ubuntu
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 62986
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 62986
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-01-26 22:08:49,995 INFO  [main] util.VersionInfo: HBase 0.96.1.1-hadoop2
2014-01-26 22:08:49,995 INFO  [main] util.VersionInfo: Subversion file:///home/jon/proj/hbase-svn/hbase-0.96.1.1 -r Unknown
2014-01-26 22:08:49,995 INFO  [main] util.VersionInfo: Compiled by jon on Tue Dec 17 12:22:12 PST 2013
2014-01-26 22:08:50,211 INFO  [main] server.ZooKeeperServer: Server environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
2014-01-26 22:08:50,211 INFO  [main] server.ZooKeeperServer: Server environment:host.name=localhost
2014-01-26 22:08:50,211 INFO  [main] server.ZooKeeperServer: Server environment:java.version=1.7.0_51
2014-01-26 22:08:50,211 INFO  [main] server.ZooKeeperServer: Server environment:java.vendor=Oracle Corporation
2014-01-26 22:08:50,211 INFO  [main] server.ZooKeeperServer: Server environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
2014-01-26 22:08:50,211 INFO  [main] server.ZooKeeperServer: Server environment:java.class.path=/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../conf:/usr/lib/jvm/java-7-openjdk-amd64/lib/tools.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/..:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/activation-1.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/aopalliance-1.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/asm-3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/avro-1.7.4.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-beanutils-1.7.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-cli-1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-codec-1.7.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-collections-3.2.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-compress-1.4.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-configuration-1.6.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-daemon-1.0.13.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-digester-1.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-el-1.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-httpclient-3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-io-2.4.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-lang-2.6.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-logging-1.1.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-math-2.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-net-3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/core-3.1.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/gmbal-api-only-3.0.0-b023.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/grizzly-framework-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/grizzly-http-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/grizzly-http-server-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/grizzly-http-servlet-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/grizzly-rcm-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/guava-12.0.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/guice-3.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/guice-servlet-3.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-annotations-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-auth-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-client-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-common-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-hdfs-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-hdfs-2.2.0-tests.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-app-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-common-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-core-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-yarn-api-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-yarn-client-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-yarn-common-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-yarn-server-common-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hamcrest-core-1.3.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-client-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-common-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-common-0.96.1.1-hadoop2-tests.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-examples-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-hadoop2-compat-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-hadoop-compat-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-it-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-it-0.96.1.1-hadoop2-tests.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-prefix-tree-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-protocol-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-server-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-server-0.96.1.1-hadoop2-tests.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-shell-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-testing-util-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-thrift-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/high-scale-lib-1.1.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/htrace-core-2.01.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/httpclient-4.1.3.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/httpcore-4.1.3.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jackson-core-asl-1.8.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jackson-xc-1.8.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jamon-runtime-2.3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jasper-compiler-5.5.23.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jasper-runtime-5.5.23.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/javax.inject-1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/javax.servlet-3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/javax.servlet-api-3.0.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jaxb-api-2.2.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-client-1.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-core-1.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-grizzly2-1.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-guice-1.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-json-1.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-server-1.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-test-framework-core-1.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-test-framework-grizzly2-1.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jets3t-0.6.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jettison-1.3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jetty-6.1.26.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jetty-sslengine-6.1.26.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jetty-util-6.1.26.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jruby-complete-1.6.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jsch-0.1.42.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jsp-2.1-6.1.14.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jsp-api-2.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jsr305-1.3.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/junit-4.11.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/libthrift-0.9.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/log4j-1.2.17.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/management-api-3.0.0-b012.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/metrics-core-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/netty-3.6.6.Final.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/paranamer-2.3.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/protobuf-java-2.5.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/servlet-api-2.5.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/slf4j-api-1.6.4.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/snappy-java-1.0.4.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/stax-api-1.0.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/xmlenc-0.52.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/xz-1.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/zookeeper-3.4.5.jar:
2014-01-26 22:08:50,211 INFO  [main] server.ZooKeeperServer: Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2014-01-26 22:08:50,211 INFO  [main] server.ZooKeeperServer: Server environment:java.io.tmpdir=/tmp
2014-01-26 22:08:50,211 INFO  [main] server.ZooKeeperServer: Server environment:java.compiler=<NA>
2014-01-26 22:08:50,212 INFO  [main] server.ZooKeeperServer: Server environment:os.name=Linux
2014-01-26 22:08:50,212 INFO  [main] server.ZooKeeperServer: Server environment:os.arch=amd64
2014-01-26 22:08:50,212 INFO  [main] server.ZooKeeperServer: Server environment:os.version=3.8.0-29-generic
2014-01-26 22:08:50,212 INFO  [main] server.ZooKeeperServer: Server environment:user.name=mojdeh
2014-01-26 22:08:50,212 INFO  [main] server.ZooKeeperServer: Server environment:user.home=/home/mojdeh
2014-01-26 22:08:50,212 INFO  [main] server.ZooKeeperServer: Server environment:user.dir=/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2
2014-01-26 22:08:50,227 INFO  [main] server.ZooKeeperServer: Created server with tickTime 2000 minSessionTimeout 4000 maxSessionTimeout 40000 datadir /home/mojdeh/HBASE/zookeeper/zookeeper_0/version-2 snapdir /home/mojdeh/HBASE/zookeeper/zookeeper_0/version-2
2014-01-26 22:08:50,241 INFO  [main] server.NIOServerCnxnFactory: binding to port 0.0.0.0/0.0.0.0:2181
2014-01-26 22:08:50,247 INFO  [main] persistence.FileTxnSnapLog: Snapshotting: 0x0 to /home/mojdeh/HBASE/zookeeper/zookeeper_0/version-2/snapshot.0
2014-01-26 22:08:50,318 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33425
2014-01-26 22:08:50,325 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Processing stat command from /127.0.0.1:33425
2014-01-26 22:08:50,328 INFO  [Thread-1] server.NIOServerCnxn: Stat command output
2014-01-26 22:08:50,328 INFO  [Thread-1] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:33425 (no session established for client)
2014-01-26 22:08:50,329 INFO  [main] zookeeper.MiniZooKeeperCluster: Started MiniZK Cluster and connect 1 ZK server on client port: 2181
2014-01-26 22:08:50,439 DEBUG [main] master.HMaster: master/localhost/127.0.0.1:0 HConnection server-to-server retries=350
2014-01-26 22:08:50,614 INFO  [main] ipc.RpcServer: master/localhost/127.0.0.1:0: started 10 reader(s).
2014-01-26 22:08:50,700 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-01-26 22:08:50,728 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-01-26 22:08:50,729 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-01-26 22:09:21,127 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-01-26 22:09:21,224 INFO  [main] master.HMaster: hbase.rootdir=file:/home/mojdeh/HBASE/hbase, hbase.cluster.distributed=false
2014-01-26 22:09:21,230 INFO  [main] Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2014-01-26 22:09:21,285 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
2014-01-26 22:09:21,285 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=localhost
2014-01-26 22:09:21,285 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_51
2014-01-26 22:09:21,285 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2014-01-26 22:09:21,285 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
2014-01-26 22:09:21,285 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../conf:/usr/lib/jvm/java-7-openjdk-amd64/lib/tools.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/..:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/activation-1.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/aopalliance-1.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/asm-3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/avro-1.7.4.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-beanutils-1.7.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-beanutils-core-1.8.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-cli-1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-codec-1.7.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-collections-3.2.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-compress-1.4.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-configuration-1.6.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-daemon-1.0.13.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-digester-1.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-el-1.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-httpclient-3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-io-2.4.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-lang-2.6.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-logging-1.1.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-math-2.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/commons-net-3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/core-3.1.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/findbugs-annotations-1.3.9-1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/gmbal-api-only-3.0.0-b023.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/grizzly-framework-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/grizzly-http-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/grizzly-http-server-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/grizzly-http-servlet-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/grizzly-rcm-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/guava-12.0.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/guice-3.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/guice-servlet-3.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-annotations-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-auth-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-client-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-common-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-hdfs-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-hdfs-2.2.0-tests.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-app-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-common-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-core-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-yarn-api-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-yarn-client-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-yarn-common-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-yarn-server-common-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hamcrest-core-1.3.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-client-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-common-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-common-0.96.1.1-hadoop2-tests.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-examples-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-hadoop2-compat-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-hadoop-compat-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-it-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-it-0.96.1.1-hadoop2-tests.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-prefix-tree-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-protocol-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-server-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-server-0.96.1.1-hadoop2-tests.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-shell-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-testing-util-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/hbase-thrift-0.96.1.1-hadoop2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/high-scale-lib-1.1.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/htrace-core-2.01.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/httpclient-4.1.3.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/httpcore-4.1.3.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jackson-core-asl-1.8.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jackson-jaxrs-1.8.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jackson-mapper-asl-1.8.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jackson-xc-1.8.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jamon-runtime-2.3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jasper-compiler-5.5.23.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jasper-runtime-5.5.23.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/javax.inject-1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/javax.servlet-3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/javax.servlet-api-3.0.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jaxb-api-2.2.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jaxb-impl-2.2.3-1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-client-1.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-core-1.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-grizzly2-1.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-guice-1.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-json-1.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-server-1.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-test-framework-core-1.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jersey-test-framework-grizzly2-1.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jets3t-0.6.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jettison-1.3.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jetty-6.1.26.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jetty-sslengine-6.1.26.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jetty-util-6.1.26.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jruby-complete-1.6.8.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jsch-0.1.42.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jsp-2.1-6.1.14.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jsp-api-2.1-6.1.14.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jsp-api-2.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/jsr305-1.3.9.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/junit-4.11.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/libthrift-0.9.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/log4j-1.2.17.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/management-api-3.0.0-b012.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/metrics-core-2.1.2.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/netty-3.6.6.Final.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/paranamer-2.3.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/protobuf-java-2.5.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/servlet-api-2.5-6.1.14.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/servlet-api-2.5.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/slf4j-api-1.6.4.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/slf4j-log4j12-1.6.4.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/snappy-java-1.0.4.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/stax-api-1.0.1.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/xmlenc-0.52.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/xz-1.0.jar:/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2/bin/../lib/zookeeper-3.4.5.jar:
2014-01-26 22:09:21,285 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2014-01-26 22:09:21,285 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-01-26 22:09:21,285 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-01-26 22:09:21,285 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-01-26 22:09:21,285 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-01-26 22:09:21,285 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=3.8.0-29-generic
2014-01-26 22:09:21,285 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=mojdeh
2014-01-26 22:09:21,285 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/mojdeh
2014-01-26 22:09:21,285 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/home/mojdeh/workspace/GDC/hbase-0.96.0-hadoop2
2014-01-26 22:09:21,286 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=master:32785, quorum=localhost:2181, baseZNode=/hbase
2014-01-26 22:09:21,300 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:32785 connecting to ZooKeeper ensemble=localhost:2181
2014-01-26 22:09:21,301 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2014-01-26 22:09:21,301 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33456
2014-01-26 22:09:21,302 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2014-01-26 22:09:21,304 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:33456
2014-01-26 22:09:21,306 INFO  [SyncThread:0] persistence.FileTxnLog: Creating new log file: log.1
2014-01-26 22:09:21,762 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d06227cc0000 with negotiated timeout 40000 for client /127.0.0.1:33456
2014-01-26 22:09:21,763 INFO  [main-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x143d06227cc0000, negotiated timeout = 40000
2014-01-26 22:09:23,024 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-01-26 22:09:23,024 INFO  [RpcServer.listener,port=32785] ipc.RpcServer: RpcServer.listener,port=32785: starting
2014-01-26 22:09:23,034 INFO  [RpcServer.handler=0,port=32785] ipc.RpcServer: RpcServer.handler=0,port=32785: starting
2014-01-26 22:09:23,034 INFO  [RpcServer.handler=1,port=32785] ipc.RpcServer: RpcServer.handler=1,port=32785: starting
2014-01-26 22:09:23,034 INFO  [RpcServer.handler=2,port=32785] ipc.RpcServer: RpcServer.handler=2,port=32785: starting
2014-01-26 22:09:23,035 INFO  [RpcServer.handler=3,port=32785] ipc.RpcServer: RpcServer.handler=3,port=32785: starting
2014-01-26 22:09:23,035 INFO  [RpcServer.handler=4,port=32785] ipc.RpcServer: RpcServer.handler=4,port=32785: starting
2014-01-26 22:09:23,035 INFO  [RpcServer.handler=5,port=32785] ipc.RpcServer: RpcServer.handler=5,port=32785: starting
2014-01-26 22:09:23,035 INFO  [RpcServer.handler=6,port=32785] ipc.RpcServer: RpcServer.handler=6,port=32785: starting
2014-01-26 22:09:23,035 INFO  [RpcServer.handler=7,port=32785] ipc.RpcServer: RpcServer.handler=7,port=32785: starting
2014-01-26 22:09:23,036 INFO  [RpcServer.handler=8,port=32785] ipc.RpcServer: RpcServer.handler=8,port=32785: starting
2014-01-26 22:09:23,036 INFO  [RpcServer.handler=9,port=32785] ipc.RpcServer: RpcServer.handler=9,port=32785: starting
2014-01-26 22:09:23,036 INFO  [RpcServer.handler=10,port=32785] ipc.RpcServer: RpcServer.handler=10,port=32785: starting
2014-01-26 22:09:23,036 INFO  [RpcServer.handler=11,port=32785] ipc.RpcServer: RpcServer.handler=11,port=32785: starting
2014-01-26 22:09:23,036 INFO  [RpcServer.handler=12,port=32785] ipc.RpcServer: RpcServer.handler=12,port=32785: starting
2014-01-26 22:09:23,037 INFO  [RpcServer.handler=13,port=32785] ipc.RpcServer: RpcServer.handler=13,port=32785: starting
2014-01-26 22:09:23,037 INFO  [RpcServer.handler=14,port=32785] ipc.RpcServer: RpcServer.handler=14,port=32785: starting
2014-01-26 22:09:23,039 INFO  [RpcServer.handler=15,port=32785] ipc.RpcServer: RpcServer.handler=15,port=32785: starting
2014-01-26 22:09:23,040 INFO  [Replication.RpcServer.handler=2,port=32785] ipc.RpcServer: Replication.RpcServer.handler=2,port=32785: starting
2014-01-26 22:09:23,040 INFO  [Replication.RpcServer.handler=1,port=32785] ipc.RpcServer: Replication.RpcServer.handler=1,port=32785: starting
2014-01-26 22:09:23,040 INFO  [Replication.RpcServer.handler=0,port=32785] ipc.RpcServer: Replication.RpcServer.handler=0,port=32785: starting
2014-01-26 22:09:23,040 INFO  [RpcServer.handler=29,port=32785] ipc.RpcServer: RpcServer.handler=29,port=32785: starting
2014-01-26 22:09:23,040 INFO  [RpcServer.handler=28,port=32785] ipc.RpcServer: RpcServer.handler=28,port=32785: starting
2014-01-26 22:09:23,040 INFO  [RpcServer.handler=27,port=32785] ipc.RpcServer: RpcServer.handler=27,port=32785: starting
2014-01-26 22:09:23,040 INFO  [RpcServer.handler=26,port=32785] ipc.RpcServer: RpcServer.handler=26,port=32785: starting
2014-01-26 22:09:23,040 INFO  [RpcServer.handler=25,port=32785] ipc.RpcServer: RpcServer.handler=25,port=32785: starting
2014-01-26 22:09:23,039 INFO  [RpcServer.handler=24,port=32785] ipc.RpcServer: RpcServer.handler=24,port=32785: starting
2014-01-26 22:09:23,039 INFO  [RpcServer.handler=23,port=32785] ipc.RpcServer: RpcServer.handler=23,port=32785: starting
2014-01-26 22:09:23,039 INFO  [RpcServer.handler=22,port=32785] ipc.RpcServer: RpcServer.handler=22,port=32785: starting
2014-01-26 22:09:23,039 INFO  [RpcServer.handler=21,port=32785] ipc.RpcServer: RpcServer.handler=21,port=32785: starting
2014-01-26 22:09:23,039 INFO  [RpcServer.handler=20,port=32785] ipc.RpcServer: RpcServer.handler=20,port=32785: starting
2014-01-26 22:09:23,039 INFO  [RpcServer.handler=19,port=32785] ipc.RpcServer: RpcServer.handler=19,port=32785: starting
2014-01-26 22:09:23,039 INFO  [RpcServer.handler=18,port=32785] ipc.RpcServer: RpcServer.handler=18,port=32785: starting
2014-01-26 22:09:23,039 INFO  [RpcServer.handler=17,port=32785] ipc.RpcServer: RpcServer.handler=17,port=32785: starting
2014-01-26 22:09:23,039 INFO  [RpcServer.handler=16,port=32785] ipc.RpcServer: RpcServer.handler=16,port=32785: starting
2014-01-26 22:09:23,089 DEBUG [main] regionserver.HRegionServer: regionserver/localhost/127.0.0.1:0 HConnection server-to-server retries=350
2014-01-26 22:09:23,093 INFO  [main] ipc.RpcServer: regionserver/localhost/127.0.0.1:0: started 10 reader(s).
2014-01-26 22:09:23,172 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 386.7 M
2014-01-26 22:09:23,228 INFO  [M:0;localhost:32785] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-01-26 22:09:23,272 INFO  [M:0;localhost:32785] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-01-26 22:09:23,274 INFO  [M:0;localhost:32785] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2014-01-26 22:09:23,275 INFO  [M:0;localhost:32785] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-01-26 22:09:23,281 INFO  [M:0;localhost:32785] http.HttpServer: Jetty bound to port 60010
2014-01-26 22:09:23,281 INFO  [M:0;localhost:32785] mortbay.log: jetty-6.1.26
2014-01-26 22:09:23,581 INFO  [M:0;localhost:32785] mortbay.log: Started SelectChannelConnector@0.0.0.0:60010
2014-01-26 22:09:23,904 INFO  [M:0;localhost:32785] master.ActiveMasterManager: Registered Active Master=localhost,32785,1390770530870
2014-01-26 22:09:23,906 DEBUG [main-EventThread] master.ActiveMasterManager: A master is now available
2014-01-26 22:09:23,909 INFO  [M:0;localhost:32785] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2014-01-26 22:09:23,965 INFO  [M:0;localhost:32785] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2014-01-26 22:09:23,985 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:RS:0;localhost:37220
2014-01-26 22:09:24,006 INFO  [RS:0;localhost:37220] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=regionserver:37220, quorum=localhost:2181, baseZNode=/hbase
2014-01-26 22:09:24,007 INFO  [RS:0;localhost:37220] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:37220 connecting to ZooKeeper ensemble=localhost:2181
2014-01-26 22:09:24,010 INFO  [RS:0;localhost:37220-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2014-01-26 22:09:24,010 INFO  [RS:0;localhost:37220-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2014-01-26 22:09:24,010 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33459
2014-01-26 22:09:24,011 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:33459
2014-01-26 22:09:24,042 DEBUG [M:0;localhost:32785] util.FSTableDescriptors: Current tableInfoPath = file:/home/mojdeh/HBASE/hbase/data/hbase/meta/.tabledesc/.tableinfo.0000000001
2014-01-26 22:09:24,053 DEBUG [M:0;localhost:32785] util.FSTableDescriptors: TableInfo already exists.. Skipping creation
2014-01-26 22:09:24,060 DEBUG [M:0;localhost:32785] fs.HFileSystem: The file system is not a DistributedFileSystem. Skipping on block location reordering
2014-01-26 22:09:24,065 INFO  [M:0;localhost:32785] master.SplitLogManager: Timeout=120000, unassigned timeout=180000, distributedLogReplay=false
2014-01-26 22:09:24,127 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d06227cc0001 with negotiated timeout 40000 for client /127.0.0.1:33459
2014-01-26 22:09:24,127 INFO  [RS:0;localhost:37220-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x143d06227cc0001, negotiated timeout = 40000
2014-01-26 22:09:24,127 INFO  [M:0;localhost:32785] master.SplitLogManager: Found 0 orphan tasks and 0 rescan nodes
2014-01-26 22:09:24,200 INFO  [M:0;localhost:32785] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x6d8983ce, quorum=localhost:2181, baseZNode=/hbase
2014-01-26 22:09:24,201 INFO  [M:0;localhost:32785] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x6d8983ce connecting to ZooKeeper ensemble=localhost:2181
2014-01-26 22:09:24,201 INFO  [M:0;localhost:32785-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2014-01-26 22:09:24,202 INFO  [M:0;localhost:32785-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2014-01-26 22:09:24,202 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33460
2014-01-26 22:09:24,202 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:33460
2014-01-26 22:09:24,248 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d06227cc0002 with negotiated timeout 40000 for client /127.0.0.1:33460
2014-01-26 22:09:24,248 INFO  [M:0;localhost:32785-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x143d06227cc0002, negotiated timeout = 40000
2014-01-26 22:09:24,267 DEBUG [M:0;localhost:32785] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@145db24a
2014-01-26 22:09:24,425 INFO  [M:0;localhost:32785] master.HMaster: Server active/primary master=localhost,32785,1390770530870, sessionid=0x143d06227cc0000, setting cluster-up flag (Was=false)
2014-01-26 22:09:24,425 DEBUG [RS:0;localhost:37220] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@21d4704a
2014-01-26 22:09:24,427 INFO  [RS:0;localhost:37220] regionserver.HRegionServer: ClusterId : 7e21e55a-7634-4277-b78f-fbccc8d4184c
2014-01-26 22:09:24,434 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x143d06227cc0001 type:create cxid:0x8 zxid:0x10 txntype:-1 reqpath:n/a Error Path:/hbase/online-snapshot Error:KeeperErrorCode = NoNode for /hbase/online-snapshot
2014-01-26 22:09:24,439 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x143d06227cc0000 type:create cxid:0x24 zxid:0x11 txntype:-1 reqpath:n/a Error Path:/hbase/online-snapshot Error:KeeperErrorCode = NoNode for /hbase/online-snapshot
2014-01-26 22:09:24,572 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x143d06227cc0000 type:create cxid:0x25 zxid:0x13 txntype:-1 reqpath:n/a Error Path:/hbase/online-snapshot Error:KeeperErrorCode = NodeExists for /hbase/online-snapshot
2014-01-26 22:09:24,674 INFO  [M:0;localhost:32785] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot already exists and this is not a retry
2014-01-26 22:09:24,674 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x143d06227cc0000 type:create cxid:0x26 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/hbase/online-snapshot/acquired Error:KeeperErrorCode = NodeExists for /hbase/online-snapshot/acquired
2014-01-26 22:09:24,770 INFO  [M:0;localhost:32785] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2014-01-26 22:09:24,936 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x143d06227cc0000 type:create cxid:0x29 zxid:0x18 txntype:-1 reqpath:n/a Error Path:/hbase/online-snapshot/abort Error:KeeperErrorCode = NodeExists for /hbase/online-snapshot/abort
2014-01-26 22:09:25,001 INFO  [RS:0;localhost:37220] regionserver.MemStoreFlusher: globalMemStoreLimit=386.7 M, globalMemStoreLimitLowMark=367.3 M, maxHeap=966.7 M
2014-01-26 22:09:25,006 INFO  [RS:0;localhost:37220] regionserver.HRegionServer: CompactionChecker runs every 10sec
2014-01-26 22:09:25,072 INFO  [M:0;localhost:32785] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/abort already exists and this is not a retry
2014-01-26 22:09:25,072 INFO  [M:0;localhost:32785] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2014-01-26 22:09:25,096 DEBUG [M:0;localhost:32785] procedure.ZKProcedureCoordinatorRpcs: Starting the controller for procedure member:localhost,32785,1390770530870
2014-01-26 22:09:25,098 INFO  [RS:0;localhost:37220] regionserver.HRegionServer: reportForDuty to master=localhost,32785,1390770530870 with port=37220, startcode=1390770563168
2014-01-26 22:09:25,104 DEBUG [M:0;localhost:32785] executor.ExecutorService: Starting executor service name=MASTER_OPEN_REGION-localhost:32785, corePoolSize=5, maxPoolSize=5
2014-01-26 22:09:25,104 DEBUG [M:0;localhost:32785] executor.ExecutorService: Starting executor service name=MASTER_CLOSE_REGION-localhost:32785, corePoolSize=5, maxPoolSize=5
2014-01-26 22:09:25,104 DEBUG [M:0;localhost:32785] executor.ExecutorService: Starting executor service name=MASTER_SERVER_OPERATIONS-localhost:32785, corePoolSize=5, maxPoolSize=5
2014-01-26 22:09:25,104 DEBUG [M:0;localhost:32785] executor.ExecutorService: Starting executor service name=MASTER_META_SERVER_OPERATIONS-localhost:32785, corePoolSize=5, maxPoolSize=5
2014-01-26 22:09:25,104 DEBUG [M:0;localhost:32785] executor.ExecutorService: Starting executor service name=M_LOG_REPLAY_OPS-localhost:32785, corePoolSize=10, maxPoolSize=10
2014-01-26 22:09:25,104 DEBUG [M:0;localhost:32785] executor.ExecutorService: Starting executor service name=MASTER_TABLE_OPERATIONS-localhost:32785, corePoolSize=1, maxPoolSize=1
2014-01-26 22:09:25,106 DEBUG [M:0;localhost:32785] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner
2014-01-26 22:09:25,109 INFO  [M:0;localhost:32785] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=replicationLogCleaner, quorum=localhost:2181, baseZNode=/hbase
2014-01-26 22:09:25,109 INFO  [M:0;localhost:32785] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=localhost:2181
2014-01-26 22:09:25,109 INFO  [M:0;localhost:32785-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2014-01-26 22:09:25,109 INFO  [M:0;localhost:32785-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2014-01-26 22:09:25,110 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33464
2014-01-26 22:09:25,110 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:33464
2014-01-26 22:09:25,241 DEBUG [RS:0;localhost:37220] regionserver.HRegionServer: Master is not running yet
2014-01-26 22:09:25,241 WARN  [RS:0;localhost:37220] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2014-01-26 22:09:25,302 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d06227cc0003 with negotiated timeout 40000 for client /127.0.0.1:33464
2014-01-26 22:09:25,302 INFO  [M:0;localhost:32785-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x143d06227cc0003, negotiated timeout = 40000
2014-01-26 22:09:25,302 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x143d06227cc0003 type:create cxid:0x1 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/hbase/replication Error:KeeperErrorCode = NoNode for /hbase/replication
2014-01-26 22:09:25,552 DEBUG [M:0;localhost:32785] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner
2014-01-26 22:09:25,559 DEBUG [M:0;localhost:32785] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotLogCleaner
2014-01-26 22:09:25,560 DEBUG [M:0;localhost:32785] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner
2014-01-26 22:09:25,561 DEBUG [M:0;localhost:32785] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner
2014-01-26 22:09:25,562 DEBUG [M:0;localhost:32785] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner
2014-01-26 22:09:25,563 INFO  [M:0;localhost:32785] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-01-26 22:09:27,066 INFO  [M:0;localhost:32785] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 1503 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-01-26 22:09:28,241 INFO  [RS:0;localhost:37220] regionserver.HRegionServer: reportForDuty to master=localhost,32785,1390770530870 with port=37220, startcode=1390770563168
2014-01-26 22:09:28,248 INFO  [RpcServer.handler=2,port=32785] master.ServerManager: Registering server=localhost,37220,1390770563168
2014-01-26 22:09:28,258 INFO  [RpcServer.handler=2,port=32785] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2014-01-26 22:09:28,260 DEBUG [RS:0;localhost:37220] regionserver.HRegionServer: Config from master: hbase.rootdir=/home/mojdeh/HBASE/hbase
2014-01-26 22:09:28,260 DEBUG [RS:0;localhost:37220] regionserver.HRegionServer: Config from master: fs.default.name=file:/
2014-01-26 22:09:28,261 DEBUG [RS:0;localhost:37220] fs.HFileSystem: The file system is not a DistributedFileSystem. Skipping on block location reordering
2014-01-26 22:09:28,263 DEBUG [RS:0;localhost:37220] regionserver.HRegionServer: logdir=file:/home/mojdeh/HBASE/hbase/WALs/localhost,37220,1390770563168
2014-01-26 22:09:28,270 INFO  [M:0;localhost:32785] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 2707 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-01-26 22:09:28,359 DEBUG [RS:0;localhost:37220] regionserver.Replication: ReplicationStatisticsThread 300
2014-01-26 22:09:28,373 INFO  [RS:0;localhost:37220] wal.FSHLog: WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true, optionallogflushinternal=1000ms
2014-01-26 22:09:28,398 INFO  [RS:0;localhost:37220] wal.FSHLog: New WAL /home/mojdeh/HBASE/hbase/WALs/localhost,37220,1390770563168/localhost%2C37220%2C1390770563168.1390770568374
2014-01-26 22:09:28,398 INFO  [RS:0;localhost:37220] wal.FSHLog: FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2014-01-26 22:09:28,404 INFO  [RS:0;localhost:37220] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2014-01-26 22:09:28,408 DEBUG [RS:0;localhost:37220] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-localhost:37220, corePoolSize=3, maxPoolSize=3
2014-01-26 22:09:28,408 DEBUG [RS:0;localhost:37220] executor.ExecutorService: Starting executor service name=RS_OPEN_META-localhost:37220, corePoolSize=1, maxPoolSize=1
2014-01-26 22:09:28,409 DEBUG [RS:0;localhost:37220] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-localhost:37220, corePoolSize=3, maxPoolSize=3
2014-01-26 22:09:28,409 DEBUG [RS:0;localhost:37220] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-localhost:37220, corePoolSize=1, maxPoolSize=1
2014-01-26 22:09:28,409 DEBUG [RS:0;localhost:37220] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-localhost:37220, corePoolSize=2, maxPoolSize=2
2014-01-26 22:09:28,410 INFO  [RS:0;localhost:37220] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-01-26 22:09:28,411 INFO  [RS:0;localhost:37220] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context regionserver
2014-01-26 22:09:28,411 INFO  [RS:0;localhost:37220] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-01-26 22:09:28,415 INFO  [RS:0;localhost:37220] http.HttpServer: Jetty bound to port 60030
2014-01-26 22:09:28,415 INFO  [RS:0;localhost:37220] mortbay.log: jetty-6.1.26
2014-01-26 22:09:28,515 INFO  [RS:0;localhost:37220] mortbay.log: Started SelectChannelConnector@0.0.0.0:60030
2014-01-26 22:09:28,517 INFO  [RS:0;localhost:37220] regionserver.ReplicationSourceManager: Current list of replicators: [localhost,37220,1390770563168] other RSs: [localhost,37220,1390770563168]
2014-01-26 22:09:28,537 INFO  [RS:0;localhost:37220] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2014-01-26 22:09:28,543 INFO  [RS:0;localhost:37220] zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x6cbe5e69, quorum=localhost:2181, baseZNode=/hbase
2014-01-26 22:09:28,544 INFO  [RS:0;localhost:37220] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x6cbe5e69 connecting to ZooKeeper ensemble=localhost:2181
2014-01-26 22:09:28,544 INFO  [RS:0;localhost:37220-SendThread(localhost:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2014-01-26 22:09:28,544 INFO  [RS:0;localhost:37220-SendThread(localhost:2181)] zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
2014-01-26 22:09:28,544 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33465
2014-01-26 22:09:28,545 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:33465
2014-01-26 22:09:28,570 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d06227cc0004 with negotiated timeout 40000 for client /127.0.0.1:33465
2014-01-26 22:09:28,570 INFO  [RS:0;localhost:37220-SendThread(localhost:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x143d06227cc0004, negotiated timeout = 40000
2014-01-26 22:09:28,573 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-01-26 22:09:28,573 INFO  [RpcServer.listener,port=37220] ipc.RpcServer: RpcServer.listener,port=37220: starting
2014-01-26 22:09:28,574 INFO  [RpcServer.handler=0,port=37220] ipc.RpcServer: RpcServer.handler=0,port=37220: starting
2014-01-26 22:09:28,574 INFO  [RpcServer.handler=1,port=37220] ipc.RpcServer: RpcServer.handler=1,port=37220: starting
2014-01-26 22:09:28,574 INFO  [RpcServer.handler=2,port=37220] ipc.RpcServer: RpcServer.handler=2,port=37220: starting
2014-01-26 22:09:28,574 INFO  [RpcServer.handler=3,port=37220] ipc.RpcServer: RpcServer.handler=3,port=37220: starting
2014-01-26 22:09:28,574 INFO  [RpcServer.handler=4,port=37220] ipc.RpcServer: RpcServer.handler=4,port=37220: starting
2014-01-26 22:09:28,574 INFO  [RpcServer.handler=5,port=37220] ipc.RpcServer: RpcServer.handler=5,port=37220: starting
2014-01-26 22:09:28,574 INFO  [RpcServer.handler=6,port=37220] ipc.RpcServer: RpcServer.handler=6,port=37220: starting
2014-01-26 22:09:28,574 INFO  [RpcServer.handler=7,port=37220] ipc.RpcServer: RpcServer.handler=7,port=37220: starting
2014-01-26 22:09:28,574 INFO  [RpcServer.handler=8,port=37220] ipc.RpcServer: RpcServer.handler=8,port=37220: starting
2014-01-26 22:09:28,575 INFO  [RpcServer.handler=9,port=37220] ipc.RpcServer: RpcServer.handler=9,port=37220: starting
2014-01-26 22:09:28,575 INFO  [RpcServer.handler=10,port=37220] ipc.RpcServer: RpcServer.handler=10,port=37220: starting
2014-01-26 22:09:28,575 INFO  [RpcServer.handler=11,port=37220] ipc.RpcServer: RpcServer.handler=11,port=37220: starting
2014-01-26 22:09:28,575 INFO  [RpcServer.handler=12,port=37220] ipc.RpcServer: RpcServer.handler=12,port=37220: starting
2014-01-26 22:09:28,575 INFO  [RpcServer.handler=13,port=37220] ipc.RpcServer: RpcServer.handler=13,port=37220: starting
2014-01-26 22:09:28,575 INFO  [RpcServer.handler=14,port=37220] ipc.RpcServer: RpcServer.handler=14,port=37220: starting
2014-01-26 22:09:28,575 INFO  [RpcServer.handler=15,port=37220] ipc.RpcServer: RpcServer.handler=15,port=37220: starting
2014-01-26 22:09:28,575 INFO  [RpcServer.handler=16,port=37220] ipc.RpcServer: RpcServer.handler=16,port=37220: starting
2014-01-26 22:09:28,575 INFO  [RpcServer.handler=17,port=37220] ipc.RpcServer: RpcServer.handler=17,port=37220: starting
2014-01-26 22:09:28,575 INFO  [RpcServer.handler=18,port=37220] ipc.RpcServer: RpcServer.handler=18,port=37220: starting
2014-01-26 22:09:28,575 INFO  [RpcServer.handler=19,port=37220] ipc.RpcServer: RpcServer.handler=19,port=37220: starting
2014-01-26 22:09:28,575 INFO  [RpcServer.handler=20,port=37220] ipc.RpcServer: RpcServer.handler=20,port=37220: starting
2014-01-26 22:09:28,576 INFO  [RpcServer.handler=21,port=37220] ipc.RpcServer: RpcServer.handler=21,port=37220: starting
2014-01-26 22:09:28,576 INFO  [RpcServer.handler=22,port=37220] ipc.RpcServer: RpcServer.handler=22,port=37220: starting
2014-01-26 22:09:28,576 INFO  [RpcServer.handler=23,port=37220] ipc.RpcServer: RpcServer.handler=23,port=37220: starting
2014-01-26 22:09:28,576 INFO  [RpcServer.handler=24,port=37220] ipc.RpcServer: RpcServer.handler=24,port=37220: starting
2014-01-26 22:09:28,576 INFO  [RpcServer.handler=25,port=37220] ipc.RpcServer: RpcServer.handler=25,port=37220: starting
2014-01-26 22:09:28,576 INFO  [RpcServer.handler=26,port=37220] ipc.RpcServer: RpcServer.handler=26,port=37220: starting
2014-01-26 22:09:28,576 INFO  [RpcServer.handler=27,port=37220] ipc.RpcServer: RpcServer.handler=27,port=37220: starting
2014-01-26 22:09:28,576 INFO  [RpcServer.handler=28,port=37220] ipc.RpcServer: RpcServer.handler=28,port=37220: starting
2014-01-26 22:09:28,576 INFO  [RpcServer.handler=29,port=37220] ipc.RpcServer: RpcServer.handler=29,port=37220: starting
2014-01-26 22:09:28,576 INFO  [Priority.RpcServer.handler=0,port=37220] ipc.RpcServer: Priority.RpcServer.handler=0,port=37220: starting
2014-01-26 22:09:28,576 INFO  [Priority.RpcServer.handler=1,port=37220] ipc.RpcServer: Priority.RpcServer.handler=1,port=37220: starting
2014-01-26 22:09:28,576 INFO  [Priority.RpcServer.handler=2,port=37220] ipc.RpcServer: Priority.RpcServer.handler=2,port=37220: starting
2014-01-26 22:09:28,577 INFO  [Priority.RpcServer.handler=3,port=37220] ipc.RpcServer: Priority.RpcServer.handler=3,port=37220: starting
2014-01-26 22:09:28,577 INFO  [Priority.RpcServer.handler=4,port=37220] ipc.RpcServer: Priority.RpcServer.handler=4,port=37220: starting
2014-01-26 22:09:28,577 INFO  [Priority.RpcServer.handler=5,port=37220] ipc.RpcServer: Priority.RpcServer.handler=5,port=37220: starting
2014-01-26 22:09:28,577 INFO  [Priority.RpcServer.handler=6,port=37220] ipc.RpcServer: Priority.RpcServer.handler=6,port=37220: starting
2014-01-26 22:09:28,577 INFO  [Priority.RpcServer.handler=7,port=37220] ipc.RpcServer: Priority.RpcServer.handler=7,port=37220: starting
2014-01-26 22:09:28,577 INFO  [Priority.RpcServer.handler=8,port=37220] ipc.RpcServer: Priority.RpcServer.handler=8,port=37220: starting
2014-01-26 22:09:28,577 INFO  [Priority.RpcServer.handler=9,port=37220] ipc.RpcServer: Priority.RpcServer.handler=9,port=37220: starting
2014-01-26 22:09:28,577 INFO  [Replication.RpcServer.handler=0,port=37220] ipc.RpcServer: Replication.RpcServer.handler=0,port=37220: starting
2014-01-26 22:09:28,577 INFO  [Replication.RpcServer.handler=1,port=37220] ipc.RpcServer: Replication.RpcServer.handler=1,port=37220: starting
2014-01-26 22:09:28,577 INFO  [Replication.RpcServer.handler=2,port=37220] ipc.RpcServer: Replication.RpcServer.handler=2,port=37220: starting
2014-01-26 22:09:28,593 INFO  [RS:0;localhost:37220] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2014-01-26 22:09:28,599 INFO  [RS:0;localhost:37220] regionserver.HRegionServer: Serving as localhost,37220,1390770563168, RpcServer on localhost/127.0.0.1:37220, sessionid=0x143d06227cc0001
2014-01-26 22:09:28,599 DEBUG [RS:0;localhost:37220] snapshot.RegionServerSnapshotManager: Start Snapshot Manager localhost,37220,1390770563168
2014-01-26 22:09:28,599 DEBUG [RS:0;localhost:37220] procedure.ZKProcedureMemberRpcs: Starting procedure member 'localhost,37220,1390770563168'
2014-01-26 22:09:28,599 DEBUG [RS:0;localhost:37220] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2014-01-26 22:09:28,599 INFO  [SplitLogWorker-localhost,37220,1390770563168] regionserver.SplitLogWorker: SplitLogWorker localhost,37220,1390770563168 starting
2014-01-26 22:09:28,600 DEBUG [RS:0;localhost:37220] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2014-01-26 22:09:29,775 INFO  [M:0;localhost:32785] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 4212 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-01-26 22:09:30,076 INFO  [M:0;localhost:32785] master.ServerManager: Finished waiting for region servers count to settle; checked in 1, slept for 4513 ms, expecting minimum of 1, maximum of 2147483647, master is running.
2014-01-26 22:09:30,078 INFO  [M:0;localhost:32785] master.MasterFileSystem: Log folder file:/home/mojdeh/HBASE/hbase/WALs/localhost,37220,1390770563168 belongs to an existing region server
2014-01-26 22:09:31,122 INFO  [M:0;localhost:32785] zookeeper.ZooKeeperNodeTracker: Unsetting hbase:meta region location in ZooKeeper
2014-01-26 22:09:31,127 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x143d06227cc0000 type:delete cxid:0x41 zxid:0x21 txntype:-1 reqpath:n/a Error Path:/hbase/meta-region-server Error:KeeperErrorCode = NoNode for /hbase/meta-region-server
2014-01-26 22:09:31,976 WARN  [M:0;localhost:32785] zookeeper.RecoverableZooKeeper: Node /hbase/meta-region-server already deleted, retry=false
2014-01-26 22:09:31,985 DEBUG [M:0;localhost:32785] master.AssignmentManager: No previous transition plan found (or ignoring an existing plan) for hbase:meta,,1.1588230740; generated random plan=hri=hbase:meta,,1.1588230740, src=, dest=localhost,37220,1390770563168; 1 (online=1, available=1) available servers, forceNewPlan=false
2014-01-26 22:09:31,986 DEBUG [M:0;localhost:32785] zookeeper.ZKAssign: master:32785-0x143d06227cc0000, quorum=localhost:2181, baseZNode=/hbase Creating (or updating) unassigned node 1588230740 with OFFLINE state
2014-01-26 22:09:32,460 DEBUG [M:0;localhost:32785] master.AssignmentManager: Setting table hbase:meta to ENABLED state.
2014-01-26 22:09:32,697 INFO  [M:0;localhost:32785] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to localhost,37220,1390770563168
2014-01-26 22:09:32,702 INFO  [M:0;localhost:32785] master.RegionStates: Transitioned {1588230740 state=OFFLINE, ts=1390770571985, server=null} to {1588230740 state=PENDING_OPEN, ts=1390770572702, server=localhost,37220,1390770563168}
2014-01-26 22:09:32,702 DEBUG [M:0;localhost:32785] master.ServerManager: New admin connection to localhost,37220,1390770563168
2014-01-26 22:09:32,726 INFO  [Priority.RpcServer.handler=0,port=37220] regionserver.HRegionServer: Open hbase:meta,,1.1588230740
2014-01-26 22:09:32,728 DEBUG [RS_OPEN_META-localhost:37220-0] zookeeper.ZKAssign: regionserver:37220-0x143d06227cc0001, quorum=localhost:2181, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-01-26 22:09:32,732 INFO  [M:0;localhost:32785] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2014-01-26 22:09:32,879 DEBUG [RS_OPEN_META-localhost:37220-0] zookeeper.ZKAssign: regionserver:37220-0x143d06227cc0001, quorum=localhost:2181, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-01-26 22:09:32,884 DEBUG [RS_OPEN_META-localhost:37220-0] regionserver.HRegionServer: logdir=file:/home/mojdeh/HBASE/hbase/WALs/localhost,37220,1390770563168
2014-01-26 22:09:32,885 DEBUG [AM.ZK.Worker-pool2-t1] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=localhost,37220,1390770563168, region=1588230740, current_state={1588230740 state=PENDING_OPEN, ts=1390770572702, server=localhost,37220,1390770563168}
2014-01-26 22:09:32,886 INFO  [AM.ZK.Worker-pool2-t1] master.RegionStates: Transitioned {1588230740 state=PENDING_OPEN, ts=1390770572702, server=localhost,37220,1390770563168} to {1588230740 state=OPENING, ts=1390770572886, server=localhost,37220,1390770563168}
2014-01-26 22:09:32,887 INFO  [RS_OPEN_META-localhost:37220-0] wal.FSHLog: WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true, optionallogflushinternal=1000ms
2014-01-26 22:09:32,892 INFO  [RS_OPEN_META-localhost:37220-0] wal.FSHLog: New WAL /home/mojdeh/HBASE/hbase/WALs/localhost,37220,1390770563168/localhost%2C37220%2C1390770563168.1390770572888.meta
2014-01-26 22:09:32,892 INFO  [RS_OPEN_META-localhost:37220-0] wal.FSHLog: FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2014-01-26 22:09:32,894 DEBUG [RS_OPEN_META-localhost:37220-0] regionserver.HRegion: Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2014-01-26 22:09:32,911 DEBUG [RS_OPEN_META-localhost:37220-0] coprocessor.CoprocessorHost: Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2014-01-26 22:09:32,915 DEBUG [RS_OPEN_META-localhost:37220-0] regionserver.HRegion: Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2014-01-26 22:09:32,916 INFO  [RS_OPEN_META-localhost:37220-0] regionserver.RegionCoprocessorHost: Load coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2014-01-26 22:09:32,920 DEBUG [RS_OPEN_META-localhost:37220-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table meta 1588230740
2014-01-26 22:09:32,920 DEBUG [RS_OPEN_META-localhost:37220-0] regionserver.HRegion: Instantiated hbase:meta,,1.1588230740
2014-01-26 22:09:32,952 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1,200000; off-peak ratio 5,000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0,500000
2014-01-26 22:09:32,979 INFO  [StoreFileOpenerThread-info-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2014-01-26 22:09:32,980 INFO  [StoreFileOpenerThread-info-1] util.ChecksumType: Checksum can use org.apache.hadoop.util.PureJavaCrc32C
2014-01-26 22:09:33,004 DEBUG [StoreOpener-1588230740-1] regionserver.HStore: loaded file:/home/mojdeh/HBASE/hbase/data/hbase/meta/1588230740/info/4f9ea84902aa4ab6949f71e9eed1785e, isReference=false, isBulkLoadResult=false, seqid=6, majorCompaction=false
2014-01-26 22:09:33,017 DEBUG [RS_OPEN_META-localhost:37220-0] regionserver.HRegion: Found 0 recovered edits file(s) under file:/home/mojdeh/HBASE/hbase/data/hbase/meta/1588230740
2014-01-26 22:09:33,023 INFO  [RS_OPEN_META-localhost:37220-0] regionserver.HRegion: Onlined 1588230740; next sequenceid=7
2014-01-26 22:09:33,023 DEBUG [RS_OPEN_META-localhost:37220-0] zookeeper.ZKAssign: regionserver:37220-0x143d06227cc0001, quorum=localhost:2181, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2014-01-26 22:09:33,025 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Post open deploy tasks for region=hbase:meta,,1.1588230740
2014-01-26 22:09:33,025 INFO  [PostOpenDeployTasks:1588230740] zookeeper.ZooKeeperNodeTracker: Setting hbase:meta region location in ZooKeeper as localhost,37220,1390770563168
2014-01-26 22:09:33,099 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Finished post open deploy task for hbase:meta,,1.1588230740
2014-01-26 22:09:33,104 DEBUG [RS_OPEN_META-localhost:37220-0] zookeeper.ZKAssign: regionserver:37220-0x143d06227cc0001, quorum=localhost:2181, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-01-26 22:09:33,260 DEBUG [RS_OPEN_META-localhost:37220-0] zookeeper.ZKAssign: regionserver:37220-0x143d06227cc0001, quorum=localhost:2181, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-01-26 22:09:33,260 DEBUG [RS_OPEN_META-localhost:37220-0] handler.OpenRegionHandler: Transitioned 1588230740 to OPENED in zk on localhost,37220,1390770563168
2014-01-26 22:09:33,260 DEBUG [RS_OPEN_META-localhost:37220-0] handler.OpenRegionHandler: Opened hbase:meta,,1.1588230740 on localhost,37220,1390770563168
2014-01-26 22:09:33,262 DEBUG [AM.ZK.Worker-pool2-t2] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=localhost,37220,1390770563168, region=1588230740, current_state={1588230740 state=OPENING, ts=1390770572886, server=localhost,37220,1390770563168}
2014-01-26 22:09:33,263 INFO  [AM.ZK.Worker-pool2-t2] master.RegionStates: Transitioned {1588230740 state=OPENING, ts=1390770572886, server=localhost,37220,1390770563168} to {1588230740 state=OPEN, ts=1390770573263, server=localhost,37220,1390770563168}
2014-01-26 22:09:33,267 INFO  [AM.ZK.Worker-pool2-t2] handler.OpenedRegionHandler: Handling OPENED of 1588230740 from localhost,37220,1390770563168; deleting unassigned node
2014-01-26 22:09:33,446 DEBUG [AM.ZK.Worker-pool2-t2] zookeeper.ZKAssign: master:32785-0x143d06227cc0000, quorum=localhost:2181, baseZNode=/hbase Deleted unassigned node 1588230740 in expected state RS_ZK_REGION_OPENED
2014-01-26 22:09:33,448 DEBUG [AM.ZK.Worker-pool2-t3] master.AssignmentManager: Znode hbase:meta,,1.1588230740 deleted, state: {1588230740 state=OPEN, ts=1390770573263, server=localhost,37220,1390770563168}
2014-01-26 22:09:33,448 INFO  [AM.ZK.Worker-pool2-t3] master.RegionStates: Onlined 1588230740 on localhost,37220,1390770563168
2014-01-26 22:09:33,450 INFO  [M:0;localhost:32785] master.HMaster: hbase:meta assigned=1, rit=false, location=localhost,37220,1390770563168
2014-01-26 22:09:33,543 INFO  [M:0;localhost:32785] catalog.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2014-01-26 22:09:33,844 INFO  [M:0;localhost:32785] master.AssignmentManager: Clean cluster startup. Assigning userregions
2014-01-26 22:09:33,844 DEBUG [M:0;localhost:32785] zookeeper.ZKAssign: master:32785-0x143d06227cc0000, quorum=localhost:2181, baseZNode=/hbase Deleting any existing unassigned nodes
2014-01-26 22:09:33,876 INFO  [M:0;localhost:32785] master.SnapshotOfRegionAssignmentFromMeta: Start to scan the hbase:meta for the current region assignment snappshot
2014-01-26 22:09:33,899 INFO  [M:0;localhost:32785] master.SnapshotOfRegionAssignmentFromMeta: Finished to scan the hbase:meta for the current region assignmentsnapshot
2014-01-26 22:09:33,900 INFO  [M:0;localhost:32785] balancer.BaseLoadBalancer: Reassigned 2 regions. 2 retained the pre-restart assignment. 
2014-01-26 22:09:33,901 DEBUG [M:0;localhost:32785] master.AssignmentManager: Assigning 2 region(s) to localhost,37220,1390770563168
2014-01-26 22:09:33,902 DEBUG [M:0;localhost:32785] zookeeper.ZKAssign: master:32785-0x143d06227cc0000, quorum=localhost:2181, baseZNode=/hbase Async create of unassigned node 8e6786d5a1299d7b651eff93cf9ca5cb with OFFLINE state
2014-01-26 22:09:33,902 DEBUG [M:0;localhost:32785] zookeeper.ZKAssign: master:32785-0x143d06227cc0000, quorum=localhost:2181, baseZNode=/hbase Async create of unassigned node 15a4b862c6b279ff97f6704c95fa3d19 with OFFLINE state
2014-01-26 22:09:33,947 DEBUG [main-EventThread] master.OfflineCallback: rs={8e6786d5a1299d7b651eff93cf9ca5cb state=OFFLINE, ts=1390770573767, server=null}, server=localhost,37220,1390770563168
2014-01-26 22:09:33,948 DEBUG [main-EventThread] master.OfflineCallback: rs={15a4b862c6b279ff97f6704c95fa3d19 state=OFFLINE, ts=1390770573558, server=null}, server=localhost,37220,1390770563168
2014-01-26 22:09:33,950 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={8e6786d5a1299d7b651eff93cf9ca5cb state=OFFLINE, ts=1390770573767, server=null}, server=localhost,37220,1390770563168
2014-01-26 22:09:33,950 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={15a4b862c6b279ff97f6704c95fa3d19 state=OFFLINE, ts=1390770573558, server=null}, server=localhost,37220,1390770563168
2014-01-26 22:09:33,954 INFO  [M:0;localhost:32785] master.AssignmentManager: localhost,37220,1390770563168 unassigned znodes=2 of total=2
2014-01-26 22:09:33,954 INFO  [M:0;localhost:32785] master.RegionStates: Transitioned {8e6786d5a1299d7b651eff93cf9ca5cb state=OFFLINE, ts=1390770573902, server=null} to {8e6786d5a1299d7b651eff93cf9ca5cb state=PENDING_OPEN, ts=1390770573954, server=localhost,37220,1390770563168}
2014-01-26 22:09:33,956 INFO  [M:0;localhost:32785] master.RegionStates: Transitioned {15a4b862c6b279ff97f6704c95fa3d19 state=OFFLINE, ts=1390770573902, server=null} to {15a4b862c6b279ff97f6704c95fa3d19 state=PENDING_OPEN, ts=1390770573956, server=localhost,37220,1390770563168}
2014-01-26 22:09:33,959 INFO  [Priority.RpcServer.handler=4,port=37220] regionserver.HRegionServer: Open test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb.
2014-01-26 22:09:33,965 INFO  [Priority.RpcServer.handler=4,port=37220] regionserver.HRegionServer: Open hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19.
2014-01-26 22:09:33,966 DEBUG [RS_OPEN_REGION-localhost:37220-0] zookeeper.ZKAssign: regionserver:37220-0x143d06227cc0001, quorum=localhost:2181, baseZNode=/hbase Transitioning 8e6786d5a1299d7b651eff93cf9ca5cb from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-01-26 22:09:33,969 DEBUG [RS_OPEN_REGION-localhost:37220-1] zookeeper.ZKAssign: regionserver:37220-0x143d06227cc0001, quorum=localhost:2181, baseZNode=/hbase Transitioning 15a4b862c6b279ff97f6704c95fa3d19 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-01-26 22:09:33,969 DEBUG [M:0;localhost:32785] master.AssignmentManager: Bulk assigning done for localhost,37220,1390770563168
2014-01-26 22:09:34,095 DEBUG [RS_OPEN_REGION-localhost:37220-0] zookeeper.ZKAssign: regionserver:37220-0x143d06227cc0001, quorum=localhost:2181, baseZNode=/hbase Transitioned node 8e6786d5a1299d7b651eff93cf9ca5cb from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-01-26 22:09:34,096 DEBUG [RS_OPEN_REGION-localhost:37220-0] regionserver.HRegion: Opening region: {ENCODED => 8e6786d5a1299d7b651eff93cf9ca5cb, NAME => 'test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb.', STARTKEY => '', ENDKEY => ''}
2014-01-26 22:09:34,098 DEBUG [AM.ZK.Worker-pool2-t5] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=localhost,37220,1390770563168, region=8e6786d5a1299d7b651eff93cf9ca5cb, current_state={8e6786d5a1299d7b651eff93cf9ca5cb state=PENDING_OPEN, ts=1390770573954, server=localhost,37220,1390770563168}
2014-01-26 22:09:34,099 INFO  [AM.ZK.Worker-pool2-t5] master.RegionStates: Transitioned {8e6786d5a1299d7b651eff93cf9ca5cb state=PENDING_OPEN, ts=1390770573954, server=localhost,37220,1390770563168} to {8e6786d5a1299d7b651eff93cf9ca5cb state=OPENING, ts=1390770574099, server=localhost,37220,1390770563168}
2014-01-26 22:09:34,099 DEBUG [RS_OPEN_REGION-localhost:37220-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table test 8e6786d5a1299d7b651eff93cf9ca5cb
2014-01-26 22:09:34,099 DEBUG [RS_OPEN_REGION-localhost:37220-0] regionserver.HRegion: Instantiated test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb.
2014-01-26 22:09:34,105 INFO  [StoreOpener-8e6786d5a1299d7b651eff93cf9ca5cb-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1,200000; off-peak ratio 5,000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0,500000
2014-01-26 22:09:34,110 DEBUG [RS_OPEN_REGION-localhost:37220-0] regionserver.HRegion: Found 0 recovered edits file(s) under file:/home/mojdeh/HBASE/hbase/data/default/test/8e6786d5a1299d7b651eff93cf9ca5cb
2014-01-26 22:09:34,111 INFO  [RS_OPEN_REGION-localhost:37220-0] regionserver.HRegion: Onlined 8e6786d5a1299d7b651eff93cf9ca5cb; next sequenceid=1
2014-01-26 22:09:34,111 DEBUG [RS_OPEN_REGION-localhost:37220-0] zookeeper.ZKAssign: regionserver:37220-0x143d06227cc0001, quorum=localhost:2181, baseZNode=/hbase Attempting to retransition opening state of node 8e6786d5a1299d7b651eff93cf9ca5cb
2014-01-26 22:09:34,139 DEBUG [RS_OPEN_REGION-localhost:37220-1] zookeeper.ZKAssign: regionserver:37220-0x143d06227cc0001, quorum=localhost:2181, baseZNode=/hbase Transitioned node 15a4b862c6b279ff97f6704c95fa3d19 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-01-26 22:09:34,140 DEBUG [RS_OPEN_REGION-localhost:37220-1] regionserver.HRegion: Opening region: {ENCODED => 15a4b862c6b279ff97f6704c95fa3d19, NAME => 'hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19.', STARTKEY => '', ENDKEY => ''}
2014-01-26 22:09:34,141 INFO  [PostOpenDeployTasks:8e6786d5a1299d7b651eff93cf9ca5cb] regionserver.HRegionServer: Post open deploy tasks for region=test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb.
2014-01-26 22:09:34,142 DEBUG [AM.ZK.Worker-pool2-t6] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=localhost,37220,1390770563168, region=15a4b862c6b279ff97f6704c95fa3d19, current_state={15a4b862c6b279ff97f6704c95fa3d19 state=PENDING_OPEN, ts=1390770573956, server=localhost,37220,1390770563168}
2014-01-26 22:09:34,142 DEBUG [RS_OPEN_REGION-localhost:37220-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table namespace 15a4b862c6b279ff97f6704c95fa3d19
2014-01-26 22:09:34,143 INFO  [AM.ZK.Worker-pool2-t6] master.RegionStates: Transitioned {15a4b862c6b279ff97f6704c95fa3d19 state=PENDING_OPEN, ts=1390770573956, server=localhost,37220,1390770563168} to {15a4b862c6b279ff97f6704c95fa3d19 state=OPENING, ts=1390770574143, server=localhost,37220,1390770563168}
2014-01-26 22:09:34,143 DEBUG [RS_OPEN_REGION-localhost:37220-1] regionserver.HRegion: Instantiated hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19.
2014-01-26 22:09:34,150 INFO  [StoreOpener-15a4b862c6b279ff97f6704c95fa3d19-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1,200000; off-peak ratio 5,000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0,500000
2014-01-26 22:09:34,160 DEBUG [StoreOpener-15a4b862c6b279ff97f6704c95fa3d19-1] regionserver.HStore: loaded file:/home/mojdeh/HBASE/hbase/data/hbase/namespace/15a4b862c6b279ff97f6704c95fa3d19/info/3043bb9a547d49deb2c4fc2989675374, isReference=false, isBulkLoadResult=false, seqid=4, majorCompaction=false
2014-01-26 22:09:34,163 DEBUG [RS_OPEN_REGION-localhost:37220-1] regionserver.HRegion: Found 0 recovered edits file(s) under file:/home/mojdeh/HBASE/hbase/data/hbase/namespace/15a4b862c6b279ff97f6704c95fa3d19
2014-01-26 22:09:34,164 INFO  [RS_OPEN_REGION-localhost:37220-1] regionserver.HRegion: Onlined 15a4b862c6b279ff97f6704c95fa3d19; next sequenceid=5
2014-01-26 22:09:34,164 DEBUG [RS_OPEN_REGION-localhost:37220-1] zookeeper.ZKAssign: regionserver:37220-0x143d06227cc0001, quorum=localhost:2181, baseZNode=/hbase Attempting to retransition opening state of node 15a4b862c6b279ff97f6704c95fa3d19
2014-01-26 22:09:34,166 INFO  [PostOpenDeployTasks:15a4b862c6b279ff97f6704c95fa3d19] regionserver.HRegionServer: Post open deploy tasks for region=hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19.
2014-01-26 22:09:34,223 INFO  [PostOpenDeployTasks:15a4b862c6b279ff97f6704c95fa3d19] catalog.MetaEditor: Updated row hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19. with server=localhost,37220,1390770563168
2014-01-26 22:09:34,223 INFO  [PostOpenDeployTasks:15a4b862c6b279ff97f6704c95fa3d19] regionserver.HRegionServer: Finished post open deploy task for hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19.
2014-01-26 22:09:34,224 DEBUG [RS_OPEN_REGION-localhost:37220-1] zookeeper.ZKAssign: regionserver:37220-0x143d06227cc0001, quorum=localhost:2181, baseZNode=/hbase Transitioning 15a4b862c6b279ff97f6704c95fa3d19 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-01-26 22:09:34,258 DEBUG [RS_OPEN_REGION-localhost:37220-1] zookeeper.ZKAssign: regionserver:37220-0x143d06227cc0001, quorum=localhost:2181, baseZNode=/hbase Transitioned node 15a4b862c6b279ff97f6704c95fa3d19 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-01-26 22:09:34,259 DEBUG [RS_OPEN_REGION-localhost:37220-1] handler.OpenRegionHandler: Transitioned 15a4b862c6b279ff97f6704c95fa3d19 to OPENED in zk on localhost,37220,1390770563168
2014-01-26 22:09:34,259 DEBUG [RS_OPEN_REGION-localhost:37220-1] handler.OpenRegionHandler: Opened hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19. on localhost,37220,1390770563168
2014-01-26 22:09:34,259 INFO  [PostOpenDeployTasks:8e6786d5a1299d7b651eff93cf9ca5cb] catalog.MetaEditor: Updated row test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb. with server=localhost,37220,1390770563168
2014-01-26 22:09:34,259 INFO  [PostOpenDeployTasks:8e6786d5a1299d7b651eff93cf9ca5cb] regionserver.HRegionServer: Finished post open deploy task for test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb.
2014-01-26 22:09:34,259 DEBUG [RS_OPEN_REGION-localhost:37220-0] zookeeper.ZKAssign: regionserver:37220-0x143d06227cc0001, quorum=localhost:2181, baseZNode=/hbase Transitioning 8e6786d5a1299d7b651eff93cf9ca5cb from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-01-26 22:09:34,260 DEBUG [AM.ZK.Worker-pool2-t7] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=localhost,37220,1390770563168, region=15a4b862c6b279ff97f6704c95fa3d19, current_state={15a4b862c6b279ff97f6704c95fa3d19 state=OPENING, ts=1390770574143, server=localhost,37220,1390770563168}
2014-01-26 22:09:34,260 INFO  [AM.ZK.Worker-pool2-t7] master.RegionStates: Transitioned {15a4b862c6b279ff97f6704c95fa3d19 state=OPENING, ts=1390770574143, server=localhost,37220,1390770563168} to {15a4b862c6b279ff97f6704c95fa3d19 state=OPEN, ts=1390770574260, server=localhost,37220,1390770563168}
2014-01-26 22:09:34,261 DEBUG [AM.ZK.Worker-pool2-t7] handler.OpenedRegionHandler: Handling OPENED of 15a4b862c6b279ff97f6704c95fa3d19 from localhost,37220,1390770563168; deleting unassigned node
2014-01-26 22:09:34,292 DEBUG [RS_OPEN_REGION-localhost:37220-0] zookeeper.ZKAssign: regionserver:37220-0x143d06227cc0001, quorum=localhost:2181, baseZNode=/hbase Transitioned node 8e6786d5a1299d7b651eff93cf9ca5cb from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-01-26 22:09:34,292 DEBUG [RS_OPEN_REGION-localhost:37220-0] handler.OpenRegionHandler: Transitioned 8e6786d5a1299d7b651eff93cf9ca5cb to OPENED in zk on localhost,37220,1390770563168
2014-01-26 22:09:34,293 DEBUG [RS_OPEN_REGION-localhost:37220-0] handler.OpenRegionHandler: Opened test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb. on localhost,37220,1390770563168
2014-01-26 22:09:34,325 DEBUG [AM.ZK.Worker-pool2-t7] zookeeper.ZKAssign: master:32785-0x143d06227cc0000, quorum=localhost:2181, baseZNode=/hbase Deleted unassigned node 15a4b862c6b279ff97f6704c95fa3d19 in expected state RS_ZK_REGION_OPENED
2014-01-26 22:09:34,326 DEBUG [AM.ZK.Worker-pool2-t8] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=localhost,37220,1390770563168, region=8e6786d5a1299d7b651eff93cf9ca5cb, current_state={8e6786d5a1299d7b651eff93cf9ca5cb state=OPENING, ts=1390770574099, server=localhost,37220,1390770563168}
2014-01-26 22:09:34,326 INFO  [AM.ZK.Worker-pool2-t8] master.RegionStates: Transitioned {8e6786d5a1299d7b651eff93cf9ca5cb state=OPENING, ts=1390770574099, server=localhost,37220,1390770563168} to {8e6786d5a1299d7b651eff93cf9ca5cb state=OPEN, ts=1390770574326, server=localhost,37220,1390770563168}
2014-01-26 22:09:34,327 DEBUG [AM.ZK.Worker-pool2-t8] handler.OpenedRegionHandler: Handling OPENED of 8e6786d5a1299d7b651eff93cf9ca5cb from localhost,37220,1390770563168; deleting unassigned node
2014-01-26 22:09:34,331 DEBUG [AM.ZK.Worker-pool2-t10] master.AssignmentManager: Znode hbase:namespace,,1390770447393.15a4b862c6b279ff97f6704c95fa3d19. deleted, state: {15a4b862c6b279ff97f6704c95fa3d19 state=OPEN, ts=1390770574260, server=localhost,37220,1390770563168}
2014-01-26 22:09:34,331 INFO  [AM.ZK.Worker-pool2-t10] master.RegionStates: Onlined 15a4b862c6b279ff97f6704c95fa3d19 on localhost,37220,1390770563168
2014-01-26 22:09:34,502 DEBUG [AM.ZK.Worker-pool2-t8] zookeeper.ZKAssign: master:32785-0x143d06227cc0000, quorum=localhost:2181, baseZNode=/hbase Deleted unassigned node 8e6786d5a1299d7b651eff93cf9ca5cb in expected state RS_ZK_REGION_OPENED
2014-01-26 22:09:34,503 DEBUG [AM.ZK.Worker-pool2-t12] master.AssignmentManager: Znode test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb. deleted, state: {8e6786d5a1299d7b651eff93cf9ca5cb state=OPEN, ts=1390770574326, server=localhost,37220,1390770563168}
2014-01-26 22:09:34,504 INFO  [AM.ZK.Worker-pool2-t12] master.RegionStates: Onlined 8e6786d5a1299d7b651eff93cf9ca5cb on localhost,37220,1390770563168
2014-01-26 22:09:34,930 INFO  [M:0;localhost:32785] master.HMaster: Master has completed initialization
2014-01-26 22:09:34,933 DEBUG [main-EventThread] hbase.ZKNamespaceManager: Updating namespace cache from node default with data: \x0A\x07default
2014-01-26 22:09:34,934 DEBUG [main-EventThread] hbase.ZKNamespaceManager: Updating namespace cache from node hbase with data: \x0A\x05hbase
2014-01-26 22:12:35,828 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33524
2014-01-26 22:12:35,831 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:33524
2014-01-26 22:12:35,897 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d06227cc0005 with negotiated timeout 40000 for client /127.0.0.1:33524
2014-01-26 22:12:36,140 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33525
2014-01-26 22:12:36,140 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:33525
2014-01-26 22:12:36,172 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d06227cc0006 with negotiated timeout 40000 for client /127.0.0.1:33525
2014-01-26 22:13:21,008 WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x143d06227cc0006, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:220)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:744)
2014-01-26 22:13:21,012 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:33525 which had sessionid 0x143d06227cc0006
2014-01-26 22:13:21,012 WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x143d06227cc0005, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:220)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:744)
2014-01-26 22:13:21,013 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:33524 which had sessionid 0x143d06227cc0005
2014-01-26 22:13:56,000 INFO  [SessionTracker] server.ZooKeeperServer: Expiring session 0x143d06227cc0005, timeout of 40000ms exceeded
2014-01-26 22:13:56,001 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x143d06227cc0005
2014-01-26 22:13:58,000 INFO  [SessionTracker] server.ZooKeeperServer: Expiring session 0x143d06227cc0006, timeout of 40000ms exceeded
2014-01-26 22:13:58,000 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x143d06227cc0006
2014-01-26 22:14:23,178 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.18 MB, free=383.50 MB, max=386.68 MB, blocks=3, accesses=19, hits=16, hitRatio=84.21%, , cachingAccesses=19, cachingHits=16, cachingHitsRatio=84.21%, evictions=0, evicted=0, evictedPerRun=NaN
2014-01-26 22:14:34,161 DEBUG [localhost,32785,1390770530870-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-01-26 22:19:23,177 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.18 MB, free=383.50 MB, max=386.68 MB, blocks=3, accesses=20, hits=17, hitRatio=85.00%, , cachingAccesses=20, cachingHits=17, cachingHitsRatio=85.00%, evictions=0, evicted=0, evictedPerRun=NaN
2014-01-26 22:19:25,566 DEBUG [M:0;localhost:32785.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: localhost%2C35894%2C1390770430440.1390770442732
2014-01-26 22:19:25,568 DEBUG [M:0;localhost:32785.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: localhost%2C35894%2C1390770430440.1390770445763.meta
2014-01-26 22:19:34,157 DEBUG [localhost,32785,1390770530870-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-01-26 22:24:23,177 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.18 MB, free=383.50 MB, max=386.68 MB, blocks=3, accesses=21, hits=18, hitRatio=85.71%, , cachingAccesses=21, cachingHits=18, cachingHitsRatio=85.71%, evictions=0, evicted=0, evictedPerRun=NaN
2014-01-26 22:24:34,157 DEBUG [localhost,32785,1390770530870-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-01-26 22:28:35,225 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33768
2014-01-26 22:28:35,231 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:33768
2014-01-26 22:28:35,634 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d06227cc0007 with negotiated timeout 40000 for client /127.0.0.1:33768
2014-01-26 22:28:36,162 INFO  [RpcServer.handler=6,port=32785] master.HMaster: Client=mojdeh//127.0.0.1 create 'population', {NAME => 'populationFamily', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => '2147483647', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
2014-01-26 22:28:36,181 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Got user-level KeeperException when processing sessionid:0x143d06227cc0000 type:create cxid:0xb3 zxid:0x3f txntype:-1 reqpath:n/a Error Path:/hbase/table-lock/population Error:KeeperErrorCode = NoNode for /hbase/table-lock/population
2014-01-26 22:28:36,362 DEBUG [RpcServer.handler=6,port=32785] lock.ZKInterProcessLockBase: Acquired a lock for /hbase/table-lock/population/write-master:327850000000000
2014-01-26 22:28:36,459 INFO  [MASTER_TABLE_OPERATIONS-localhost:32785-0] handler.CreateTableHandler: Create table population
2014-01-26 22:28:36,474 DEBUG [MASTER_TABLE_OPERATIONS-localhost:32785-0] util.FSTableDescriptors: Wrote descriptor into: file:/home/mojdeh/HBASE/hbase/.tmp/data/default/population/.tabledesc/.tableinfo.0000000001
2014-01-26 22:28:36,479 INFO  [RegionOpenAndInitThread-population-1] regionserver.HRegion: creating HRegion population HTD == 'population', {NAME => 'populationFamily', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => '2147483647', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = file:/home/mojdeh/HBASE/hbase/.tmp Table name == population
2014-01-26 22:28:36,487 DEBUG [RegionOpenAndInitThread-population-1] regionserver.HRegion: Instantiated population,,1390771716162.8e33a0cd532aa16d324e1448819bd638.
2014-01-26 22:28:36,487 DEBUG [RegionOpenAndInitThread-population-1] regionserver.HRegion: Closing population,,1390771716162.8e33a0cd532aa16d324e1448819bd638.: disabling compactions & flushes
2014-01-26 22:28:36,488 DEBUG [RegionOpenAndInitThread-population-1] regionserver.HRegion: Updates disabled for region population,,1390771716162.8e33a0cd532aa16d324e1448819bd638.
2014-01-26 22:28:36,488 INFO  [RegionOpenAndInitThread-population-1] regionserver.HRegion: Closed population,,1390771716162.8e33a0cd532aa16d324e1448819bd638.
2014-01-26 22:28:36,493 INFO  [MASTER_TABLE_OPERATIONS-localhost:32785-0] catalog.MetaEditor: Added 1
2014-01-26 22:28:36,494 DEBUG [MASTER_TABLE_OPERATIONS-localhost:32785-0] master.AssignmentManager: Assigning 1 region(s) to localhost,37220,1390770563168
2014-01-26 22:28:36,494 DEBUG [MASTER_TABLE_OPERATIONS-localhost:32785-0] zookeeper.ZKAssign: master:32785-0x143d06227cc0000, quorum=localhost:2181, baseZNode=/hbase Async create of unassigned node 8e33a0cd532aa16d324e1448819bd638 with OFFLINE state
2014-01-26 22:28:36,533 DEBUG [main-EventThread] master.OfflineCallback: rs={8e33a0cd532aa16d324e1448819bd638 state=OFFLINE, ts=1390771716493, server=null}, server=localhost,37220,1390770563168
2014-01-26 22:28:36,534 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={8e33a0cd532aa16d324e1448819bd638 state=OFFLINE, ts=1390771716493, server=null}, server=localhost,37220,1390770563168
2014-01-26 22:28:36,534 INFO  [MASTER_TABLE_OPERATIONS-localhost:32785-0] master.AssignmentManager: localhost,37220,1390770563168 unassigned znodes=1 of total=1
2014-01-26 22:28:36,534 INFO  [MASTER_TABLE_OPERATIONS-localhost:32785-0] master.RegionStates: Transitioned {8e33a0cd532aa16d324e1448819bd638 state=OFFLINE, ts=1390771716494, server=null} to {8e33a0cd532aa16d324e1448819bd638 state=PENDING_OPEN, ts=1390771716534, server=localhost,37220,1390770563168}
2014-01-26 22:28:36,537 INFO  [Priority.RpcServer.handler=7,port=37220] regionserver.HRegionServer: Open population,,1390771716162.8e33a0cd532aa16d324e1448819bd638.
2014-01-26 22:28:36,538 DEBUG [RS_OPEN_REGION-localhost:37220-2] zookeeper.ZKAssign: regionserver:37220-0x143d06227cc0001, quorum=localhost:2181, baseZNode=/hbase Transitioning 8e33a0cd532aa16d324e1448819bd638 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-01-26 22:28:36,539 DEBUG [MASTER_TABLE_OPERATIONS-localhost:32785-0] master.AssignmentManager: Bulk assigning done for localhost,37220,1390770563168
2014-01-26 22:28:36,577 DEBUG [RS_OPEN_REGION-localhost:37220-2] zookeeper.ZKAssign: regionserver:37220-0x143d06227cc0001, quorum=localhost:2181, baseZNode=/hbase Transitioned node 8e33a0cd532aa16d324e1448819bd638 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2014-01-26 22:28:36,577 DEBUG [RS_OPEN_REGION-localhost:37220-2] regionserver.HRegion: Opening region: {ENCODED => 8e33a0cd532aa16d324e1448819bd638, NAME => 'population,,1390771716162.8e33a0cd532aa16d324e1448819bd638.', STARTKEY => '', ENDKEY => ''}
2014-01-26 22:28:36,578 DEBUG [AM.ZK.Worker-pool2-t14] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=localhost,37220,1390770563168, region=8e33a0cd532aa16d324e1448819bd638, current_state={8e33a0cd532aa16d324e1448819bd638 state=PENDING_OPEN, ts=1390771716534, server=localhost,37220,1390770563168}
2014-01-26 22:28:36,578 DEBUG [RS_OPEN_REGION-localhost:37220-2] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table population 8e33a0cd532aa16d324e1448819bd638
2014-01-26 22:28:36,578 INFO  [AM.ZK.Worker-pool2-t14] master.RegionStates: Transitioned {8e33a0cd532aa16d324e1448819bd638 state=PENDING_OPEN, ts=1390771716534, server=localhost,37220,1390770563168} to {8e33a0cd532aa16d324e1448819bd638 state=OPENING, ts=1390771716578, server=localhost,37220,1390770563168}
2014-01-26 22:28:36,578 DEBUG [RS_OPEN_REGION-localhost:37220-2] regionserver.HRegion: Instantiated population,,1390771716162.8e33a0cd532aa16d324e1448819bd638.
2014-01-26 22:28:36,582 INFO  [StoreOpener-8e33a0cd532aa16d324e1448819bd638-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1,200000; off-peak ratio 5,000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0,500000
2014-01-26 22:28:36,606 DEBUG [RS_OPEN_REGION-localhost:37220-2] regionserver.HRegion: Found 0 recovered edits file(s) under file:/home/mojdeh/HBASE/hbase/data/default/population/8e33a0cd532aa16d324e1448819bd638
2014-01-26 22:28:36,606 INFO  [RS_OPEN_REGION-localhost:37220-2] regionserver.HRegion: Onlined 8e33a0cd532aa16d324e1448819bd638; next sequenceid=1
2014-01-26 22:28:36,606 DEBUG [RS_OPEN_REGION-localhost:37220-2] zookeeper.ZKAssign: regionserver:37220-0x143d06227cc0001, quorum=localhost:2181, baseZNode=/hbase Attempting to retransition opening state of node 8e33a0cd532aa16d324e1448819bd638
2014-01-26 22:28:36,785 DEBUG [MASTER_TABLE_OPERATIONS-localhost:32785-0] lock.ZKInterProcessLockBase: Released /hbase/table-lock/population/write-master:327850000000000
2014-01-26 22:28:36,787 INFO  [PostOpenDeployTasks:8e33a0cd532aa16d324e1448819bd638] regionserver.HRegionServer: Post open deploy tasks for region=population,,1390771716162.8e33a0cd532aa16d324e1448819bd638.
2014-01-26 22:28:36,801 INFO  [PostOpenDeployTasks:8e33a0cd532aa16d324e1448819bd638] catalog.MetaEditor: Updated row population,,1390771716162.8e33a0cd532aa16d324e1448819bd638. with server=localhost,37220,1390770563168
2014-01-26 22:28:36,801 INFO  [PostOpenDeployTasks:8e33a0cd532aa16d324e1448819bd638] regionserver.HRegionServer: Finished post open deploy task for population,,1390771716162.8e33a0cd532aa16d324e1448819bd638.
2014-01-26 22:28:36,802 DEBUG [RS_OPEN_REGION-localhost:37220-2] zookeeper.ZKAssign: regionserver:37220-0x143d06227cc0001, quorum=localhost:2181, baseZNode=/hbase Transitioning 8e33a0cd532aa16d324e1448819bd638 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-01-26 22:28:36,840 DEBUG [RS_OPEN_REGION-localhost:37220-2] zookeeper.ZKAssign: regionserver:37220-0x143d06227cc0001, quorum=localhost:2181, baseZNode=/hbase Transitioned node 8e33a0cd532aa16d324e1448819bd638 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2014-01-26 22:28:36,840 DEBUG [RS_OPEN_REGION-localhost:37220-2] handler.OpenRegionHandler: Transitioned 8e33a0cd532aa16d324e1448819bd638 to OPENED in zk on localhost,37220,1390770563168
2014-01-26 22:28:36,840 DEBUG [RS_OPEN_REGION-localhost:37220-2] handler.OpenRegionHandler: Opened population,,1390771716162.8e33a0cd532aa16d324e1448819bd638. on localhost,37220,1390770563168
2014-01-26 22:28:36,841 DEBUG [AM.ZK.Worker-pool2-t15] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=localhost,37220,1390770563168, region=8e33a0cd532aa16d324e1448819bd638, current_state={8e33a0cd532aa16d324e1448819bd638 state=OPENING, ts=1390771716578, server=localhost,37220,1390770563168}
2014-01-26 22:28:36,841 INFO  [AM.ZK.Worker-pool2-t15] master.RegionStates: Transitioned {8e33a0cd532aa16d324e1448819bd638 state=OPENING, ts=1390771716578, server=localhost,37220,1390770563168} to {8e33a0cd532aa16d324e1448819bd638 state=OPEN, ts=1390771716841, server=localhost,37220,1390770563168}
2014-01-26 22:28:36,841 DEBUG [AM.ZK.Worker-pool2-t15] handler.OpenedRegionHandler: Handling OPENED of 8e33a0cd532aa16d324e1448819bd638 from localhost,37220,1390770563168; deleting unassigned node
2014-01-26 22:28:36,859 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33773
2014-01-26 22:28:36,860 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:33773
2014-01-26 22:28:36,873 DEBUG [AM.ZK.Worker-pool2-t15] zookeeper.ZKAssign: master:32785-0x143d06227cc0000, quorum=localhost:2181, baseZNode=/hbase Deleted unassigned node 8e33a0cd532aa16d324e1448819bd638 in expected state RS_ZK_REGION_OPENED
2014-01-26 22:28:36,874 DEBUG [AM.ZK.Worker-pool2-t17] master.AssignmentManager: Znode population,,1390771716162.8e33a0cd532aa16d324e1448819bd638. deleted, state: {8e33a0cd532aa16d324e1448819bd638 state=OPEN, ts=1390771716841, server=localhost,37220,1390770563168}
2014-01-26 22:28:36,874 INFO  [AM.ZK.Worker-pool2-t17] master.RegionStates: Onlined 8e33a0cd532aa16d324e1448819bd638 on localhost,37220,1390770563168
2014-01-26 22:28:36,907 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d06227cc0008 with negotiated timeout 40000 for client /127.0.0.1:33773
2014-01-26 22:28:36,935 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x143d06227cc0008
2014-01-26 22:28:36,974 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:33773 which had sessionid 0x143d06227cc0008
2014-01-26 22:28:37,387 WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x143d06227cc0007, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:220)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:744)
2014-01-26 22:28:37,388 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:33768 which had sessionid 0x143d06227cc0007
2014-01-26 22:29:18,000 INFO  [SessionTracker] server.ZooKeeperServer: Expiring session 0x143d06227cc0007, timeout of 40000ms exceeded
2014-01-26 22:29:18,001 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x143d06227cc0007
2014-01-26 22:29:19,807 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33775
2014-01-26 22:29:19,811 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:33775
2014-01-26 22:29:19,843 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d06227cc0009 with negotiated timeout 40000 for client /127.0.0.1:33775
2014-01-26 22:29:20,099 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:33776
2014-01-26 22:29:20,099 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:33776
2014-01-26 22:29:20,128 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d06227cc000a with negotiated timeout 40000 for client /127.0.0.1:33776
2014-01-26 22:29:23,176 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.18 MB, free=383.50 MB, max=386.68 MB, blocks=3, accesses=30, hits=27, hitRatio=90.00%, , cachingAccesses=30, cachingHits=27, cachingHitsRatio=90.00%, evictions=0, evicted=0, evictedPerRun=NaN
2014-01-26 22:29:34,158 DEBUG [localhost,32785,1390770530870-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-01-26 22:34:23,177 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.18 MB, free=383.50 MB, max=386.68 MB, blocks=3, accesses=31, hits=28, hitRatio=90.32%, , cachingAccesses=31, cachingHits=28, cachingHitsRatio=90.32%, evictions=0, evicted=0, evictedPerRun=NaN
2014-01-26 22:34:34,159 DEBUG [localhost,32785,1390770530870-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-01-26 22:39:23,177 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.18 MB, free=383.50 MB, max=386.68 MB, blocks=3, accesses=32, hits=29, hitRatio=90.63%, , cachingAccesses=32, cachingHits=29, cachingHitsRatio=90.63%, evictions=0, evicted=0, evictedPerRun=NaN
2014-01-26 22:39:34,160 DEBUG [localhost,32785,1390770530870-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-01-26 22:44:23,177 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.18 MB, free=383.50 MB, max=386.68 MB, blocks=3, accesses=33, hits=30, hitRatio=90.91%, , cachingAccesses=33, cachingHits=30, cachingHitsRatio=90.91%, evictions=0, evicted=0, evictedPerRun=NaN
2014-01-26 22:44:34,159 DEBUG [localhost,32785,1390770530870-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-01-26 22:49:23,177 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.18 MB, free=383.50 MB, max=386.68 MB, blocks=3, accesses=34, hits=31, hitRatio=91.18%, , cachingAccesses=34, cachingHits=31, cachingHitsRatio=91.18%, evictions=0, evicted=0, evictedPerRun=NaN
2014-01-26 22:49:34,159 DEBUG [localhost,32785,1390770530870-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-01-26 22:54:23,177 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.18 MB, free=383.50 MB, max=386.68 MB, blocks=3, accesses=35, hits=32, hitRatio=91.43%, , cachingAccesses=35, cachingHits=32, cachingHitsRatio=91.43%, evictions=0, evicted=0, evictedPerRun=NaN
2014-01-26 22:54:34,158 DEBUG [localhost,32785,1390770530870-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-01-26 22:59:23,177 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.18 MB, free=383.50 MB, max=386.68 MB, blocks=3, accesses=36, hits=33, hitRatio=91.67%, , cachingAccesses=36, cachingHits=33, cachingHitsRatio=91.67%, evictions=0, evicted=0, evictedPerRun=NaN
2014-01-26 22:59:34,160 DEBUG [localhost,32785,1390770530870-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-01-26 23:04:23,177 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.18 MB, free=383.50 MB, max=386.68 MB, blocks=3, accesses=37, hits=34, hitRatio=91.89%, , cachingAccesses=37, cachingHits=34, cachingHitsRatio=91.89%, evictions=0, evicted=0, evictedPerRun=NaN
2014-01-26 23:04:34,160 DEBUG [localhost,32785,1390770530870-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-01-26 23:09:23,176 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.18 MB, free=383.50 MB, max=386.68 MB, blocks=3, accesses=38, hits=35, hitRatio=92.11%, , cachingAccesses=38, cachingHits=35, cachingHitsRatio=92.11%, evictions=0, evicted=0, evictedPerRun=NaN
2014-01-26 23:09:28,461 DEBUG [RS:0;localhost:37220.logRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2014-01-26 23:09:28,473 INFO  [RS:0;localhost:37220.logRoller] wal.FSHLog: Rolled WAL /home/mojdeh/HBASE/hbase/WALs/localhost,37220,1390770563168/localhost%2C37220%2C1390770563168.1390770568374 with entries=1, filesize=99; new WAL /home/mojdeh/HBASE/hbase/WALs/localhost,37220,1390770563168/localhost%2C37220%2C1390770563168.1390774168462
2014-01-26 23:09:32,941 DEBUG [RS_OPEN_META-localhost:37220-0-MetaLogRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2014-01-26 23:09:32,952 INFO  [RS_OPEN_META-localhost:37220-0-MetaLogRoller] wal.FSHLog: Rolled WAL /home/mojdeh/HBASE/hbase/WALs/localhost,37220,1390770563168/localhost%2C37220%2C1390770563168.1390770572888.meta with entries=4, filesize=1.3 K; new WAL /home/mojdeh/HBASE/hbase/WALs/localhost,37220,1390770563168/localhost%2C37220%2C1390770563168.1390774172943.meta
2014-01-26 23:09:34,160 DEBUG [localhost,32785,1390770530870-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-01-26 23:09:38,457 INFO  [RS:0;localhost:37220.periodicFlusher] regionserver.HRegionServer: RS:0;localhost:37220.periodicFlusher requesting flush for region hbase:meta,,1.1588230740 after a delay of 12980
2014-01-26 23:09:48,457 INFO  [RS:0;localhost:37220.periodicFlusher] regionserver.HRegionServer: RS:0;localhost:37220.periodicFlusher requesting flush for region hbase:meta,,1.1588230740 after a delay of 16191
2014-01-26 23:09:51,444 DEBUG [Thread-54] regionserver.HRegion: Started memstore flush for hbase:meta,,1.1588230740, current region memstore size 2.3 K
2014-01-26 23:09:51,491 INFO  [Thread-54] regionserver.DefaultStoreFlusher: Flushed, sequenceid=12, memsize=2.3 K, hasBloomFilter=false, into tmp file file:/home/mojdeh/HBASE/hbase/data/hbase/meta/1588230740/.tmp/76ac4809869140c59797a66eae2c96a8
2014-01-26 23:09:51,494 DEBUG [Thread-54] regionserver.HRegionFileSystem: Committing store file file:/home/mojdeh/HBASE/hbase/data/hbase/meta/1588230740/.tmp/76ac4809869140c59797a66eae2c96a8 as file:/home/mojdeh/HBASE/hbase/data/hbase/meta/1588230740/info/76ac4809869140c59797a66eae2c96a8
2014-01-26 23:09:51,496 INFO  [Thread-54] regionserver.HStore: Added file:/home/mojdeh/HBASE/hbase/data/hbase/meta/1588230740/info/76ac4809869140c59797a66eae2c96a8, entries=10, sequenceid=12, filesize=1.9 K
2014-01-26 23:09:51,497 INFO  [Thread-54] regionserver.HRegion: Finished memstore flush of ~2.3 K/2392, currentsize=0/0 for region hbase:meta,,1.1588230740 in 54ms, sequenceid=12, compaction requested=false
2014-01-26 23:13:18,460 INFO  [RS:0;localhost:37220.periodicFlusher] regionserver.HRegionServer: RS:0;localhost:37220.periodicFlusher requesting flush for region test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb. after a delay of 5344
2014-01-26 23:13:23,806 DEBUG [Thread-54] regionserver.HRegion: Started memstore flush for test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb., current region memstore size 160
2014-01-26 23:13:23,846 INFO  [Thread-54] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7, memsize=160, hasBloomFilter=true, into tmp file file:/home/mojdeh/HBASE/hbase/data/default/test/8e6786d5a1299d7b651eff93cf9ca5cb/.tmp/f3c67b49bbee4000851dca038625bd5a
2014-01-26 23:13:23,848 DEBUG [Thread-54] regionserver.HRegionFileSystem: Committing store file file:/home/mojdeh/HBASE/hbase/data/default/test/8e6786d5a1299d7b651eff93cf9ca5cb/.tmp/f3c67b49bbee4000851dca038625bd5a as file:/home/mojdeh/HBASE/hbase/data/default/test/8e6786d5a1299d7b651eff93cf9ca5cb/c/f3c67b49bbee4000851dca038625bd5a
2014-01-26 23:13:23,850 INFO  [Thread-54] regionserver.HStore: Added file:/home/mojdeh/HBASE/hbase/data/default/test/8e6786d5a1299d7b651eff93cf9ca5cb/c/f3c67b49bbee4000851dca038625bd5a, entries=1, sequenceid=7, filesize=995
2014-01-26 23:13:23,850 INFO  [Thread-54] regionserver.HRegion: Finished memstore flush of ~160/160, currentsize=0/0 for region test,,1390770466344.8e6786d5a1299d7b651eff93cf9ca5cb. in 44ms, sequenceid=7, compaction requested=false
2014-01-26 23:14:23,177 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.18 MB, free=383.50 MB, max=386.68 MB, blocks=3, accesses=39, hits=36, hitRatio=92.31%, , cachingAccesses=39, cachingHits=36, cachingHitsRatio=92.31%, evictions=0, evicted=0, evictedPerRun=NaN
2014-01-26 23:14:33,761 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:34210
2014-01-26 23:14:33,767 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:34210
2014-01-26 23:14:34,126 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d06227cc000b with negotiated timeout 40000 for client /127.0.0.1:34210
2014-01-26 23:14:34,159 DEBUG [localhost,32785,1390770530870-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-01-26 23:14:35,247 WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x143d06227cc000b, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:220)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:744)
2014-01-26 23:14:35,248 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:34210 which had sessionid 0x143d06227cc000b
2014-01-26 23:15:16,000 INFO  [SessionTracker] server.ZooKeeperServer: Expiring session 0x143d06227cc000b, timeout of 40000ms exceeded
2014-01-26 23:15:16,001 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x143d06227cc000b
2014-01-26 23:17:00,541 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:34219
2014-01-26 23:17:00,544 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:34219
2014-01-26 23:17:00,605 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d06227cc000c with negotiated timeout 40000 for client /127.0.0.1:34219
2014-01-26 23:18:30,327 WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x143d06227cc000c, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:220)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:744)
2014-01-26 23:18:30,328 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:34219 which had sessionid 0x143d06227cc000c
2014-01-26 23:19:02,001 INFO  [SessionTracker] server.ZooKeeperServer: Expiring session 0x143d06227cc000c, timeout of 40000ms exceeded
2014-01-26 23:19:02,001 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x143d06227cc000c
2014-01-26 23:19:23,177 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.18 MB, free=383.50 MB, max=386.68 MB, blocks=4, accesses=53, hits=49, hitRatio=92.45%, , cachingAccesses=53, cachingHits=49, cachingHitsRatio=92.45%, evictions=0, evicted=0, evictedPerRun=NaN
2014-01-26 23:19:34,161 DEBUG [localhost,32785,1390770530870-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-01-26 23:21:44,484 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:34231
2014-01-26 23:21:44,487 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:34231
2014-01-26 23:21:44,653 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d06227cc000d with negotiated timeout 40000 for client /127.0.0.1:34231
2014-01-26 23:22:05,185 WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x143d06227cc000d, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:220)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:744)
2014-01-26 23:22:05,186 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:34231 which had sessionid 0x143d06227cc000d
2014-01-26 23:22:40,000 INFO  [SessionTracker] server.ZooKeeperServer: Expiring session 0x143d06227cc000d, timeout of 40000ms exceeded
2014-01-26 23:22:40,001 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x143d06227cc000d
2014-01-26 23:24:23,177 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.18 MB, free=383.50 MB, max=386.68 MB, blocks=4, accesses=63, hits=59, hitRatio=93.65%, , cachingAccesses=63, cachingHits=59, cachingHitsRatio=93.65%, evictions=0, evicted=0, evictedPerRun=NaN
2014-01-26 23:24:34,161 DEBUG [localhost,32785,1390770530870-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-01-26 23:29:23,177 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.18 MB, free=383.50 MB, max=386.68 MB, blocks=4, accesses=65, hits=61, hitRatio=93.85%, , cachingAccesses=65, cachingHits=61, cachingHitsRatio=93.85%, evictions=0, evicted=0, evictedPerRun=NaN
2014-01-26 23:29:34,161 DEBUG [localhost,32785,1390770530870-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-01-26 23:32:14,063 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:34257
2014-01-26 23:32:14,066 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:34257
2014-01-26 23:32:14,098 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d06227cc000e with negotiated timeout 40000 for client /127.0.0.1:34257
2014-01-26 23:33:08,254 WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x143d06227cc000e, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:220)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:744)
2014-01-26 23:33:08,254 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:34257 which had sessionid 0x143d06227cc000e
2014-01-26 23:33:44,000 INFO  [SessionTracker] server.ZooKeeperServer: Expiring session 0x143d06227cc000e, timeout of 40000ms exceeded
2014-01-26 23:33:44,000 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x143d06227cc000e
2014-01-26 23:34:23,177 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.18 MB, free=383.50 MB, max=386.68 MB, blocks=4, accesses=79, hits=75, hitRatio=94.94%, , cachingAccesses=79, cachingHits=75, cachingHitsRatio=94.94%, evictions=0, evicted=0, evictedPerRun=NaN
2014-01-26 23:34:34,160 DEBUG [localhost,32785,1390770530870-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-01-26 23:35:18,951 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:34269
2014-01-26 23:35:18,958 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.ZooKeeperServer: Client attempting to establish new session at /127.0.0.1:34269
2014-01-26 23:35:19,217 INFO  [SyncThread:0] server.ZooKeeperServer: Established session 0x143d06227cc000f with negotiated timeout 40000 for client /127.0.0.1:34269
2014-01-26 23:35:20,287 WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x143d06227cc000f, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:220)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:744)
2014-01-26 23:35:20,288 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:34269 which had sessionid 0x143d06227cc000f
2014-01-26 23:36:00,000 INFO  [SessionTracker] server.ZooKeeperServer: Expiring session 0x143d06227cc000f, timeout of 40000ms exceeded
2014-01-26 23:36:00,001 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor: Processed session termination for sessionid: 0x143d06227cc000f
2014-01-26 23:39:23,177 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.18 MB, free=383.50 MB, max=386.68 MB, blocks=4, accesses=87, hits=83, hitRatio=95.40%, , cachingAccesses=87, cachingHits=83, cachingHitsRatio=95.40%, evictions=0, evicted=0, evictedPerRun=NaN
2014-01-26 23:39:34,161 DEBUG [localhost,32785,1390770530870-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-01-26 23:44:23,177 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.18 MB, free=383.50 MB, max=386.68 MB, blocks=4, accesses=95, hits=91, hitRatio=95.79%, , cachingAccesses=95, cachingHits=91, cachingHitsRatio=95.79%, evictions=0, evicted=0, evictedPerRun=NaN
2014-01-26 23:44:34,162 DEBUG [localhost,32785,1390770530870-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-01-26 23:49:23,177 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.18 MB, free=383.50 MB, max=386.68 MB, blocks=4, accesses=97, hits=93, hitRatio=95.88%, , cachingAccesses=97, cachingHits=93, cachingHitsRatio=95.88%, evictions=0, evicted=0, evictedPerRun=NaN
2014-01-26 23:49:34,163 DEBUG [localhost,32785,1390770530870-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-01-26 23:54:23,177 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.18 MB, free=383.50 MB, max=386.68 MB, blocks=4, accesses=99, hits=95, hitRatio=95.96%, , cachingAccesses=99, cachingHits=95, cachingHitsRatio=95.96%, evictions=0, evicted=0, evictedPerRun=NaN
2014-01-26 23:54:34,164 DEBUG [localhost,32785,1390770530870-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-01-26 23:59:23,177 DEBUG [LruStats #0] hfile.LruBlockCache: Total=3.18 MB, free=383.50 MB, max=386.68 MB, blocks=4, accesses=101, hits=97, hitRatio=96.04%, , cachingAccesses=101, cachingHits=97, cachingHitsRatio=96.04%, evictions=0, evicted=0, evictedPerRun=NaN
